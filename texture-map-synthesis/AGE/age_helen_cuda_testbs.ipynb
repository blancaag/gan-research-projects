{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--g_updates'], dest='g_updates', nargs=None, const=None, default='2;KL_fake:1,match_z:1,match_x:0', type=None, choices=None, help='Update plan for generator <number of updates>;[<term:weight>]', metavar=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../utils')\n",
    "\n",
    "import libraries\n",
    "# from libraries import *\n",
    "import utils_general\n",
    "from utils_general import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#########\n",
    "\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', required=True,\n",
    "                    help='cifar10 | lsun | imagenet | folder | lfw ')\n",
    "parser.add_argument('--dataroot', type=str, help='path to dataset')\n",
    "parser.add_argument('--workers', type=int,\n",
    "                    help='number of data loading workers', default=8)\n",
    "parser.add_argument('--batch_size', type=int,\n",
    "                    default=64, help='batch size')\n",
    "parser.add_argument('--image_size', type=int, default=32,\n",
    "                    help='the resolution of the input image to network')\n",
    "parser.add_argument('--nz', type=int, default=100,\n",
    "                    help='size of the latent z vector')\n",
    "parser.add_argument('--ngf', type=int, default=64)\n",
    "parser.add_argument('--ndf', type=int, default=64)\n",
    "parser.add_argument('--nc', type=int)\n",
    "\n",
    "parser.add_argument('--nepoch', type=int, default=25,\n",
    "                    help='number of epochs to train for')\n",
    "parser.add_argument('--lr', type=float, default=0.0002,\n",
    "                    help='learning rate, default=0.0002')\n",
    "parser.add_argument('--beta1', type=float, default=0.5,\n",
    "                    help='beta1 for adam. default=0.5')\n",
    "parser.add_argument('--cpu', action='store_true',\n",
    "                    help='use CPU instead of GPU')\n",
    "parser.add_argument('--ngpu', type=int, default=1,\n",
    "                    help='number of GPUs to use')\n",
    "\n",
    "parser.add_argument('--netG', default='',\n",
    "                    help=\"path to netG config\")\n",
    "parser.add_argument('--netE', default='',\n",
    "                    help=\"path to netE config\")\n",
    "parser.add_argument('--netG_chp', default='',\n",
    "                    help=\"path to netG (to continue training)\")\n",
    "parser.add_argument('--netE_chp', default='',\n",
    "                    help=\"path to netE (to continue training)\")\n",
    "\n",
    "parser.add_argument('--save_dir', default='.',\n",
    "                    help='folder to output images and model checkpoints')\n",
    "parser.add_argument('--criterion', default='param',\n",
    "                    help='param|nonparam, How to estimate KL')\n",
    "parser.add_argument('--KL', default='qp', help='pq|qp')\n",
    "parser.add_argument('--noise', default='sphere', help='normal|sphere')\n",
    "parser.add_argument('--match_z', default='cos', help='none|L1|L2|cos')\n",
    "parser.add_argument('--match_x', default='L1', help='none|L1|L2|cos')\n",
    "\n",
    "parser.add_argument('--drop_lr', default=5, type=int, help='')\n",
    "parser.add_argument('--save_every', default=50, type=int, help='')\n",
    "\n",
    "parser.add_argument('--manual_seed', type=int, default=123, help='manual seed')\n",
    "parser.add_argument('--start_epoch', type=int, default=0, help='epoch number to start with')\n",
    "\n",
    "parser.add_argument(\n",
    "    '--e_updates', default=\"1;KL_fake:1,KL_real:1,match_z:0,match_x:0\",\n",
    "    help='Update plan for encoder <number of updates>;[<term:weight>]'\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    '--g_updates', default=\"2;KL_fake:1,match_z:1,match_x:0\",\n",
    "    help='Update plan for generator <number of updates>;[<term:weight>]'\n",
    ")\n",
    "\n",
    "# opt = parser.parse_args()\n",
    "\n",
    "# python age.py \n",
    "# --dataset celeba \n",
    "# --dataroot <data_root> \n",
    "# --image_size 64 \n",
    "# --save_dir <save_dir> \n",
    "# --lr 0.0002 \n",
    "# --nz 64 \n",
    "# --batch_size 64 \n",
    "# --netG dcgan64px \n",
    "# --netE dcgan64px \n",
    "# --nepoch 5 \n",
    "# --drop_lr 5 \n",
    "# --e_updates '1;KL_fake:1,KL_real:1,match_z:0,match_x:10' \n",
    "# --g_updates '3;KL_fake:1,match_z:1000,match_x:0'\n",
    "\n",
    "# python age.py \n",
    "# --dataset celeba \n",
    "# --dataroot <data_root> \n",
    "# --image_size 64 \n",
    "# --save_dir <save_dir> \n",
    "# --start_epoch 5 \n",
    "# --lr 0.0002 \n",
    "# --nz 64 \n",
    "# --batch_size 256 \n",
    "# --netG dcgan64px \n",
    "# --netE dcgan64px \n",
    "# --nepoch 6 \n",
    "# --drop_lr 5   \n",
    "# --e_updates '1;KL_fake:1,KL_real:1,match_z:0,match_x:15' \n",
    "# --g_updates '3;KL_fake:1,match_z:1000,match_x:0' \n",
    "# --netE_chp  <save_dir>/netE_epoch_5.pth \n",
    "# --netG_chp <save_dir>/netG_epoch_5.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svmem(total=64388890624, available=61909028864, percent=3.9, used=1985212416, free=59827081216, active=3348983808, inactive=830545920, buffers=53317632, cached=2523279360, shared=11788288)\n"
     ]
    }
   ],
   "source": [
    "# print(get_available_gpus())\n",
    "print(psutil.virtual_memory())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "import importlib\n",
    "# from .dataset import FolderWithImages\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory was not created.\n"
     ]
    }
   ],
   "source": [
    "# setup function @utils.py\n",
    "\n",
    "cuda = True # not opt.cpu\n",
    "torch.set_num_threads(4)\n",
    "dataset = 'helen'\n",
    "save_dir = 'output/helen'\n",
    "try:\n",
    "    os.makedirs(save_dir)\n",
    "except OSError:\n",
    "    print('Directory was not created.')\n",
    "\n",
    "manual_seed = random.randint(1, 10000)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "if torch.cuda.is_available() and not cuda:\n",
    "    print(\"WARNING: You have a CUDA device,\"\n",
    "            \"so you should probably run with --cuda\")\n",
    "\n",
    "e_updates = '1;KL_fake:1,KL_real:1,match_z:0,match_x:10' \n",
    "g_updates = '3;KL_fake:1,match_z:1000,match_x:0'\n",
    "    \n",
    "updates = {'e': {}, 'g': {}}\n",
    "updates['e']['num_updates'] = int(e_updates.split(';')[0])\n",
    "updates['e'].update({x.split(':')[0]: float(x.split(':')[1]) \n",
    "                     for x in e_updates.split(';')[1].split(',')})\n",
    "\n",
    "updates['g']['num_updates'] = int(g_updates.split(';')[0])\n",
    "updates['g'].update({x.split(':')[0]: float(x.split(':')[1]) \n",
    "                     for x in g_updates.split(';')[1].split(',')})\n",
    "\n",
    "\n",
    "###################\n",
    "\n",
    "image_size = 64 # 512\n",
    "batch_size = 64 # 64\n",
    "workers = 8\n",
    "shuffle = True\n",
    "drop_last = True\n",
    "train = True\n",
    "\n",
    "nc = 3\n",
    "nz = 64 #100 #'size of the latent z vector')\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "ngpu = 1 # 'number of GPUs to use')\n",
    "pin_memory = False # True | If ``True``, the data loader will copy tensors into CUDA pinned memory before returning them.\n",
    "\n",
    "noise = 'sphere' #help='normal|sphere')\n",
    "\n",
    "netG = 'dcgan64px' \n",
    "netE = 'dcgan64px' \n",
    "\n",
    "netG_chp = '' # \"path to netG (to continue training)\"\n",
    "netE_chp = '' # \"path to netE (to continue training)\"\n",
    "\n",
    "lr = 0.0002 \n",
    "drop_lr = 200\n",
    "beta1 = 0.5 # help='beta1 for adam. default=0.5'\n",
    "criterion = 'param'# help='param|nonparam, How to estimate KL'\n",
    "KL ='qp' # help='pq|qp'\n",
    "match_z = 'cos' # help='none|L1|L2|cos'\n",
    "match_x = 'L1' # help='none|L1|L2|cos'\n",
    "\n",
    "start_epoch = 0\n",
    "nepoch = 10\n",
    "\n",
    "save_every_e = 1\n",
    "save_every_b = None\n",
    "dataroot = '../data/isomapsr'\n",
    "\n",
    "# --lr 0.0002 \n",
    "# --nz 64 \n",
    "# --batch_size 64 \n",
    "# --netG dcgan64px \n",
    "# --netE dcgan64px \n",
    "# --nepoch 5 \n",
    "# --drop_lr 5 \n",
    "# --e_updates '1;KL_fake:1,KL_real:1,match_z:0,match_x:10' \n",
    "# --g_updates '3;KL_fake:1,match_z:1000,match_x:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py:156: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "import importlib\n",
    "import random\n",
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "from PIL import Image\n",
    "\n",
    "##\n",
    "import torch.utils.data as data\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from PIL import Image\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in [\".png\", \".jpg\", \".jpeg\"])\n",
    "\n",
    "def load_img(filepath):\n",
    "    img = cv2.imread(filepath) #, cv2.IMREAD_UNCHANGED)\n",
    "#     img = Image.open(filepath).convert('RGB')\n",
    "    return img\n",
    "\n",
    "class FolderWithImages(data.Dataset):\n",
    "    def __init__(self, root, input_transform=None, target_transform=None):\n",
    "        super(FolderWithImages, self).__init__()\n",
    "        self.image_filenames = [join(root, x)\n",
    "                                for x in listdir(root) if is_image_file(x.lower())]\n",
    "\n",
    "        self.input_transform = input_transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input = load_img(self.image_filenames[index])\n",
    "        target = input.copy()\n",
    "        if self.input_transform:\n",
    "            input = self.input_transform(input)\n",
    "        if self.target_transform:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return input, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "    \n",
    "##\n",
    "\n",
    "def setup_dataset(dataset, dataroot, train=True, shuffle=True, drop_last=True):\n",
    "    '''\n",
    "    Setups dataset.\n",
    "    '''\n",
    "    # Usual transform\n",
    "    t = transforms.Compose([\n",
    "        transforms.Scale([image_size, image_size]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "    if dataset in ['imagenet', 'folder', 'lfw']:\n",
    "        imdir = 'train' if train else 'val'\n",
    "        dataroot = os.path.join(dataroot, imdir)\n",
    "\n",
    "        dataset = dset.ImageFolder(root=dataroot, transform=t)\n",
    "    elif dataset == 'lsun':\n",
    "        dataset = dset.LSUN(db_path=dataroot,\n",
    "                            classes=['bedroom_train'],\n",
    "                            train=train,\n",
    "                            transform=t)\n",
    "    elif dataset == 'cifar10':\n",
    "        dataset = dset.CIFAR10(root='data/raw/cifar10',\n",
    "                               download=True,\n",
    "                               train=train,\n",
    "                               transform=t\n",
    "                               )\n",
    "    elif dataset == 'mnist':\n",
    "        dataset = dset.MNIST(root='data/raw/mnist',\n",
    "                             download=True,\n",
    "                             train=train,\n",
    "                             transform=t\n",
    "                             )\n",
    "    elif dataset == 'svhn':\n",
    "        dataset = dset.SVHN(root='data/raw/svhn',\n",
    "                            download=True,\n",
    "                            train=train,\n",
    "                            transform=t)\n",
    "    elif dataset == 'celeba':\n",
    "        imdir = 'train' if train else 'val'\n",
    "        dataroot = os.path.join(dataroot, imdir)\n",
    "\n",
    "        dataset = FolderWithImages(root=dataroot,\n",
    "                                   input_transform=transforms.Compose([\n",
    "                                       ALICropAndScale(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(\n",
    "                                           (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                   ]),\n",
    "                                   target_transform=transforms.ToTensor()\n",
    "                                   )\n",
    "    elif dataset == 'helen':\n",
    "        imdir = 'train' if train else 'val'\n",
    "        dataroot = os.path.join(dataroot, imdir)\n",
    "\n",
    "        dataset = FolderWithImages(root=dataroot,\n",
    "                                   input_transform=transforms.Compose([\n",
    "                                       Scale(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(\n",
    "                                           (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                   ]),\n",
    "                                   target_transform=transforms.ToTensor()\n",
    "                                   )\n",
    "        \n",
    "    else:\n",
    "        assert False, 'Wrong dataset name.'\n",
    "\n",
    "    assert len(dataset) > 0, 'No images found, check your paths.'\n",
    "\n",
    "    # Shuffle and drop last when training\n",
    "    dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=shuffle,\n",
    "                                             num_workers=int(workers),\n",
    "                                             pin_memory=pin_memory,\n",
    "                                             drop_last=drop_last)\n",
    "#     print(len(dataloader))\n",
    "#     for i in dataloader: print(i[0].shape, i[1].shape)\n",
    "        \n",
    "    return InfiniteDataLoader(dataloader)\n",
    "#     return dataloader\n",
    "\n",
    "class InfiniteDataLoader(object):\n",
    "    \"\"\"docstring for InfiniteDataLoader\"\"\"\n",
    "\n",
    "    def __init__(self, dataloader):\n",
    "        super(InfiniteDataLoader, self).__init__()\n",
    "        self.dataloader = dataloader\n",
    "        self.data_iter = None\n",
    "\n",
    "    def next(self):\n",
    "        try:\n",
    "            data = self.data_iter.next()\n",
    "        except Exception:\n",
    "            # Reached end of the dataset\n",
    "            self.data_iter = iter(self.dataloader)\n",
    "            data = self.data_iter.next()\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataloader)\n",
    "\n",
    "class ALICropAndScale(object):\n",
    "    def __call__(self, img):\n",
    "        return img.resize((64, 78), Image.ANTIALIAS).crop((0, 7, 64, 64 + 7))\n",
    "    \n",
    "class Scale(object):\n",
    "    def __call__(self, img):\n",
    "        img = cv2.resize(img, (image_size, image_size), cv2.INTER_AREA)\n",
    "        return img \n",
    "\n",
    "# cv::INTER_AREA interpolation, whereas to\n",
    "# .   enlarge an image, it will generally look best with cv::INTER_CUBIC (slow) or cv::INTER_LINEAR\n",
    "# .   (faster but still looks OK).\n",
    "    \n",
    "# Setup dataset\n",
    "dataloader = dict(train=setup_dataset(dataset, dataroot, train=True),\n",
    "                  val=setup_dataset(dataset, dataroot, train=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "0 torch.Size([64, 3, 64, 64])\n",
      "1 torch.Size([64, 3, 64, 64])\n",
      "2 torch.Size([64, 3, 64, 64])\n",
      "3 torch.Size([64, 3, 64, 64])\n",
      "4 torch.Size([64, 3, 64, 64])\n",
      "5 torch.Size([64, 3, 64, 64])\n",
      "6 torch.Size([64, 3, 64, 64])\n",
      "7 torch.Size([64, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "print(len(dataloader['train']))\n",
    "# for i, j in dataloader['train']:\n",
    "#     print(i.shape, j.shape)\n",
    "\n",
    "\n",
    "# def populate_x(x, dataloader):\n",
    "#     '''\n",
    "#     Fills input variable `x` with data generated with dataloader\n",
    "#     '''\n",
    "#     real_cpu, _ = dataloader.next()\n",
    "#     x.data.resize_(real_cpu.size()).copy_(real_cpu)\n",
    "\n",
    "for i in range(len(dataloader['val'])):\n",
    "    print(i, dataloader['val'].next()[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(x, dim=0):\n",
    "    '''\n",
    "    Projects points to a sphere.\n",
    "    '''\n",
    "    return x.div(x.norm(2, dim=dim).expand_as(x))\n",
    "\n",
    "def normalize_(x, dim=0):\n",
    "    '''\n",
    "    Projects points to a sphere inplace.\n",
    "    '''\n",
    "    x.div_(x.norm(2, dim=dim).expand_as(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator\n",
      " _netG_Base(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d (64, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): ConvTranspose2d (512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): ConvTranspose2d (256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (8): ReLU(inplace)\n",
      "    (9): ConvTranspose2d (128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (11): ReLU(inplace)\n",
      "    (12): ConvTranspose2d (64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n",
      "Encoder\n",
      " _netE_Base(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d (3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(0.2, inplace)\n",
      "    (2): Conv2d (64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (4): LeakyReLU(0.2, inplace)\n",
      "    (5): Conv2d (128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (7): LeakyReLU(0.2, inplace)\n",
      "    (8): Conv2d (256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (10): LeakyReLU(0.2, inplace)\n",
      "    (11): Conv2d (512, 64, kernel_size=(4, 4), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def weights_init(m):\n",
    "    '''\n",
    "    Custom weights initialization called on netG and netE\n",
    "    '''\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "class _netE_Base(nn.Module):\n",
    "    def __init__(self, main):\n",
    "        super(_netE_Base, self).__init__()\n",
    "        self.noise = noise\n",
    "        self.ngpu = ngpu\n",
    "        self.main = main\n",
    "\n",
    "    def forward(self, input):\n",
    "        gpu_ids = None\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 0:\n",
    "            gpu_ids = range(self.ngpu)\n",
    "            output = nn.parallel.data_parallel(self.main, input, gpu_ids)\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        if self.noise == 'sphere':\n",
    "            output = normalize(output)\n",
    "        return output\n",
    "    \n",
    "class _netG_Base(nn.Module):\n",
    "    def __init__(self, main):\n",
    "        super(_netG_Base, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = main\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        # Check input is either (B,C,1,1) or (B,C)\n",
    "        assert input.nelement() == input.size(0) * input.size(1), 'wtf'\n",
    "        input = input.view(input.size(0), input.size(1), 1, 1)\n",
    "\n",
    "        gpu_ids = None\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 0:\n",
    "            gpu_ids = range(self.ngpu)\n",
    "            return nn.parallel.data_parallel(self.main, input, gpu_ids)\n",
    "        else:\n",
    "            return self.main(input)\n",
    "\n",
    "\n",
    "def _netE():\n",
    "#     ndf = opt.ndf\n",
    "#     nc = opt.nc\n",
    "#     nz = opt.nz\n",
    "\n",
    "    main = nn.Sequential(\n",
    "        # input is (nc) x 64 x 64\n",
    "        nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # state size. (ndf) x 16 x 16\n",
    "        nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf * 2),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # state size. (ndf*2) x 8 x 8\n",
    "        nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf * 4),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # state size. (ndf*4) x 4 x 4\n",
    "        nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf * 8),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # state size. (ndf*8) x 4 x 4\n",
    "        nn.Conv2d(ndf * 8, nz, 4, 1, 0, bias=True),\n",
    "    )\n",
    "\n",
    "    return _netE_Base(main)\n",
    "\n",
    "def _netG():\n",
    "#     ngf = opt.ngf\n",
    "#     nc = opt.nc\n",
    "#     nz = opt.nz\n",
    "\n",
    "    main = nn.Sequential(\n",
    "        # input is Z, going into a convolution\n",
    "        nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(ngf * 8),\n",
    "        nn.ReLU(True),\n",
    "        # state size. (ngf*8) x 4 x 4\n",
    "        nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ngf * 4),\n",
    "        nn.ReLU(True),\n",
    "        # state size. (ngf*4) x 8 x 8\n",
    "        nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ngf * 2),\n",
    "        nn.ReLU(True),\n",
    "        # state size. (ngf*2) x 16 x 16\n",
    "        nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ngf),\n",
    "        nn.ReLU(True),\n",
    "        # state size. (ngf) x 32 x 32\n",
    "        nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "        nn.Tanh()\n",
    "        # state size. (nc) x 64 x 64\n",
    "    )\n",
    "\n",
    "    return _netG_Base(main)\n",
    "\n",
    "def load_G():\n",
    "    '''\n",
    "    Loads generator model.\n",
    "    '''\n",
    "    netG = _netG()\n",
    "    netG.apply(weights_init)\n",
    "    netG.train()\n",
    "    if netG_chp != '':\n",
    "        netG.load_state_dict(torch.load(netG_chp).state_dict())\n",
    "\n",
    "    print('Generator\\n', netG)\n",
    "    return netG\n",
    "\n",
    "def load_E():\n",
    "    '''\n",
    "    Loads encoder model.\n",
    "    '''\n",
    "    netE = _netE()\n",
    "    netE.apply(weights_init)\n",
    "    netE.train()\n",
    "    if netE_chp != '':\n",
    "        netE.load_state_dict(torch.load(netE_chp).state_dict())\n",
    "\n",
    "    print('Encoder\\n', netE)\n",
    "\n",
    "    return netE\n",
    "\n",
    "# Load generator\n",
    "netG = load_G()\n",
    "\n",
    "# Load encoder\n",
    "netE = load_E()\n",
    "\n",
    "# RuntimeError: Given transposed=1, weight[64, 512, 4, 4], so expected input[64, 256, 1, 1] to have 64 channels,\n",
    "# but got 256 channels instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretraining preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def var(x, dim=0):\n",
    "    '''\n",
    "    Calculates variance.\n",
    "    '''\n",
    "    x_zero_meaned = x - x.mean(dim).expand_as(x)\n",
    "    return x_zero_meaned.pow(2).mean(dim)\n",
    "\n",
    "\n",
    "class KLN01Loss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, direction, minimize):\n",
    "        super(KLN01Loss, self).__init__()\n",
    "        self.minimize = minimize\n",
    "        assert direction in ['pq', 'qp'], 'direction?'\n",
    "\n",
    "        self.direction = direction\n",
    "\n",
    "    def forward(self, samples):\n",
    "\n",
    "        assert samples.nelement() == samples.size(1) * samples.size(0), 'wtf?'\n",
    "\n",
    "        samples = samples.view(samples.size(0), -1)\n",
    "\n",
    "        self.samples_var = var(samples)\n",
    "        self.samples_mean = samples.mean(0)\n",
    "\n",
    "        samples_mean = self.samples_mean\n",
    "        samples_var = self.samples_var\n",
    "\n",
    "        if self.direction == 'pq':\n",
    "            # mu_1 = 0; sigma_1 = 1\n",
    "\n",
    "            t1 = (1 + samples_mean.pow(2)) / (2 * samples_var.pow(2))\n",
    "            t2 = samples_var.log()\n",
    "\n",
    "            KL = (t1 + t2 - 0.5).mean()\n",
    "        else:\n",
    "            # mu_2 = 0; sigma_2 = 1\n",
    "\n",
    "            t1 = (samples_var.pow(2) + samples_mean.pow(2)) / 2\n",
    "            t2 = -samples_var.log()\n",
    "\n",
    "            KL = (t1 + t2 - 0.5).mean()\n",
    "\n",
    "        if not self.minimize:\n",
    "            KL *= -1\n",
    "\n",
    "        return KL\n",
    "\n",
    "# ----------------------------\n",
    "\n",
    "def pairwise_euclidean(samples):\n",
    "\n",
    "    B = samples.size(0)\n",
    "\n",
    "    samples_norm = samples.mul(samples).sum(1)\n",
    "    samples_norm = samples_norm.expand(B, B)\n",
    "\n",
    "    dist_mat = samples.mm(samples.t()).mul(-2) + \\\n",
    "        samples_norm.add(samples_norm.t())\n",
    "    return dist_mat\n",
    "\n",
    "def sample_entropy(samples):\n",
    "\n",
    "        # Assume B x C input\n",
    "\n",
    "    dist_mat = pairwise_euclidean(samples)\n",
    "\n",
    "    # Get max and add it to diag\n",
    "    m = dist_mat.max().detach()\n",
    "    dist_mat_d = dist_mat + \\\n",
    "        Variable(torch.eye(dist_mat.size(0)) * (m.data[0] + 1)).cuda()\n",
    "\n",
    "    entropy = (dist_mat_d.min(1)[0] + 1e-4).log().sum()\n",
    "\n",
    "    entropy *= (samples.size(1) + 0.) / samples.size(0)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "class SampleKLN01Loss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, direction, minimize):\n",
    "        super(SampleKLN01Loss, self).__init__()\n",
    "        self.minimize = minimize\n",
    "        assert direction in ['pq', 'qp'], 'direction?'\n",
    "\n",
    "        self.direction = direction\n",
    "\n",
    "    def forward(self, samples):\n",
    "\n",
    "        assert samples.ndimension == 2, 'wft'\n",
    "        samples = samples.view(samples.size(0), -1)\n",
    "\n",
    "        self.samples_var = var(samples)\n",
    "        self.samples_mean = samples.mean(0)\n",
    "\n",
    "        if self.direction == 'pq':\n",
    "            assert False, 'not possible'\n",
    "        else:\n",
    "            entropy = sample_entropy(samples)\n",
    "\n",
    "            cross_entropy = - samples.pow(2).mean() / 2.\n",
    "\n",
    "            KL = - cross_entropy - entropy\n",
    "\n",
    "        if not self.minimize:\n",
    "            KL *= -1\n",
    "\n",
    "        return KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x = torch.FloatTensor(batch_size, nc, image_size, image_size)\n",
    "# z = torch.FloatTensor(batch_size, nz, 1, 1)\n",
    "# fixed_z = torch.FloatTensor(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "# z = fixed_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using parametric criterion KL_qp\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(batch_size, nc, image_size, image_size)\n",
    "z = torch.FloatTensor(batch_size, nz, 1, 1)\n",
    "fixed_z = torch.FloatTensor(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "\n",
    "def match(x, y, dist):\n",
    "    '''\n",
    "    Computes distance between corresponding points in `x` and `y`\n",
    "    using distance `dist`.\n",
    "    '''\n",
    "    if dist == 'L2':\n",
    "        return (x - y).pow(2).mean()\n",
    "    elif dist == 'L1':\n",
    "        return (x - y).abs().mean()\n",
    "    elif dist == 'cos':\n",
    "        x_n = normalize(x)\n",
    "        y_n = normalize(y)\n",
    "\n",
    "        return 2 - (x_n).mul(y_n).mean()\n",
    "    else:\n",
    "        assert dist == 'none', 'wtf ?'\n",
    "\n",
    "def normalize(x, dim=0):\n",
    "    '''\n",
    "    Projects points to a sphere.\n",
    "    '''\n",
    "    return x.div(x.norm(2, dim=dim).expand_as(x))\n",
    "\n",
    "def normalize_(x, dim=0):\n",
    "    '''\n",
    "    Projects points to a sphere inplace.\n",
    "    '''\n",
    "    x.div_(x.norm(2, dim=dim).expand_as(x))\n",
    "\n",
    "if noise == 'sphere':\n",
    "    normalize_(fixed_z)\n",
    "\n",
    "if cuda:\n",
    "    netE.cuda()\n",
    "    netG.cuda()\n",
    "    x = x.cuda()\n",
    "    z, fixed_z = z.cuda(), fixed_z.cuda()\n",
    "\n",
    "x = Variable(x)\n",
    "z = Variable(z)\n",
    "fixed_z = Variable(fixed_z)\n",
    "\n",
    "# Setup optimizers\n",
    "optimizerD = optim.Adam(netE.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "# Setup criterions\n",
    "if criterion == 'param':\n",
    "    print('Using parametric criterion KL_%s' % KL)\n",
    "    KL_minimizer = KLN01Loss(direction=KL, minimize=True)\n",
    "    KL_maximizer = KLN01Loss(direction=KL, minimize=False)\n",
    "elif criterion == 'nonparam':\n",
    "    print('Using NON-parametric criterion KL_%s' % KL)\n",
    "    KL_minimizer = SampleKLN01Loss(direction=KL, minimize=True)\n",
    "    KL_maximizer = SampleKLN01Loss(direction=KL, minimize=False)\n",
    "else:\n",
    "    assert False, 'criterion?'\n",
    "\n",
    "real_cpu = torch.FloatTensor()\n",
    "\n",
    "def save_images(epoch):\n",
    "\n",
    "    real_cpu.resize_(x.data.size()).copy_(x.data)\n",
    "\n",
    "    # Real samples\n",
    "    save_path = '%s/real_samples.png' % save_dir\n",
    "    vutils.save_image(real_cpu[:64] / 2 + 0.5, save_path)\n",
    "\n",
    "    netG.eval()\n",
    "    fake = netG(fixed_z)\n",
    "\n",
    "    # Fake samples\n",
    "    save_path = '%s/fake_samples_epoch_%03d.png' % (save_dir, epoch)\n",
    "    vutils.save_image(fake.data[:64] / 2 + 0.5, save_path)\n",
    "\n",
    "    # Save reconstructions\n",
    "    populate_x(x, dataloader['val'])\n",
    "    gex = netG(netE(x)) # here - at G entry\n",
    "\n",
    "    t = torch.FloatTensor(x.size(0) * 2, x.size(1),\n",
    "                          x.size(2), x.size(3))\n",
    "\n",
    "    t[0::2] = x.data[:]\n",
    "    t[1::2] = gex.data[:]\n",
    "\n",
    "    save_path = '%s/reconstructions_epoch_%03d.png' % (save_dir, epoch)\n",
    "    grid = vutils.save_image(t[:64] / 2 + 0.5, save_path)\n",
    "    \n",
    "    netG.train()\n",
    "\n",
    "def adjust_lr(epoch):\n",
    "    if epoch % drop_lr == (drop_lr - 1):\n",
    "        ###\n",
    "        assert optimizerD.param_groups[0]['lr'] == optimizerG.param_groups[0]['lr']\n",
    "        print('Adjusting learning rate from %f to %f on E and G' % (lr, lr / 2))\n",
    "        optimizerD.param_groups[0]['lr'] /= 2\n",
    "        optimizerG.param_groups[0]['lr'] /= 2\n",
    "        ###\n",
    "#         lr /= 2\n",
    "#         for param_group in optimizerD.param_groups:\n",
    "#             param_group['lr'] = lr\n",
    "\n",
    "#         for param_group in optimizerG.param_groups:\n",
    "#             param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def populate_x(x, dataloader):\n",
    "    '''\n",
    "    Fills input variable `x` with data generated with dataloader\n",
    "    '''\n",
    "    real_cpu, _ = dataloader.next()\n",
    "    x.data.resize_(real_cpu.size()).copy_(real_cpu)\n",
    "\n",
    "def populate_z(z):\n",
    "    '''\n",
    "    Fills noise variable `z` with noise U(S^M)\n",
    "    '''\n",
    "    z.data.resize_(batch_size, nz, 1, 1)\n",
    "    z.data.normal_(0, 1)\n",
    "    if noise == 'sphere':\n",
    "        normalize_(z.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(len(dataloader['train'].next()))\n",
    "# print(len(dataloader['val'].next()))\n",
    "# print(dataloader['train'].next()[0].shape, dataloader['train'].next()[1].shape)\n",
    "# print(dataloader['train'].next()[0].shape, dataloader['train'].next()[1].shape)\n",
    "\n",
    "# populate_x(x, dataloader['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10][0/52] KL_real/fake: 4.024/3.961 mean_real/fake: 0.006/0.000 var_real/fake: 0.012/0.012 \n",
      "[0/10][1/52] KL_real/fake: 4.181/3.791 mean_real/fake: -0.008/0.004 var_real/fake: 0.010/0.014 \n",
      "[0/10][2/52] KL_real/fake: 3.846/3.741 mean_real/fake: -0.005/-0.002 var_real/fake: 0.013/0.015 \n",
      "[0/10][3/52] KL_real/fake: 3.787/3.744 mean_real/fake: 0.008/-0.005 var_real/fake: 0.014/0.015 \n",
      "[0/10][4/52] KL_real/fake: 3.797/3.776 mean_real/fake: 0.004/0.006 var_real/fake: 0.014/0.014 \n",
      "[0/10][5/52] KL_real/fake: 3.747/3.795 mean_real/fake: 0.005/-0.003 var_real/fake: 0.014/0.014 \n",
      "[0/10][6/52] KL_real/fake: 3.719/3.859 mean_real/fake: -0.003/-0.020 var_real/fake: 0.015/0.013 \n",
      "[0/10][7/52] KL_real/fake: 3.701/3.933 mean_real/fake: -0.009/0.011 var_real/fake: 0.015/0.013 \n",
      "[0/10][8/52] KL_real/fake: 3.706/3.991 mean_real/fake: 0.010/-0.025 var_real/fake: 0.015/0.012 \n",
      "[0/10][9/52] KL_real/fake: 3.714/4.080 mean_real/fake: -0.004/0.010 var_real/fake: 0.015/0.012 \n",
      "[0/10][10/52] KL_real/fake: 3.713/4.158 mean_real/fake: 0.003/-0.019 var_real/fake: 0.015/0.011 \n",
      "[0/10][11/52] KL_real/fake: 3.714/4.186 mean_real/fake: -0.004/-0.005 var_real/fake: 0.015/0.011 \n",
      "[0/10][12/52] KL_real/fake: 3.727/4.304 mean_real/fake: 0.005/-0.007 var_real/fake: 0.015/0.011 \n",
      "[0/10][13/52] KL_real/fake: 3.710/4.359 mean_real/fake: 0.006/-0.003 var_real/fake: 0.015/0.010 \n",
      "[0/10][14/52] KL_real/fake: 3.701/4.394 mean_real/fake: 0.003/0.007 var_real/fake: 0.015/0.010 \n",
      "[0/10][15/52] KL_real/fake: 3.712/4.475 mean_real/fake: 0.016/-0.004 var_real/fake: 0.015/0.010 \n",
      "[0/10][16/52] KL_real/fake: 3.692/4.525 mean_real/fake: 0.001/0.007 var_real/fake: 0.015/0.009 \n",
      "[0/10][17/52] KL_real/fake: 3.764/4.551 mean_real/fake: 0.005/-0.002 var_real/fake: 0.014/0.009 \n",
      "[0/10][18/52] KL_real/fake: 3.744/4.560 mean_real/fake: 0.004/0.008 var_real/fake: 0.014/0.009 \n",
      "[0/10][19/52] KL_real/fake: 3.751/4.630 mean_real/fake: 0.007/-0.003 var_real/fake: 0.014/0.008 \n",
      "[0/10][20/52] KL_real/fake: 3.737/4.676 mean_real/fake: 0.001/0.006 var_real/fake: 0.015/0.008 \n",
      "[0/10][21/52] KL_real/fake: 3.792/4.737 mean_real/fake: 0.001/0.009 var_real/fake: 0.014/0.007 \n",
      "[0/10][22/52] KL_real/fake: 3.758/4.631 mean_real/fake: 0.009/0.010 var_real/fake: 0.014/0.008 \n",
      "[0/10][23/52] KL_real/fake: 3.855/4.868 mean_real/fake: 0.008/0.011 var_real/fake: 0.013/0.007 \n",
      "[0/10][24/52] KL_real/fake: 3.782/4.513 mean_real/fake: 0.004/0.006 var_real/fake: 0.014/0.008 \n",
      "[0/10][25/52] KL_real/fake: 4.109/4.886 mean_real/fake: 0.006/0.003 var_real/fake: 0.010/0.006 \n",
      "[0/10][26/52] KL_real/fake: 3.788/4.225 mean_real/fake: 0.003/0.008 var_real/fake: 0.014/0.010 \n",
      "[0/10][27/52] KL_real/fake: 4.105/4.533 mean_real/fake: 0.006/0.007 var_real/fake: 0.011/0.007 \n",
      "[0/10][28/52] KL_real/fake: 4.094/4.464 mean_real/fake: 0.003/0.002 var_real/fake: 0.011/0.008 \n",
      "[0/10][29/52] KL_real/fake: 4.101/4.481 mean_real/fake: 0.000/0.002 var_real/fake: 0.011/0.008 \n",
      "[0/10][30/52] KL_real/fake: 4.208/4.564 mean_real/fake: 0.002/0.002 var_real/fake: 0.010/0.008 \n",
      "[0/10][31/52] KL_real/fake: 4.160/4.567 mean_real/fake: -0.002/-0.001 var_real/fake: 0.010/0.008 \n",
      "[0/10][32/52] KL_real/fake: 4.162/4.658 mean_real/fake: -0.007/-0.003 var_real/fake: 0.010/0.007 \n",
      "[0/10][33/52] KL_real/fake: 4.273/4.805 mean_real/fake: 0.001/-0.001 var_real/fake: 0.009/0.006 \n",
      "[0/10][34/52] KL_real/fake: 4.207/4.798 mean_real/fake: -0.003/-0.003 var_real/fake: 0.010/0.006 \n",
      "[0/10][35/52] KL_real/fake: 4.194/4.708 mean_real/fake: -0.004/-0.002 var_real/fake: 0.010/0.007 \n",
      "[0/10][36/52] KL_real/fake: 4.269/4.751 mean_real/fake: 0.002/0.001 var_real/fake: 0.010/0.007 \n",
      "[0/10][37/52] KL_real/fake: 4.284/4.928 mean_real/fake: 0.001/0.001 var_real/fake: 0.009/0.006 \n",
      "[0/10][38/52] KL_real/fake: 4.214/4.629 mean_real/fake: -0.001/0.003 var_real/fake: 0.010/0.008 \n",
      "[0/10][39/52] KL_real/fake: 4.146/4.660 mean_real/fake: 0.003/0.004 var_real/fake: 0.010/0.007 \n",
      "[0/10][40/52] KL_real/fake: 4.185/4.601 mean_real/fake: 0.002/0.004 var_real/fake: 0.010/0.008 \n",
      "[0/10][41/52] KL_real/fake: 4.172/4.734 mean_real/fake: 0.000/0.000 var_real/fake: 0.010/0.007 \n",
      "[0/10][42/52] KL_real/fake: 4.327/4.735 mean_real/fake: 0.001/0.000 var_real/fake: 0.009/0.007 \n",
      "[0/10][43/52] KL_real/fake: 4.241/4.408 mean_real/fake: -0.006/-0.000 var_real/fake: 0.010/0.009 \n",
      "[0/10][44/52] KL_real/fake: 4.189/4.362 mean_real/fake: -0.002/0.005 var_real/fake: 0.010/0.009 \n",
      "[0/10][45/52] KL_real/fake: 4.207/4.309 mean_real/fake: 0.004/0.004 var_real/fake: 0.010/0.009 \n",
      "[0/10][46/52] KL_real/fake: 4.303/4.390 mean_real/fake: 0.005/0.005 var_real/fake: 0.009/0.008 \n",
      "[0/10][47/52] KL_real/fake: 4.287/4.486 mean_real/fake: 0.000/0.000 var_real/fake: 0.010/0.008 \n",
      "[0/10][48/52] KL_real/fake: 4.365/4.355 mean_real/fake: -0.007/-0.000 var_real/fake: 0.009/0.009 \n",
      "[0/10][49/52] KL_real/fake: 4.418/4.326 mean_real/fake: -0.002/-0.003 var_real/fake: 0.009/0.009 \n",
      "[0/10][50/52] KL_real/fake: 4.291/4.195 mean_real/fake: -0.009/-0.004 var_real/fake: 0.009/0.010 \n",
      "[0/10][51/52] KL_real/fake: 4.171/4.200 mean_real/fake: -0.004/-0.006 var_real/fake: 0.010/0.010 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type _netG_Base. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type _netE_Base. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10][0/52] KL_real/fake: 4.122/4.163 mean_real/fake: -0.005/-0.006 var_real/fake: 0.011/0.011 \n",
      "[1/10][1/52] KL_real/fake: 4.205/4.242 mean_real/fake: -0.006/-0.006 var_real/fake: 0.010/0.010 \n",
      "[1/10][2/52] KL_real/fake: 4.276/4.336 mean_real/fake: -0.002/-0.004 var_real/fake: 0.010/0.009 \n",
      "[1/10][3/52] KL_real/fake: 4.345/4.394 mean_real/fake: -0.004/-0.004 var_real/fake: 0.009/0.009 \n",
      "[1/10][4/52] KL_real/fake: 4.317/4.355 mean_real/fake: -0.003/-0.002 var_real/fake: 0.009/0.009 \n",
      "[1/10][5/52] KL_real/fake: 4.299/4.262 mean_real/fake: -0.004/-0.004 var_real/fake: 0.009/0.010 \n",
      "[1/10][6/52] KL_real/fake: 4.367/4.326 mean_real/fake: -0.004/-0.004 var_real/fake: 0.009/0.010 \n",
      "[1/10][7/52] KL_real/fake: 4.339/4.373 mean_real/fake: -0.003/-0.005 var_real/fake: 0.009/0.009 \n",
      "[1/10][8/52] KL_real/fake: 4.360/4.389 mean_real/fake: -0.002/-0.005 var_real/fake: 0.009/0.009 \n",
      "[1/10][9/52] KL_real/fake: 4.374/4.332 mean_real/fake: -0.006/-0.004 var_real/fake: 0.009/0.010 \n",
      "[1/10][10/52] KL_real/fake: 4.421/4.339 mean_real/fake: -0.007/-0.000 var_real/fake: 0.009/0.009 \n",
      "[1/10][11/52] KL_real/fake: 4.376/4.429 mean_real/fake: -0.005/-0.002 var_real/fake: 0.009/0.009 \n",
      "[1/10][12/52] KL_real/fake: 4.454/4.449 mean_real/fake: -0.000/-0.001 var_real/fake: 0.009/0.009 \n",
      "[1/10][13/52] KL_real/fake: 4.363/4.351 mean_real/fake: -0.004/-0.001 var_real/fake: 0.009/0.009 \n",
      "[1/10][14/52] KL_real/fake: 4.374/4.352 mean_real/fake: -0.003/-0.005 var_real/fake: 0.009/0.010 \n",
      "[1/10][15/52] KL_real/fake: 4.329/4.321 mean_real/fake: -0.008/-0.006 var_real/fake: 0.010/0.010 \n",
      "[1/10][16/52] KL_real/fake: 4.362/4.340 mean_real/fake: -0.009/-0.005 var_real/fake: 0.010/0.010 \n",
      "[1/10][17/52] KL_real/fake: 4.367/4.388 mean_real/fake: -0.004/-0.003 var_real/fake: 0.009/0.009 \n",
      "[1/10][18/52] KL_real/fake: 4.431/4.374 mean_real/fake: -0.005/-0.003 var_real/fake: 0.009/0.009 \n",
      "[1/10][19/52] KL_real/fake: 4.340/4.400 mean_real/fake: -0.005/-0.005 var_real/fake: 0.010/0.009 \n",
      "[1/10][20/52] KL_real/fake: 4.363/4.397 mean_real/fake: -0.003/-0.002 var_real/fake: 0.010/0.010 \n",
      "[1/10][21/52] KL_real/fake: 4.438/4.373 mean_real/fake: -0.004/-0.003 var_real/fake: 0.009/0.010 \n",
      "[1/10][22/52] KL_real/fake: 4.362/4.342 mean_real/fake: -0.005/-0.002 var_real/fake: 0.010/0.010 \n",
      "[1/10][23/52] KL_real/fake: 4.365/4.327 mean_real/fake: -0.006/-0.006 var_real/fake: 0.010/0.010 \n",
      "[1/10][24/52] KL_real/fake: 4.355/4.315 mean_real/fake: -0.011/-0.008 var_real/fake: 0.010/0.010 \n",
      "[1/10][25/52] KL_real/fake: 4.339/4.328 mean_real/fake: -0.014/-0.010 var_real/fake: 0.010/0.010 \n",
      "[1/10][26/52] KL_real/fake: 4.338/4.313 mean_real/fake: -0.007/-0.003 var_real/fake: 0.010/0.010 \n",
      "[1/10][27/52] KL_real/fake: 4.312/4.302 mean_real/fake: -0.007/-0.005 var_real/fake: 0.010/0.010 \n",
      "[1/10][28/52] KL_real/fake: 4.329/4.269 mean_real/fake: -0.007/-0.008 var_real/fake: 0.010/0.010 \n",
      "[1/10][29/52] KL_real/fake: 4.317/4.308 mean_real/fake: -0.011/-0.006 var_real/fake: 0.010/0.010 \n",
      "[1/10][30/52] KL_real/fake: 4.344/4.312 mean_real/fake: -0.010/-0.005 var_real/fake: 0.010/0.010 \n",
      "[1/10][31/52] KL_real/fake: 4.342/4.329 mean_real/fake: -0.007/-0.007 var_real/fake: 0.010/0.010 \n",
      "[1/10][32/52] KL_real/fake: 4.319/4.300 mean_real/fake: -0.011/-0.011 var_real/fake: 0.010/0.010 \n",
      "[1/10][33/52] KL_real/fake: 4.342/4.268 mean_real/fake: -0.012/-0.010 var_real/fake: 0.010/0.010 \n",
      "[1/10][34/52] KL_real/fake: 4.325/4.316 mean_real/fake: -0.009/-0.011 var_real/fake: 0.010/0.010 \n",
      "[1/10][35/52] KL_real/fake: 4.311/4.283 mean_real/fake: -0.013/-0.009 var_real/fake: 0.010/0.010 \n",
      "[1/10][36/52] KL_real/fake: 4.321/4.315 mean_real/fake: -0.012/-0.008 var_real/fake: 0.010/0.010 \n",
      "[1/10][37/52] KL_real/fake: 4.378/4.357 mean_real/fake: -0.009/-0.008 var_real/fake: 0.010/0.010 \n",
      "[1/10][38/52] KL_real/fake: 4.429/4.375 mean_real/fake: -0.010/-0.007 var_real/fake: 0.009/0.010 \n",
      "[1/10][39/52] KL_real/fake: 4.368/4.355 mean_real/fake: -0.010/-0.006 var_real/fake: 0.010/0.010 \n",
      "[1/10][40/52] KL_real/fake: 4.334/4.347 mean_real/fake: -0.010/-0.004 var_real/fake: 0.010/0.010 \n",
      "[1/10][41/52] KL_real/fake: 4.359/4.338 mean_real/fake: -0.006/-0.005 var_real/fake: 0.010/0.010 \n",
      "[1/10][42/52] KL_real/fake: 4.314/4.294 mean_real/fake: -0.009/-0.006 var_real/fake: 0.010/0.010 \n",
      "[1/10][43/52] KL_real/fake: 4.353/4.338 mean_real/fake: -0.005/-0.007 var_real/fake: 0.010/0.010 \n",
      "[1/10][44/52] KL_real/fake: 4.346/4.378 mean_real/fake: -0.005/-0.007 var_real/fake: 0.010/0.010 \n",
      "[1/10][45/52] KL_real/fake: 4.403/4.375 mean_real/fake: -0.011/-0.008 var_real/fake: 0.010/0.010 \n",
      "[1/10][46/52] KL_real/fake: 4.385/4.362 mean_real/fake: -0.010/-0.007 var_real/fake: 0.010/0.010 \n",
      "[1/10][47/52] KL_real/fake: 4.471/4.419 mean_real/fake: -0.005/-0.006 var_real/fake: 0.009/0.010 \n",
      "[1/10][48/52] KL_real/fake: 4.422/4.450 mean_real/fake: -0.005/-0.007 var_real/fake: 0.010/0.010 \n",
      "[1/10][49/52] KL_real/fake: 4.447/4.418 mean_real/fake: -0.008/-0.008 var_real/fake: 0.010/0.010 \n",
      "[1/10][50/52] KL_real/fake: 4.322/4.316 mean_real/fake: -0.009/-0.010 var_real/fake: 0.010/0.010 \n",
      "[1/10][51/52] KL_real/fake: 4.307/4.328 mean_real/fake: -0.010/-0.009 var_real/fake: 0.010/0.010 \n",
      "[2/10][0/52] KL_real/fake: 4.396/4.320 mean_real/fake: -0.010/-0.010 var_real/fake: 0.010/0.010 \n",
      "[2/10][1/52] KL_real/fake: 4.379/4.321 mean_real/fake: -0.008/-0.006 var_real/fake: 0.010/0.010 \n",
      "[2/10][2/52] KL_real/fake: 4.354/4.357 mean_real/fake: -0.009/-0.005 var_real/fake: 0.010/0.010 \n",
      "[2/10][3/52] KL_real/fake: 4.386/4.369 mean_real/fake: -0.007/-0.005 var_real/fake: 0.010/0.010 \n",
      "[2/10][4/52] KL_real/fake: 4.411/4.390 mean_real/fake: -0.006/-0.007 var_real/fake: 0.010/0.010 \n",
      "[2/10][5/52] KL_real/fake: 4.385/4.361 mean_real/fake: -0.006/-0.005 var_real/fake: 0.010/0.010 \n",
      "[2/10][6/52] KL_real/fake: 4.407/4.369 mean_real/fake: -0.004/-0.008 var_real/fake: 0.010/0.010 \n",
      "[2/10][7/52] KL_real/fake: 4.433/4.395 mean_real/fake: -0.007/-0.008 var_real/fake: 0.009/0.010 \n",
      "[2/10][8/52] KL_real/fake: 4.472/4.399 mean_real/fake: -0.011/-0.010 var_real/fake: 0.009/0.010 \n",
      "[2/10][9/52] KL_real/fake: 4.441/4.432 mean_real/fake: -0.011/-0.007 var_real/fake: 0.010/0.010 \n",
      "[2/10][10/52] KL_real/fake: 4.455/4.419 mean_real/fake: -0.011/-0.009 var_real/fake: 0.010/0.010 \n",
      "[2/10][11/52] KL_real/fake: 4.403/4.405 mean_real/fake: -0.011/-0.009 var_real/fake: 0.010/0.010 \n",
      "[2/10][12/52] KL_real/fake: 4.441/4.421 mean_real/fake: -0.009/-0.009 var_real/fake: 0.010/0.010 \n",
      "[2/10][13/52] KL_real/fake: 4.469/4.391 mean_real/fake: -0.009/-0.009 var_real/fake: 0.009/0.010 \n",
      "[2/10][14/52] KL_real/fake: 4.456/4.427 mean_real/fake: -0.014/-0.013 var_real/fake: 0.010/0.010 \n",
      "[2/10][15/52] KL_real/fake: 4.445/4.402 mean_real/fake: -0.013/-0.011 var_real/fake: 0.010/0.010 \n",
      "[2/10][16/52] KL_real/fake: 4.403/4.389 mean_real/fake: -0.012/-0.010 var_real/fake: 0.010/0.010 \n",
      "[2/10][17/52] KL_real/fake: 4.349/4.352 mean_real/fake: -0.011/-0.012 var_real/fake: 0.010/0.010 \n",
      "[2/10][18/52] KL_real/fake: 4.353/4.380 mean_real/fake: -0.011/-0.013 var_real/fake: 0.010/0.010 \n",
      "[2/10][19/52] KL_real/fake: 4.393/4.384 mean_real/fake: -0.012/-0.010 var_real/fake: 0.010/0.010 \n",
      "[2/10][20/52] KL_real/fake: 4.513/4.474 mean_real/fake: -0.012/-0.013 var_real/fake: 0.009/0.009 \n",
      "[2/10][21/52] KL_real/fake: 4.458/4.449 mean_real/fake: -0.017/-0.012 var_real/fake: 0.010/0.010 \n",
      "[2/10][22/52] KL_real/fake: 4.506/4.491 mean_real/fake: -0.012/-0.010 var_real/fake: 0.009/0.010 \n",
      "[2/10][23/52] KL_real/fake: 4.573/4.482 mean_real/fake: -0.012/-0.011 var_real/fake: 0.009/0.010 \n",
      "[2/10][24/52] KL_real/fake: 4.505/4.434 mean_real/fake: -0.010/-0.006 var_real/fake: 0.009/0.010 \n",
      "[2/10][25/52] KL_real/fake: 4.456/4.428 mean_real/fake: -0.010/-0.004 var_real/fake: 0.009/0.010 \n",
      "[2/10][26/52] KL_real/fake: 4.396/4.392 mean_real/fake: -0.007/-0.001 var_real/fake: 0.010/0.010 \n",
      "[2/10][27/52] KL_real/fake: 4.370/4.372 mean_real/fake: -0.003/-0.003 var_real/fake: 0.010/0.010 \n",
      "[2/10][28/52] KL_real/fake: 4.389/4.380 mean_real/fake: -0.003/-0.006 var_real/fake: 0.010/0.010 \n",
      "[2/10][29/52] KL_real/fake: 4.452/4.431 mean_real/fake: -0.004/-0.005 var_real/fake: 0.009/0.010 \n",
      "[2/10][30/52] KL_real/fake: 4.500/4.454 mean_real/fake: -0.008/-0.007 var_real/fake: 0.009/0.010 \n",
      "[2/10][31/52] KL_real/fake: 4.438/4.410 mean_real/fake: -0.011/-0.010 var_real/fake: 0.010/0.010 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/10][32/52] KL_real/fake: 4.475/4.466 mean_real/fake: -0.012/-0.011 var_real/fake: 0.009/0.010 \n",
      "[2/10][33/52] KL_real/fake: 4.505/4.472 mean_real/fake: -0.011/-0.010 var_real/fake: 0.009/0.010 \n",
      "[2/10][34/52] KL_real/fake: 4.453/4.475 mean_real/fake: -0.011/-0.013 var_real/fake: 0.010/0.010 \n",
      "[2/10][35/52] KL_real/fake: 4.478/4.469 mean_real/fake: -0.011/-0.012 var_real/fake: 0.009/0.009 \n",
      "[2/10][36/52] KL_real/fake: 4.486/4.429 mean_real/fake: -0.016/-0.008 var_real/fake: 0.009/0.010 \n",
      "[2/10][37/52] KL_real/fake: 4.499/4.454 mean_real/fake: -0.010/-0.003 var_real/fake: 0.009/0.009 \n",
      "[2/10][38/52] KL_real/fake: 4.480/4.461 mean_real/fake: -0.006/-0.007 var_real/fake: 0.009/0.009 \n",
      "[2/10][39/52] KL_real/fake: 4.517/4.466 mean_real/fake: -0.007/-0.009 var_real/fake: 0.009/0.009 \n",
      "[2/10][40/52] KL_real/fake: 4.447/4.432 mean_real/fake: -0.009/-0.012 var_real/fake: 0.010/0.010 \n",
      "[2/10][41/52] KL_real/fake: 4.408/4.448 mean_real/fake: -0.011/-0.009 var_real/fake: 0.010/0.010 \n",
      "[2/10][42/52] KL_real/fake: 4.437/4.425 mean_real/fake: -0.012/-0.010 var_real/fake: 0.010/0.010 \n",
      "[2/10][43/52] KL_real/fake: 4.427/4.452 mean_real/fake: -0.009/-0.010 var_real/fake: 0.009/0.010 \n",
      "[2/10][44/52] KL_real/fake: 4.403/4.408 mean_real/fake: -0.011/-0.009 var_real/fake: 0.010/0.010 \n",
      "[2/10][45/52] KL_real/fake: 4.389/4.401 mean_real/fake: -0.011/-0.011 var_real/fake: 0.010/0.010 \n",
      "[2/10][46/52] KL_real/fake: 4.471/4.427 mean_real/fake: -0.011/-0.010 var_real/fake: 0.009/0.010 \n",
      "[2/10][47/52] KL_real/fake: 4.468/4.463 mean_real/fake: -0.009/-0.007 var_real/fake: 0.010/0.010 \n",
      "[2/10][48/52] KL_real/fake: 4.498/4.443 mean_real/fake: -0.007/-0.008 var_real/fake: 0.009/0.010 \n",
      "[2/10][49/52] KL_real/fake: 4.455/4.364 mean_real/fake: -0.007/-0.008 var_real/fake: 0.009/0.010 \n",
      "[2/10][50/52] KL_real/fake: 4.422/4.396 mean_real/fake: -0.005/-0.003 var_real/fake: 0.010/0.010 \n",
      "[2/10][51/52] KL_real/fake: 4.436/4.417 mean_real/fake: -0.003/-0.002 var_real/fake: 0.010/0.010 \n",
      "[3/10][0/52] KL_real/fake: 4.485/4.477 mean_real/fake: -0.001/-0.004 var_real/fake: 0.009/0.009 \n",
      "[3/10][1/52] KL_real/fake: 4.476/4.434 mean_real/fake: -0.007/-0.008 var_real/fake: 0.009/0.010 \n",
      "[3/10][2/52] KL_real/fake: 4.472/4.435 mean_real/fake: -0.009/-0.009 var_real/fake: 0.009/0.010 \n",
      "[3/10][3/52] KL_real/fake: 4.464/4.478 mean_real/fake: -0.008/-0.009 var_real/fake: 0.010/0.010 \n",
      "[3/10][4/52] KL_real/fake: 4.483/4.502 mean_real/fake: -0.009/-0.008 var_real/fake: 0.009/0.010 \n",
      "[3/10][5/52] KL_real/fake: 4.483/4.516 mean_real/fake: -0.005/-0.006 var_real/fake: 0.009/0.009 \n",
      "[3/10][6/52] KL_real/fake: 4.521/4.479 mean_real/fake: -0.007/-0.006 var_real/fake: 0.009/0.010 \n",
      "[3/10][7/52] KL_real/fake: 4.486/4.493 mean_real/fake: -0.008/-0.006 var_real/fake: 0.010/0.010 \n",
      "[3/10][8/52] KL_real/fake: 4.529/4.521 mean_real/fake: -0.004/-0.005 var_real/fake: 0.009/0.010 \n",
      "[3/10][9/52] KL_real/fake: 4.498/4.468 mean_real/fake: -0.005/-0.003 var_real/fake: 0.009/0.010 \n",
      "[3/10][10/52] KL_real/fake: 4.438/4.417 mean_real/fake: -0.005/-0.003 var_real/fake: 0.010/0.010 \n",
      "[3/10][11/52] KL_real/fake: 4.432/4.447 mean_real/fake: -0.005/-0.007 var_real/fake: 0.010/0.010 \n",
      "[3/10][12/52] KL_real/fake: 4.482/4.485 mean_real/fake: -0.007/-0.009 var_real/fake: 0.010/0.010 \n",
      "[3/10][13/52] KL_real/fake: 4.512/4.460 mean_real/fake: -0.009/-0.010 var_real/fake: 0.010/0.010 \n",
      "[3/10][14/52] KL_real/fake: 4.524/4.481 mean_real/fake: -0.010/-0.010 var_real/fake: 0.009/0.010 \n",
      "[3/10][15/52] KL_real/fake: 4.529/4.518 mean_real/fake: -0.010/-0.010 var_real/fake: 0.009/0.010 \n",
      "[3/10][16/52] KL_real/fake: 4.455/4.481 mean_real/fake: -0.010/-0.009 var_real/fake: 0.009/0.010 \n",
      "[3/10][17/52] KL_real/fake: 4.434/4.467 mean_real/fake: -0.009/-0.007 var_real/fake: 0.010/0.010 \n",
      "[3/10][18/52] KL_real/fake: 4.460/4.383 mean_real/fake: -0.005/-0.006 var_real/fake: 0.009/0.010 \n",
      "[3/10][19/52] KL_real/fake: 4.478/4.432 mean_real/fake: -0.008/-0.009 var_real/fake: 0.009/0.010 \n",
      "[3/10][20/52] KL_real/fake: 4.495/4.460 mean_real/fake: -0.007/-0.009 var_real/fake: 0.009/0.010 \n",
      "[3/10][21/52] KL_real/fake: 4.513/4.453 mean_real/fake: -0.007/-0.005 var_real/fake: 0.009/0.009 \n",
      "[3/10][22/52] KL_real/fake: 4.490/4.445 mean_real/fake: -0.005/-0.004 var_real/fake: 0.009/0.010 \n",
      "[3/10][23/52] KL_real/fake: 4.488/4.467 mean_real/fake: -0.007/-0.004 var_real/fake: 0.009/0.010 \n",
      "[3/10][24/52] KL_real/fake: 4.462/4.434 mean_real/fake: -0.007/-0.004 var_real/fake: 0.009/0.010 \n",
      "[3/10][25/52] KL_real/fake: 4.483/4.468 mean_real/fake: -0.004/-0.002 var_real/fake: 0.009/0.009 \n",
      "[3/10][26/52] KL_real/fake: 4.520/4.472 mean_real/fake: -0.006/-0.004 var_real/fake: 0.009/0.010 \n",
      "[3/10][27/52] KL_real/fake: 4.515/4.416 mean_real/fake: -0.005/-0.003 var_real/fake: 0.009/0.010 \n",
      "[3/10][28/52] KL_real/fake: 4.485/4.482 mean_real/fake: -0.003/-0.002 var_real/fake: 0.009/0.009 \n",
      "[3/10][29/52] KL_real/fake: 4.507/4.492 mean_real/fake: -0.006/-0.006 var_real/fake: 0.009/0.009 \n",
      "[3/10][30/52] KL_real/fake: 4.501/4.484 mean_real/fake: -0.010/-0.008 var_real/fake: 0.009/0.009 \n",
      "[3/10][31/52] KL_real/fake: 4.475/4.536 mean_real/fake: -0.007/-0.007 var_real/fake: 0.009/0.009 \n",
      "[3/10][32/52] KL_real/fake: 4.549/4.522 mean_real/fake: -0.006/-0.006 var_real/fake: 0.009/0.009 \n",
      "[3/10][33/52] KL_real/fake: 4.497/4.514 mean_real/fake: -0.006/-0.007 var_real/fake: 0.009/0.009 \n",
      "[3/10][34/52] KL_real/fake: 4.547/4.503 mean_real/fake: -0.007/-0.007 var_real/fake: 0.009/0.009 \n",
      "[3/10][35/52] KL_real/fake: 4.498/4.483 mean_real/fake: -0.007/-0.008 var_real/fake: 0.009/0.010 \n",
      "[3/10][36/52] KL_real/fake: 4.500/4.475 mean_real/fake: -0.007/-0.007 var_real/fake: 0.009/0.010 \n",
      "[3/10][37/52] KL_real/fake: 4.494/4.473 mean_real/fake: -0.007/-0.007 var_real/fake: 0.009/0.010 \n",
      "[3/10][38/52] KL_real/fake: 4.493/4.438 mean_real/fake: -0.008/-0.008 var_real/fake: 0.009/0.010 \n",
      "[3/10][39/52] KL_real/fake: 4.452/4.432 mean_real/fake: -0.005/-0.005 var_real/fake: 0.009/0.010 \n",
      "[3/10][40/52] KL_real/fake: 4.467/4.443 mean_real/fake: -0.006/-0.003 var_real/fake: 0.009/0.010 \n",
      "[3/10][41/52] KL_real/fake: 4.499/4.498 mean_real/fake: -0.003/-0.004 var_real/fake: 0.009/0.010 \n",
      "[3/10][42/52] KL_real/fake: 4.539/4.564 mean_real/fake: -0.002/-0.007 var_real/fake: 0.009/0.009 \n",
      "[3/10][43/52] KL_real/fake: 4.540/4.514 mean_real/fake: -0.006/-0.008 var_real/fake: 0.009/0.009 \n",
      "[3/10][44/52] KL_real/fake: 4.559/4.465 mean_real/fake: -0.008/-0.008 var_real/fake: 0.009/0.010 \n",
      "[3/10][45/52] KL_real/fake: 4.533/4.529 mean_real/fake: -0.011/-0.008 var_real/fake: 0.009/0.009 \n",
      "[3/10][46/52] KL_real/fake: 4.539/4.525 mean_real/fake: -0.007/-0.007 var_real/fake: 0.009/0.009 \n",
      "[3/10][47/52] KL_real/fake: 4.484/4.497 mean_real/fake: -0.005/-0.006 var_real/fake: 0.009/0.009 \n",
      "[3/10][48/52] KL_real/fake: 4.481/4.472 mean_real/fake: -0.006/-0.005 var_real/fake: 0.009/0.010 \n",
      "[3/10][49/52] KL_real/fake: 4.457/4.470 mean_real/fake: -0.007/-0.006 var_real/fake: 0.009/0.010 \n",
      "[3/10][50/52] KL_real/fake: 4.468/4.448 mean_real/fake: -0.004/-0.004 var_real/fake: 0.009/0.010 \n",
      "[3/10][51/52] KL_real/fake: 4.440/4.421 mean_real/fake: -0.005/-0.002 var_real/fake: 0.009/0.009 \n",
      "[4/10][0/52] KL_real/fake: 4.429/4.392 mean_real/fake: -0.003/-0.003 var_real/fake: 0.009/0.010 \n",
      "[4/10][1/52] KL_real/fake: 4.457/4.391 mean_real/fake: -0.003/-0.003 var_real/fake: 0.009/0.010 \n",
      "[4/10][2/52] KL_real/fake: 4.500/4.472 mean_real/fake: -0.004/-0.004 var_real/fake: 0.009/0.009 \n",
      "[4/10][3/52] KL_real/fake: 4.496/4.463 mean_real/fake: -0.003/-0.006 var_real/fake: 0.009/0.010 \n",
      "[4/10][4/52] KL_real/fake: 4.527/4.508 mean_real/fake: -0.003/-0.007 var_real/fake: 0.009/0.010 \n",
      "[4/10][5/52] KL_real/fake: 4.536/4.520 mean_real/fake: -0.006/-0.008 var_real/fake: 0.009/0.009 \n",
      "[4/10][6/52] KL_real/fake: 4.576/4.547 mean_real/fake: -0.007/-0.007 var_real/fake: 0.009/0.009 \n",
      "[4/10][7/52] KL_real/fake: 4.533/4.549 mean_real/fake: -0.005/-0.005 var_real/fake: 0.009/0.009 \n",
      "[4/10][8/52] KL_real/fake: 4.498/4.467 mean_real/fake: -0.004/-0.004 var_real/fake: 0.009/0.010 \n",
      "[4/10][9/52] KL_real/fake: 4.476/4.431 mean_real/fake: -0.006/-0.006 var_real/fake: 0.010/0.010 \n",
      "[4/10][10/52] KL_real/fake: 4.482/4.375 mean_real/fake: -0.007/-0.004 var_real/fake: 0.009/0.010 \n",
      "[4/10][11/52] KL_real/fake: 4.440/4.392 mean_real/fake: -0.007/-0.006 var_real/fake: 0.010/0.010 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/10][12/52] KL_real/fake: 4.502/4.445 mean_real/fake: -0.007/-0.008 var_real/fake: 0.009/0.010 \n",
      "[4/10][13/52] KL_real/fake: 4.471/4.413 mean_real/fake: -0.013/-0.010 var_real/fake: 0.009/0.010 \n",
      "[4/10][14/52] KL_real/fake: 4.448/4.421 mean_real/fake: -0.013/-0.010 var_real/fake: 0.010/0.010 \n",
      "[4/10][15/52] KL_real/fake: 4.465/4.410 mean_real/fake: -0.011/-0.010 var_real/fake: 0.009/0.010 \n",
      "[4/10][16/52] KL_real/fake: 4.441/4.387 mean_real/fake: -0.011/-0.010 var_real/fake: 0.010/0.010 \n",
      "[4/10][17/52] KL_real/fake: 4.452/4.436 mean_real/fake: -0.010/-0.009 var_real/fake: 0.010/0.010 \n",
      "[4/10][18/52] KL_real/fake: 4.456/4.431 mean_real/fake: -0.008/-0.006 var_real/fake: 0.009/0.010 \n",
      "[4/10][19/52] KL_real/fake: 4.439/4.479 mean_real/fake: -0.005/-0.006 var_real/fake: 0.010/0.010 \n",
      "[4/10][20/52] KL_real/fake: 4.457/4.439 mean_real/fake: -0.006/-0.007 var_real/fake: 0.009/0.010 \n",
      "[4/10][21/52] KL_real/fake: 4.432/4.434 mean_real/fake: -0.003/-0.006 var_real/fake: 0.009/0.010 \n",
      "[4/10][22/52] KL_real/fake: 4.470/4.452 mean_real/fake: -0.004/-0.004 var_real/fake: 0.010/0.010 \n",
      "[4/10][23/52] KL_real/fake: 4.472/4.456 mean_real/fake: -0.008/-0.006 var_real/fake: 0.010/0.010 \n",
      "[4/10][24/52] KL_real/fake: 4.524/4.448 mean_real/fake: -0.006/-0.008 var_real/fake: 0.010/0.010 \n",
      "[4/10][25/52] KL_real/fake: 4.530/4.476 mean_real/fake: -0.006/-0.009 var_real/fake: 0.010/0.010 \n",
      "[4/10][26/52] KL_real/fake: 4.516/4.512 mean_real/fake: -0.007/-0.008 var_real/fake: 0.009/0.010 \n",
      "[4/10][27/52] KL_real/fake: 4.452/4.496 mean_real/fake: -0.006/-0.009 var_real/fake: 0.010/0.010 \n",
      "[4/10][28/52] KL_real/fake: 4.493/4.477 mean_real/fake: -0.009/-0.008 var_real/fake: 0.009/0.010 \n",
      "[4/10][29/52] KL_real/fake: 4.440/4.470 mean_real/fake: -0.009/-0.009 var_real/fake: 0.010/0.010 \n",
      "[4/10][30/52] KL_real/fake: 4.471/4.486 mean_real/fake: -0.009/-0.006 var_real/fake: 0.009/0.009 \n",
      "[4/10][31/52] KL_real/fake: 4.485/4.475 mean_real/fake: -0.006/-0.005 var_real/fake: 0.009/0.009 \n",
      "[4/10][32/52] KL_real/fake: 4.486/4.453 mean_real/fake: -0.008/-0.008 var_real/fake: 0.009/0.010 \n",
      "[4/10][33/52] KL_real/fake: 4.414/4.403 mean_real/fake: -0.007/-0.006 var_real/fake: 0.010/0.010 \n",
      "[4/10][34/52] KL_real/fake: 4.442/4.383 mean_real/fake: -0.007/-0.008 var_real/fake: 0.010/0.010 \n",
      "[4/10][35/52] KL_real/fake: 4.363/4.354 mean_real/fake: -0.008/-0.008 var_real/fake: 0.010/0.010 \n",
      "[4/10][36/52] KL_real/fake: 4.374/4.356 mean_real/fake: -0.011/-0.006 var_real/fake: 0.010/0.010 \n",
      "[4/10][37/52] KL_real/fake: 4.409/4.389 mean_real/fake: -0.009/-0.009 var_real/fake: 0.010/0.010 \n",
      "[4/10][38/52] KL_real/fake: 4.432/4.419 mean_real/fake: -0.009/-0.006 var_real/fake: 0.010/0.010 \n",
      "[4/10][39/52] KL_real/fake: 4.413/4.391 mean_real/fake: -0.006/-0.002 var_real/fake: 0.010/0.010 \n",
      "[4/10][40/52] KL_real/fake: 4.424/4.398 mean_real/fake: -0.002/-0.002 var_real/fake: 0.010/0.010 \n",
      "[4/10][41/52] KL_real/fake: 4.398/4.377 mean_real/fake: -0.003/-0.006 var_real/fake: 0.010/0.010 \n",
      "[4/10][42/52] KL_real/fake: 4.398/4.391 mean_real/fake: -0.004/-0.005 var_real/fake: 0.010/0.010 \n",
      "[4/10][43/52] KL_real/fake: 4.412/4.409 mean_real/fake: -0.005/-0.004 var_real/fake: 0.010/0.010 \n",
      "[4/10][44/52] KL_real/fake: 4.442/4.411 mean_real/fake: -0.002/-0.004 var_real/fake: 0.010/0.010 \n",
      "[4/10][45/52] KL_real/fake: 4.440/4.447 mean_real/fake: -0.005/-0.005 var_real/fake: 0.010/0.010 \n",
      "[4/10][46/52] KL_real/fake: 4.479/4.468 mean_real/fake: -0.007/-0.006 var_real/fake: 0.009/0.010 \n",
      "[4/10][47/52] KL_real/fake: 4.532/4.510 mean_real/fake: -0.006/-0.006 var_real/fake: 0.009/0.010 \n",
      "[4/10][48/52] KL_real/fake: 4.512/4.516 mean_real/fake: -0.004/-0.005 var_real/fake: 0.009/0.010 \n",
      "[4/10][49/52] KL_real/fake: 4.502/4.442 mean_real/fake: -0.007/-0.005 var_real/fake: 0.009/0.009 \n",
      "[4/10][50/52] KL_real/fake: 4.447/4.434 mean_real/fake: -0.006/-0.003 var_real/fake: 0.010/0.010 \n",
      "[4/10][51/52] KL_real/fake: 4.452/4.392 mean_real/fake: -0.003/-0.001 var_real/fake: 0.010/0.010 \n",
      "[5/10][0/52] KL_real/fake: 4.411/4.359 mean_real/fake: -0.002/-0.002 var_real/fake: 0.010/0.010 \n",
      "[5/10][1/52] KL_real/fake: 4.377/4.377 mean_real/fake: -0.002/-0.001 var_real/fake: 0.010/0.010 \n",
      "[5/10][2/52] KL_real/fake: 4.400/4.366 mean_real/fake: -0.005/-0.004 var_real/fake: 0.010/0.010 \n",
      "[5/10][3/52] KL_real/fake: 4.448/4.400 mean_real/fake: -0.005/-0.005 var_real/fake: 0.009/0.010 \n",
      "[5/10][4/52] KL_real/fake: 4.455/4.408 mean_real/fake: -0.003/-0.004 var_real/fake: 0.009/0.010 \n",
      "[5/10][5/52] KL_real/fake: 4.445/4.399 mean_real/fake: -0.004/-0.003 var_real/fake: 0.010/0.010 \n",
      "[5/10][6/52] KL_real/fake: 4.416/4.411 mean_real/fake: -0.003/-0.004 var_real/fake: 0.010/0.010 \n",
      "[5/10][7/52] KL_real/fake: 4.438/4.426 mean_real/fake: -0.001/-0.005 var_real/fake: 0.010/0.010 \n",
      "[5/10][8/52] KL_real/fake: 4.436/4.404 mean_real/fake: -0.004/-0.004 var_real/fake: 0.010/0.010 \n",
      "[5/10][9/52] KL_real/fake: 4.417/4.412 mean_real/fake: -0.006/-0.006 var_real/fake: 0.010/0.010 \n",
      "[5/10][10/52] KL_real/fake: 4.429/4.389 mean_real/fake: -0.007/-0.006 var_real/fake: 0.010/0.010 \n",
      "[5/10][11/52] KL_real/fake: 4.423/4.425 mean_real/fake: -0.007/-0.003 var_real/fake: 0.009/0.010 \n",
      "[5/10][12/52] KL_real/fake: 4.385/4.333 mean_real/fake: -0.005/-0.002 var_real/fake: 0.010/0.010 \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 210, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\nAttributeError: 'NoneType' object has no attribute 'next'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-26688e4d47b7>\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\nAttributeError: 'NoneType' object has no attribute 'next'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7b7a2d1d9444>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mpopulate_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0;31m# e(X)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-a39c6fa89e5b>\u001b[0m in \u001b[0;36mpopulate_x\u001b[0;34m(x, dataloader)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mFills\u001b[0m \u001b[0minput\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     '''\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mreal_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_cpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_cpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-26688e4d47b7>\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# Reached end of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 210, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 196, in __next__\n    return self._process_next_batch(batch)\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 230, in _process_next_batch\n    raise batch.exc_type(batch.exc_msg)\nAttributeError: Traceback (most recent call last):\n  File \"<ipython-input-5-26688e4d47b7>\", line 142, in next\n    data = self.data_iter.next()\nAttributeError: 'NoneType' object has no attribute 'next'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 42, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-26688e4d47b7>\", line 35, in __getitem__\n    target = input.copy()\nAttributeError: 'NoneType' object has no attribute 'copy'\n"
     ]
    }
   ],
   "source": [
    "stats = {}\n",
    "for epoch in range(start_epoch, nepoch):\n",
    "\n",
    "    # Adjust learning rate\n",
    "    adjust_lr(epoch)\n",
    "\n",
    "    for i in range(len(dataloader['train'])):\n",
    "\n",
    "        # ---------------------------\n",
    "        #        Optimize over e\n",
    "        # ---------------------------\n",
    "\n",
    "        for e_iter in range(updates['e']['num_updates']):\n",
    "            e_losses = []\n",
    "            netE.zero_grad()\n",
    "\n",
    "            # X\n",
    "            populate_x(x, dataloader['train'])\n",
    "            # e(X)\n",
    "            ex = netE(x)\n",
    "\n",
    "            # KL_real: - \\Delta( e(X) , Z ) -> max_e\n",
    "            KL_real = KL_minimizer(ex)\n",
    "            e_losses.append(KL_real * updates['e']['KL_real'])\n",
    "\n",
    "            if updates['e']['match_x'] != 0:\n",
    "                # g(e(X))\n",
    "                gex = netG(ex)\n",
    "\n",
    "                # match_x: E_x||g(e(x)) - x|| -> min_e\n",
    "                err = match(gex, x, match_x)\n",
    "                e_losses.append(err * updates['e']['match_x'])\n",
    "\n",
    "            # Save some stats\n",
    "            stats['real_mean'] = KL_minimizer.samples_mean.data.mean()\n",
    "            stats['real_var'] = KL_minimizer.samples_var.data.mean()\n",
    "            stats['KL_real'] = KL_real.data[0]\n",
    "\n",
    "            # ================================================\n",
    "\n",
    "            # Z\n",
    "            populate_z(z)\n",
    "            # g(Z)\n",
    "            fake = netG(z).detach()\n",
    "            # e(g(Z))\n",
    "            egz = netE(fake)\n",
    "\n",
    "            # KL_fake: \\Delta( e(g(Z)) , Z ) -> max_e\n",
    "            KL_fake = KL_maximizer(egz)\n",
    "            e_losses.append(KL_fake * updates['e']['KL_fake'])\n",
    "\n",
    "            if updates['e']['match_z'] != 0:\n",
    "                # match_z: E_z||e(g(z)) - z|| -> min_e\n",
    "                err = match(egz, z, match_z)\n",
    "                e_losses.append(err * updates['e']['match_z'])\n",
    "\n",
    "            # Save some stats\n",
    "            stats['fake_mean'] = KL_maximizer.samples_mean.data.mean()\n",
    "            stats['fake_var'] = KL_maximizer.samples_var.data.mean()\n",
    "            stats['KL_fake'] = -KL_fake.data[0]\n",
    "\n",
    "            # Update e\n",
    "            sum(e_losses).backward()\n",
    "            optimizerD.step()\n",
    "\n",
    "        # ---------------------------\n",
    "        #        Minimize over g\n",
    "        # ---------------------------\n",
    "\n",
    "        for g_iter in range(updates['g']['num_updates']):\n",
    "            g_losses = []\n",
    "            netG.zero_grad()\n",
    "\n",
    "            # Z\n",
    "            populate_z(z)\n",
    "            # g(Z)\n",
    "            fake = netG(z)\n",
    "            # e(g(Z))\n",
    "            egz = netE(fake)\n",
    "\n",
    "            # KL_fake: \\Delta( e(g(Z)) , Z ) -> min_g\n",
    "            KL_fake_g = KL_minimizer(egz)\n",
    "            g_losses.append(KL_fake_g * updates['g']['KL_fake'])\n",
    "\n",
    "            if updates['g']['match_z'] != 0:\n",
    "                # match_z: E_z||e(g(z)) - z|| -> min_g\n",
    "                err = match(egz, z, match_z)\n",
    "                err = err * updates['g']['match_z']\n",
    "                g_losses.append(err)\n",
    "\n",
    "            # ==================================\n",
    "\n",
    "            if updates['g']['match_x'] != 0:\n",
    "                # X\n",
    "                populate_x(x, dataloader['train'])\n",
    "                # e(X)\n",
    "                ex = netE(x)\n",
    "\n",
    "                # g(e(X))\n",
    "                gex = netG(ex)\n",
    "\n",
    "                # match_x: E_x||g(e(x)) - x|| -> min_g\n",
    "                err = match(gex, x, match_x)\n",
    "                err = err * updates['g']['match_x']\n",
    "                g_losses.append(err)\n",
    "\n",
    "            # Step g\n",
    "            sum(g_losses).backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "        print('[{epoch}/{nepoch}][{iter}/{niter}] '\n",
    "              'KL_real/fake: {KL_real:.3f}/{KL_fake:.3f} '\n",
    "              'mean_real/fake: {real_mean:.3f}/{fake_mean:.3f} '\n",
    "              'var_real/fake: {real_var:.3f}/{fake_var:.3f} '\n",
    "              ''.format(epoch=epoch,\n",
    "                        nepoch=nepoch,\n",
    "                        iter=i,\n",
    "                        niter=len(dataloader['train']),\n",
    "                        **stats))\n",
    "\n",
    "#         if save_every_b:\n",
    "#             if i % save_every_b == 0: save_images(epoch)\n",
    "\n",
    "            \n",
    "        # If an epoch takes long time, dump intermediate\n",
    "        if dataset in ['lsun', 'imagenet'] and (i % 5000 == 0):\n",
    "            torch.save(netG, '%s/netG_epoch_%d_it_%d.pth' %\n",
    "                       (save_dir, epoch, i))\n",
    "            torch.save(netE, '%s/netE_epoch_%d_it_%d.pth' %\n",
    "                       (save_dir, epoch, i))\n",
    "    \n",
    "#     if epoch % save_every_e == 0: save_images(epoch)\n",
    "    # do checkpointing\n",
    "    torch.save(netG, '%s/netG_epoch_%d.pth' % (save_dir, epoch))\n",
    "    torch.save(netE, '%s/netE_epoch_%d.pth' % (save_dir, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(real_cpu.shape); print(real_cpu[:64].shape); print(real_cpu[0].shape)\n",
    "# # vutils.save_image(real_cpu[:64] / 2 + 0.5, save_path)\n",
    "# plt.imshow(real_cpu[0].numpy().reshape((64,64,3))) #[[2, 1, 0],:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# e_updates = '1;KL_fake:1,KL_real:1,match_z:0,match_x:10' \n",
    "# g_updates = '3;KL_fake:1,match_z:1000,match_x:0'\n",
    "\n",
    "# 10 * 50 * 64 - 32000 \n",
    "# 10 * 25 * 128\n",
    "# 10 * 13 * 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_every_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
