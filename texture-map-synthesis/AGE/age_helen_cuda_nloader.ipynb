{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--g_updates'], dest='g_updates', nargs=None, const=None, default='2;KL_fake:1,match_z:1,match_x:0', type=None, choices=None, help='Update plan for generator <number of updates>;[<term:weight>]', metavar=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../utils')\n",
    "\n",
    "import libraries\n",
    "# from libraries import *\n",
    "import utils_general\n",
    "from utils_general import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#########\n",
    "\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', required=True,\n",
    "                    help='cifar10 | lsun | imagenet | folder | lfw ')\n",
    "parser.add_argument('--dataroot', type=str, help='path to dataset')\n",
    "parser.add_argument('--workers', type=int,\n",
    "                    help='number of data loading workers', default=8)\n",
    "parser.add_argument('--batch_size', type=int,\n",
    "                    default=64, help='batch size')\n",
    "parser.add_argument('--image_size', type=int, default=32,\n",
    "                    help='the resolution of the input image to network')\n",
    "parser.add_argument('--nz', type=int, default=100,\n",
    "                    help='size of the latent z vector')\n",
    "parser.add_argument('--ngf', type=int, default=64)\n",
    "parser.add_argument('--ndf', type=int, default=64)\n",
    "parser.add_argument('--nc', type=int)\n",
    "\n",
    "parser.add_argument('--nepoch', type=int, default=25,\n",
    "                    help='number of epochs to train for')\n",
    "parser.add_argument('--lr', type=float, default=0.0002,\n",
    "                    help='learning rate, default=0.0002')\n",
    "parser.add_argument('--beta1', type=float, default=0.5,\n",
    "                    help='beta1 for adam. default=0.5')\n",
    "parser.add_argument('--cpu', action='store_true',\n",
    "                    help='use CPU instead of GPU')\n",
    "parser.add_argument('--ngpu', type=int, default=1,\n",
    "                    help='number of GPUs to use')\n",
    "\n",
    "parser.add_argument('--netG', default='',\n",
    "                    help=\"path to netG config\")\n",
    "parser.add_argument('--netE', default='',\n",
    "                    help=\"path to netE config\")\n",
    "parser.add_argument('--netG_chp', default='',\n",
    "                    help=\"path to netG (to continue training)\")\n",
    "parser.add_argument('--netE_chp', default='',\n",
    "                    help=\"path to netE (to continue training)\")\n",
    "\n",
    "parser.add_argument('--save_dir', default='.',\n",
    "                    help='folder to output images and model checkpoints')\n",
    "parser.add_argument('--criterion', default='param',\n",
    "                    help='param|nonparam, How to estimate KL')\n",
    "parser.add_argument('--KL', default='qp', help='pq|qp')\n",
    "parser.add_argument('--noise', default='sphere', help='normal|sphere')\n",
    "parser.add_argument('--match_z', default='cos', help='none|L1|L2|cos')\n",
    "parser.add_argument('--match_x', default='L1', help='none|L1|L2|cos')\n",
    "\n",
    "parser.add_argument('--drop_lr', default=5, type=int, help='')\n",
    "parser.add_argument('--save_every', default=50, type=int, help='')\n",
    "\n",
    "parser.add_argument('--manual_seed', type=int, default=123, help='manual seed')\n",
    "parser.add_argument('--start_epoch', type=int, default=0, help='epoch number to start with')\n",
    "\n",
    "parser.add_argument(\n",
    "    '--e_updates', default=\"1;KL_fake:1,KL_real:1,match_z:0,match_x:0\",\n",
    "    help='Update plan for encoder <number of updates>;[<term:weight>]'\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    '--g_updates', default=\"2;KL_fake:1,match_z:1,match_x:0\",\n",
    "    help='Update plan for generator <number of updates>;[<term:weight>]'\n",
    ")\n",
    "\n",
    "# opt = parser.parse_args()\n",
    "\n",
    "# python age.py \n",
    "# --dataset celeba \n",
    "# --dataroot <data_root> \n",
    "# --image_size 64 \n",
    "# --save_dir <save_dir> \n",
    "# --lr 0.0002 \n",
    "# --nz 64 \n",
    "# --batch_size 64 \n",
    "# --netG dcgan64px \n",
    "# --netE dcgan64px \n",
    "# --nepoch 5 \n",
    "# --drop_lr 5 \n",
    "# --e_updates '1;KL_fake:1,KL_real:1,match_z:0,match_x:10' \n",
    "# --g_updates '3;KL_fake:1,match_z:1000,match_x:0'\n",
    "\n",
    "# python age.py \n",
    "# --dataset celeba \n",
    "# --dataroot <data_root> \n",
    "# --image_size 64 \n",
    "# --save_dir <save_dir> \n",
    "# --start_epoch 5 \n",
    "# --lr 0.0002 \n",
    "# --nz 64 \n",
    "# --batch_size 256 \n",
    "# --netG dcgan64px \n",
    "# --netE dcgan64px \n",
    "# --nepoch 6 \n",
    "# --drop_lr 5   \n",
    "# --e_updates '1;KL_fake:1,KL_real:1,match_z:0,match_x:15' \n",
    "# --g_updates '3;KL_fake:1,match_z:1000,match_x:0' \n",
    "# --netE_chp  <save_dir>/netE_epoch_5.pth \n",
    "# --netG_chp <save_dir>/netG_epoch_5.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svmem(total=64388890624, available=8367689728, percent=87.0, used=17162006528, free=7234359296, active=17450283008, inactive=38768807936, buffers=17756160, cached=39974768640, shared=38346809344)\n"
     ]
    }
   ],
   "source": [
    "# print(get_available_gpus())\n",
    "print(psutil.virtual_memory())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "import importlib\n",
    "# from .dataset import FolderWithImages\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory was not created.\n"
     ]
    }
   ],
   "source": [
    "# setup function @utils.py\n",
    "\n",
    "cuda = True # not opt.cpu\n",
    "torch.set_num_threads(4)\n",
    "dataset = 'helen'\n",
    "save_dir = 'output/helen'\n",
    "try:\n",
    "    os.makedirs(save_dir)\n",
    "except OSError:\n",
    "    print('Directory was not created.')\n",
    "\n",
    "manual_seed = random.randint(1, 10000)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "if torch.cuda.is_available() and not cuda:\n",
    "    print(\"WARNING: You have a CUDA device,\"\n",
    "            \"so you should probably run with --cuda\")\n",
    "\n",
    "e_updates = '1;KL_fake:1,KL_real:1,match_z:0,match_x:10' \n",
    "g_updates = '3;KL_fake:1,match_z:1000,match_x:0'\n",
    "    \n",
    "updates = {'e': {}, 'g': {}}\n",
    "updates['e']['num_updates'] = int(e_updates.split(';')[0])\n",
    "updates['e'].update({x.split(':')[0]: float(x.split(':')[1]) \n",
    "                     for x in e_updates.split(';')[1].split(',')})\n",
    "\n",
    "updates['g']['num_updates'] = int(g_updates.split(';')[0])\n",
    "updates['g'].update({x.split(':')[0]: float(x.split(':')[1]) \n",
    "                     for x in g_updates.split(';')[1].split(',')})\n",
    "\n",
    "\n",
    "###################\n",
    "\n",
    "image_size = 64 # 512\n",
    "batch_size = 64 # 64\n",
    "workers = 8\n",
    "shuffle = True\n",
    "drop_last = True\n",
    "train = True\n",
    "\n",
    "nc = 3\n",
    "nz = 64 #100 #'size of the latent z vector')\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "ngpu = 1 # 'number of GPUs to use')\n",
    "pin_memory = False # True | If ``True``, the data loader will copy tensors into CUDA pinned memory before returning them.\n",
    "\n",
    "noise = 'sphere' #help='normal|sphere')\n",
    "\n",
    "netG = 'dcgan64px' \n",
    "netE = 'dcgan64px' \n",
    "\n",
    "netG_chp = '' # \"path to netG (to continue training)\"\n",
    "netE_chp = '' # \"path to netE (to continue training)\"\n",
    "\n",
    "lr = 0.0002 \n",
    "drop_lr = 200\n",
    "beta1 = 0.5 # help='beta1 for adam. default=0.5'\n",
    "criterion = 'param'# help='param|nonparam, How to estimate KL'\n",
    "KL ='qp' # help='pq|qp'\n",
    "match_z = 'cos' # help='none|L1|L2|cos'\n",
    "match_x = 'L1' # help='none|L1|L2|cos'\n",
    "\n",
    "start_epoch = 0\n",
    "nepoch = 1000\n",
    "\n",
    "save_every_e = 100\n",
    "save_every_b = None\n",
    "dataroot = '../data/isomapsr'\n",
    "\n",
    "# --lr 0.0002 \n",
    "# --nz 64 \n",
    "# --batch_size 64 \n",
    "# --netG dcgan64px \n",
    "# --netE dcgan64px \n",
    "# --nepoch 5 \n",
    "# --drop_lr 5 \n",
    "# --e_updates '1;KL_fake:1,KL_real:1,match_z:0,match_x:10' \n",
    "# --g_updates '3;KL_fake:1,match_z:1000,match_x:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py:156: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "import importlib\n",
    "import random\n",
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "from PIL import Image\n",
    "\n",
    "##\n",
    "import torch.utils.data as data\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from PIL import Image\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in [\".png\", \".jpg\", \".jpeg\"])\n",
    "\n",
    "def load_img(filepath):\n",
    "    img = cv2.imread(filepath) #, cv2.IMREAD_UNCHANGED)\n",
    "#     img = Image.open(filepath).convert('RGB')\n",
    "    return img\n",
    "\n",
    "class FolderWithImages(data.Dataset):\n",
    "    def __init__(self, root, input_transform=None, target_transform=None):\n",
    "        super(FolderWithImages, self).__init__()\n",
    "        self.image_filenames = [join(root, x)\n",
    "                                for x in listdir(root) if is_image_file(x.lower())]\n",
    "\n",
    "        self.input_transform = input_transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input = load_img(self.image_filenames[index])\n",
    "        target = input.copy()\n",
    "        if self.input_transform:\n",
    "            input = self.input_transform(input)\n",
    "        if self.target_transform:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return input, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "    \n",
    "##\n",
    "\n",
    "def setup_dataset(dataset, dataroot, train=True, shuffle=True, drop_last=True):\n",
    "    '''\n",
    "    Setups dataset.\n",
    "    '''\n",
    "    # Usual transform\n",
    "    t = transforms.Compose([\n",
    "        transforms.Scale([image_size, image_size]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "    if dataset in ['imagenet', 'folder', 'lfw']:\n",
    "        imdir = 'train' if train else 'val'\n",
    "        dataroot = os.path.join(dataroot, imdir)\n",
    "\n",
    "        dataset = dset.ImageFolder(root=dataroot, transform=t)\n",
    "    elif dataset == 'lsun':\n",
    "        dataset = dset.LSUN(db_path=dataroot,\n",
    "                            classes=['bedroom_train'],\n",
    "                            train=train,\n",
    "                            transform=t)\n",
    "    elif dataset == 'cifar10':\n",
    "        dataset = dset.CIFAR10(root='data/raw/cifar10',\n",
    "                               download=True,\n",
    "                               train=train,\n",
    "                               transform=t\n",
    "                               )\n",
    "    elif dataset == 'mnist':\n",
    "        dataset = dset.MNIST(root='data/raw/mnist',\n",
    "                             download=True,\n",
    "                             train=train,\n",
    "                             transform=t\n",
    "                             )\n",
    "    elif dataset == 'svhn':\n",
    "        dataset = dset.SVHN(root='data/raw/svhn',\n",
    "                            download=True,\n",
    "                            train=train,\n",
    "                            transform=t)\n",
    "    elif dataset == 'celeba':\n",
    "        imdir = 'train' if train else 'val'\n",
    "        dataroot = os.path.join(dataroot, imdir)\n",
    "\n",
    "        dataset = FolderWithImages(root=dataroot,\n",
    "                                   input_transform=transforms.Compose([\n",
    "                                       ALICropAndScale(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(\n",
    "                                           (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                   ]),\n",
    "                                   target_transform=transforms.ToTensor()\n",
    "                                   )\n",
    "    elif dataset == 'helen':\n",
    "        imdir = 'train' if train else 'val'\n",
    "        dataroot = os.path.join(dataroot, imdir)\n",
    "\n",
    "        dataset = FolderWithImages(root=dataroot,\n",
    "                                   input_transform=transforms.Compose([\n",
    "                                       Scale(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(\n",
    "                                           (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                   ]),\n",
    "                                   target_transform=transforms.ToTensor()\n",
    "                                   )\n",
    "        \n",
    "    else:\n",
    "        assert False, 'Wrong dataset name.'\n",
    "\n",
    "    assert len(dataset) > 0, 'No images found, check your paths.'\n",
    "\n",
    "    # Shuffle and drop last when training\n",
    "    dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=shuffle,\n",
    "                                             num_workers=int(workers),\n",
    "                                             pin_memory=pin_memory,\n",
    "                                             drop_last=drop_last)\n",
    "#     print(len(dataloader))\n",
    "#     for i in dataloader: print(i[0].shape, i[1].shape)\n",
    "        \n",
    "    return InfiniteDataLoader(dataloader)\n",
    "#     return dataloader\n",
    "\n",
    "class InfiniteDataLoader(object):\n",
    "    \"\"\"docstring for InfiniteDataLoader\"\"\"\n",
    "\n",
    "    def __init__(self, dataloader):\n",
    "        super(InfiniteDataLoader, self).__init__()\n",
    "        self.dataloader = dataloader\n",
    "        self.data_iter = None\n",
    "\n",
    "    def next(self):\n",
    "        try:\n",
    "            data = self.data_iter.next()\n",
    "        except Exception:\n",
    "            # Reached end of the dataset\n",
    "            self.data_iter = iter(self.dataloader)\n",
    "            data = self.data_iter.next()\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataloader)\n",
    "\n",
    "class ALICropAndScale(object):\n",
    "    def __call__(self, img):\n",
    "        return img.resize((64, 78), Image.ANTIALIAS).crop((0, 7, 64, 64 + 7))\n",
    "    \n",
    "class Scale(object):\n",
    "    def __call__(self, img):\n",
    "        img = cv2.resize(img, (image_size, image_size), cv2.INTER_AREA)\n",
    "        return img \n",
    "\n",
    "# cv::INTER_AREA interpolation, whereas to\n",
    "# .   enlarge an image, it will generally look best with cv::INTER_CUBIC (slow) or cv::INTER_LINEAR\n",
    "# .   (faster but still looks OK).\n",
    "    \n",
    "# Setup dataset\n",
    "dataloader = dict(train=setup_dataset(dataset, dataroot, train=True),\n",
    "                  val=setup_dataset(dataset, dataroot, train=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "0 torch.Size([256, 3, 256, 256])\n",
      "1 torch.Size([256, 3, 256, 256])\n",
      "2 torch.Size([256, 3, 256, 256])\n",
      "3 torch.Size([256, 3, 256, 256])\n",
      "4 torch.Size([256, 3, 256, 256])\n",
      "5 torch.Size([256, 3, 256, 256])\n",
      "6 torch.Size([256, 3, 256, 256])\n",
      "7 torch.Size([256, 3, 256, 256])\n",
      "8 torch.Size([256, 3, 256, 256])\n",
      "9 torch.Size([256, 3, 256, 256])\n",
      "10 torch.Size([256, 3, 256, 256])\n",
      "11 torch.Size([256, 3, 256, 256])\n",
      "12 torch.Size([256, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "print(len(dataloader['train']))\n",
    "# for i, j in dataloader['train']:\n",
    "#     print(i.shape, j.shape)\n",
    "\n",
    "\n",
    "# def populate_x(x, dataloader):\n",
    "#     '''\n",
    "#     Fills input variable `x` with data generated with dataloader\n",
    "#     '''\n",
    "#     real_cpu, _ = dataloader.next()\n",
    "#     x.data.resize_(real_cpu.size()).copy_(real_cpu)\n",
    "\n",
    "for i in range(len(dataloader['train'])):\n",
    "    print(i, dataloader['train'].next()[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(x, dim=0):\n",
    "    '''\n",
    "    Projects points to a sphere.\n",
    "    '''\n",
    "    return x.div(x.norm(2, dim=dim).expand_as(x))\n",
    "\n",
    "def normalize_(x, dim=0):\n",
    "    '''\n",
    "    Projects points to a sphere inplace.\n",
    "    '''\n",
    "    x.div_(x.norm(2, dim=dim).expand_as(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator\n",
      " _netG_Base(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d (64, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): ConvTranspose2d (512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): ConvTranspose2d (256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (8): ReLU(inplace)\n",
      "    (9): ConvTranspose2d (128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (11): ReLU(inplace)\n",
      "    (12): ConvTranspose2d (64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n",
      "Encoder\n",
      " _netE_Base(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d (3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(0.2, inplace)\n",
      "    (2): Conv2d (64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (4): LeakyReLU(0.2, inplace)\n",
      "    (5): Conv2d (128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (7): LeakyReLU(0.2, inplace)\n",
      "    (8): Conv2d (256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (10): LeakyReLU(0.2, inplace)\n",
      "    (11): Conv2d (512, 64, kernel_size=(4, 4), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def weights_init(m):\n",
    "    '''\n",
    "    Custom weights initialization called on netG and netE\n",
    "    '''\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "class _netE_Base(nn.Module):\n",
    "    def __init__(self, main):\n",
    "        super(_netE_Base, self).__init__()\n",
    "        self.noise = noise\n",
    "        self.ngpu = ngpu\n",
    "        self.main = main\n",
    "\n",
    "    def forward(self, input):\n",
    "        gpu_ids = None\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 0:\n",
    "            gpu_ids = range(self.ngpu)\n",
    "            output = nn.parallel.data_parallel(self.main, input, gpu_ids)\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        if self.noise == 'sphere':\n",
    "            output = normalize(output)\n",
    "        return output\n",
    "    \n",
    "class _netG_Base(nn.Module):\n",
    "    def __init__(self, main):\n",
    "        super(_netG_Base, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = main\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        # Check input is either (B,C,1,1) or (B,C)\n",
    "        assert input.nelement() == input.size(0) * input.size(1), 'wtf'\n",
    "        input = input.view(input.size(0), input.size(1), 1, 1)\n",
    "\n",
    "        gpu_ids = None\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 0:\n",
    "            gpu_ids = range(self.ngpu)\n",
    "            return nn.parallel.data_parallel(self.main, input, gpu_ids)\n",
    "        else:\n",
    "            return self.main(input)\n",
    "\n",
    "\n",
    "def _netE():\n",
    "#     ndf = opt.ndf\n",
    "#     nc = opt.nc\n",
    "#     nz = opt.nz\n",
    "\n",
    "    main = nn.Sequential(\n",
    "        # input is (nc) x 64 x 64\n",
    "        nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # state size. (ndf) x 16 x 16\n",
    "        nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf * 2),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # state size. (ndf*2) x 8 x 8\n",
    "        nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf * 4),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # state size. (ndf*4) x 4 x 4\n",
    "        nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf * 8),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # state size. (ndf*8) x 4 x 4\n",
    "        nn.Conv2d(ndf * 8, nz, 4, 1, 0, bias=True),\n",
    "    )\n",
    "\n",
    "    return _netE_Base(main)\n",
    "\n",
    "def _netG():\n",
    "#     ngf = opt.ngf\n",
    "#     nc = opt.nc\n",
    "#     nz = opt.nz\n",
    "\n",
    "    main = nn.Sequential(\n",
    "        # input is Z, going into a convolution\n",
    "        nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(ngf * 8),\n",
    "        nn.ReLU(True),\n",
    "        # state size. (ngf*8) x 4 x 4\n",
    "        nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ngf * 4),\n",
    "        nn.ReLU(True),\n",
    "        # state size. (ngf*4) x 8 x 8\n",
    "        nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ngf * 2),\n",
    "        nn.ReLU(True),\n",
    "        # state size. (ngf*2) x 16 x 16\n",
    "        nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ngf),\n",
    "        nn.ReLU(True),\n",
    "        # state size. (ngf) x 32 x 32\n",
    "        nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "        nn.Tanh()\n",
    "        # state size. (nc) x 64 x 64\n",
    "    )\n",
    "\n",
    "    return _netG_Base(main)\n",
    "\n",
    "def load_G():\n",
    "    '''\n",
    "    Loads generator model.\n",
    "    '''\n",
    "    netG = _netG()\n",
    "    netG.apply(weights_init)\n",
    "    netG.train()\n",
    "    if netG_chp != '':\n",
    "        netG.load_state_dict(torch.load(netG_chp).state_dict())\n",
    "\n",
    "    print('Generator\\n', netG)\n",
    "    return netG\n",
    "\n",
    "def load_E():\n",
    "    '''\n",
    "    Loads encoder model.\n",
    "    '''\n",
    "    netE = _netE()\n",
    "    netE.apply(weights_init)\n",
    "    netE.train()\n",
    "    if netE_chp != '':\n",
    "        netE.load_state_dict(torch.load(netE_chp).state_dict())\n",
    "\n",
    "    print('Encoder\\n', netE)\n",
    "\n",
    "    return netE\n",
    "\n",
    "# Load generator\n",
    "netG = load_G()\n",
    "\n",
    "# Load encoder\n",
    "netE = load_E()\n",
    "\n",
    "# RuntimeError: Given transposed=1, weight[64, 512, 4, 4], so expected input[64, 256, 1, 1] to have 64 channels,\n",
    "# but got 256 channels instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretraining preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def var(x, dim=0):\n",
    "    '''\n",
    "    Calculates variance.\n",
    "    '''\n",
    "    x_zero_meaned = x - x.mean(dim).expand_as(x)\n",
    "    return x_zero_meaned.pow(2).mean(dim)\n",
    "\n",
    "\n",
    "class KLN01Loss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, direction, minimize):\n",
    "        super(KLN01Loss, self).__init__()\n",
    "        self.minimize = minimize\n",
    "        assert direction in ['pq', 'qp'], 'direction?'\n",
    "\n",
    "        self.direction = direction\n",
    "\n",
    "    def forward(self, samples):\n",
    "\n",
    "        assert samples.nelement() == samples.size(1) * samples.size(0), 'wtf?'\n",
    "\n",
    "        samples = samples.view(samples.size(0), -1)\n",
    "\n",
    "        self.samples_var = var(samples)\n",
    "        self.samples_mean = samples.mean(0)\n",
    "\n",
    "        samples_mean = self.samples_mean\n",
    "        samples_var = self.samples_var\n",
    "\n",
    "        if self.direction == 'pq':\n",
    "            # mu_1 = 0; sigma_1 = 1\n",
    "\n",
    "            t1 = (1 + samples_mean.pow(2)) / (2 * samples_var.pow(2))\n",
    "            t2 = samples_var.log()\n",
    "\n",
    "            KL = (t1 + t2 - 0.5).mean()\n",
    "        else:\n",
    "            # mu_2 = 0; sigma_2 = 1\n",
    "\n",
    "            t1 = (samples_var.pow(2) + samples_mean.pow(2)) / 2\n",
    "            t2 = -samples_var.log()\n",
    "\n",
    "            KL = (t1 + t2 - 0.5).mean()\n",
    "\n",
    "        if not self.minimize:\n",
    "            KL *= -1\n",
    "\n",
    "        return KL\n",
    "\n",
    "# ----------------------------\n",
    "\n",
    "def pairwise_euclidean(samples):\n",
    "\n",
    "    B = samples.size(0)\n",
    "\n",
    "    samples_norm = samples.mul(samples).sum(1)\n",
    "    samples_norm = samples_norm.expand(B, B)\n",
    "\n",
    "    dist_mat = samples.mm(samples.t()).mul(-2) + \\\n",
    "        samples_norm.add(samples_norm.t())\n",
    "    return dist_mat\n",
    "\n",
    "def sample_entropy(samples):\n",
    "\n",
    "        # Assume B x C input\n",
    "\n",
    "    dist_mat = pairwise_euclidean(samples)\n",
    "\n",
    "    # Get max and add it to diag\n",
    "    m = dist_mat.max().detach()\n",
    "    dist_mat_d = dist_mat + \\\n",
    "        Variable(torch.eye(dist_mat.size(0)) * (m.data[0] + 1)).cuda()\n",
    "\n",
    "    entropy = (dist_mat_d.min(1)[0] + 1e-4).log().sum()\n",
    "\n",
    "    entropy *= (samples.size(1) + 0.) / samples.size(0)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "class SampleKLN01Loss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, direction, minimize):\n",
    "        super(SampleKLN01Loss, self).__init__()\n",
    "        self.minimize = minimize\n",
    "        assert direction in ['pq', 'qp'], 'direction?'\n",
    "\n",
    "        self.direction = direction\n",
    "\n",
    "    def forward(self, samples):\n",
    "\n",
    "        assert samples.ndimension == 2, 'wft'\n",
    "        samples = samples.view(samples.size(0), -1)\n",
    "\n",
    "        self.samples_var = var(samples)\n",
    "        self.samples_mean = samples.mean(0)\n",
    "\n",
    "        if self.direction == 'pq':\n",
    "            assert False, 'not possible'\n",
    "        else:\n",
    "            entropy = sample_entropy(samples)\n",
    "\n",
    "            cross_entropy = - samples.pow(2).mean() / 2.\n",
    "\n",
    "            KL = - cross_entropy - entropy\n",
    "\n",
    "        if not self.minimize:\n",
    "            KL *= -1\n",
    "\n",
    "        return KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x = torch.FloatTensor(batch_size, nc, image_size, image_size)\n",
    "# z = torch.FloatTensor(batch_size, nz, 1, 1)\n",
    "# fixed_z = torch.FloatTensor(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "# z = fixed_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using parametric criterion KL_qp\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(batch_size, nc, image_size, image_size)\n",
    "z = torch.FloatTensor(batch_size, nz, 1, 1)\n",
    "fixed_z = torch.FloatTensor(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "\n",
    "def match(x, y, dist):\n",
    "    '''\n",
    "    Computes distance between corresponding points in `x` and `y`\n",
    "    using distance `dist`.\n",
    "    '''\n",
    "    if dist == 'L2':\n",
    "        return (x - y).pow(2).mean()\n",
    "    elif dist == 'L1':\n",
    "        return (x - y).abs().mean()\n",
    "    elif dist == 'cos':\n",
    "        x_n = normalize(x)\n",
    "        y_n = normalize(y)\n",
    "\n",
    "        return 2 - (x_n).mul(y_n).mean()\n",
    "    else:\n",
    "        assert dist == 'none', 'wtf ?'\n",
    "\n",
    "def normalize(x, dim=0):\n",
    "    '''\n",
    "    Projects points to a sphere.\n",
    "    '''\n",
    "    return x.div(x.norm(2, dim=dim).expand_as(x))\n",
    "\n",
    "def normalize_(x, dim=0):\n",
    "    '''\n",
    "    Projects points to a sphere inplace.\n",
    "    '''\n",
    "    x.div_(x.norm(2, dim=dim).expand_as(x))\n",
    "\n",
    "if noise == 'sphere':\n",
    "    normalize_(fixed_z)\n",
    "\n",
    "if cuda:\n",
    "    netE.cuda()\n",
    "    netG.cuda()\n",
    "    x = x.cuda()\n",
    "    z, fixed_z = z.cuda(), fixed_z.cuda()\n",
    "\n",
    "x = Variable(x)\n",
    "z = Variable(z)\n",
    "fixed_z = Variable(fixed_z)\n",
    "\n",
    "# Setup optimizers\n",
    "optimizerD = optim.Adam(netE.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "# Setup criterions\n",
    "if criterion == 'param':\n",
    "    print('Using parametric criterion KL_%s' % KL)\n",
    "    KL_minimizer = KLN01Loss(direction=KL, minimize=True)\n",
    "    KL_maximizer = KLN01Loss(direction=KL, minimize=False)\n",
    "elif criterion == 'nonparam':\n",
    "    print('Using NON-parametric criterion KL_%s' % KL)\n",
    "    KL_minimizer = SampleKLN01Loss(direction=KL, minimize=True)\n",
    "    KL_maximizer = SampleKLN01Loss(direction=KL, minimize=False)\n",
    "else:\n",
    "    assert False, 'criterion?'\n",
    "\n",
    "real_cpu = torch.FloatTensor()\n",
    "\n",
    "def save_images(epoch):\n",
    "\n",
    "    real_cpu.resize_(x.data.size()).copy_(x.data)\n",
    "\n",
    "    # Real samples\n",
    "    save_path = '%s/real_samples.png' % save_dir\n",
    "    vutils.save_image(real_cpu[:64] / 2 + 0.5, save_path)\n",
    "\n",
    "    netG.eval()\n",
    "    fake = netG(fixed_z)\n",
    "\n",
    "    # Fake samples\n",
    "    save_path = '%s/fake_samples_epoch_%03d.png' % (save_dir, epoch)\n",
    "    vutils.save_image(fake.data[:64] / 2 + 0.5, save_path)\n",
    "\n",
    "    # Save reconstructions\n",
    "    populate_x(x, dataloader['val'])\n",
    "    gex = netG(netE(x)) # here - at G entry\n",
    "\n",
    "    t = torch.FloatTensor(x.size(0) * 2, x.size(1),\n",
    "                          x.size(2), x.size(3))\n",
    "\n",
    "    t[0::2] = x.data[:]\n",
    "    t[1::2] = gex.data[:]\n",
    "\n",
    "    save_path = '%s/reconstructions_epoch_%03d.png' % (save_dir, epoch)\n",
    "    grid = vutils.save_image(t[:64] / 2 + 0.5, save_path)\n",
    "    \n",
    "    netG.train()\n",
    "\n",
    "def adjust_lr(epoch):\n",
    "    if epoch % drop_lr == (drop_lr - 1):\n",
    "        ###\n",
    "        assert optimizerD.param_groups[0]['lr'] == optimizerG.param_groups[0]['lr']\n",
    "        print('Adjusting learning rate from %f to %f on E and G' % (lr, lr / 2))\n",
    "        optimizerD.param_groups[0]['lr'] /= 2\n",
    "        optimizerG.param_groups[0]['lr'] /= 2\n",
    "        ###\n",
    "#         lr /= 2\n",
    "#         for param_group in optimizerD.param_groups:\n",
    "#             param_group['lr'] = lr\n",
    "\n",
    "#         for param_group in optimizerG.param_groups:\n",
    "#             param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def populate_x(x, dataloader):\n",
    "    '''\n",
    "    Fills input variable `x` with data generated with dataloader\n",
    "    '''\n",
    "    real_cpu, _ = dataloader.next()\n",
    "    x.data.resize_(real_cpu.size()).copy_(real_cpu)\n",
    "\n",
    "def populate_z(z):\n",
    "    '''\n",
    "    Fills noise variable `z` with noise U(S^M)\n",
    "    '''\n",
    "    z.data.resize_(batch_size, nz, 1, 1)\n",
    "    z.data.normal_(0, 1)\n",
    "    if noise == 'sphere':\n",
    "        normalize_(z.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(len(dataloader['train'].next()))\n",
    "# print(len(dataloader['val'].next()))\n",
    "# print(dataloader['train'].next()[0].shape, dataloader['train'].next()[1].shape)\n",
    "# print(dataloader['train'].next()[0].shape, dataloader['train'].next()[1].shape)\n",
    "\n",
    "# populate_x(x, dataloader['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7b7a2d1d9444>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mpopulate_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0;31m# e(X)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-a39c6fa89e5b>\u001b[0m in \u001b[0;36mpopulate_x\u001b[0;34m(x, dataloader)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mFills\u001b[0m \u001b[0minput\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     '''\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mreal_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_cpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_cpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "stats = {}\n",
    "for epoch in range(start_epoch, nepoch):\n",
    "\n",
    "    # Adjust learning rate\n",
    "    adjust_lr(epoch)\n",
    "\n",
    "    for i in range(len(dataloader['train'])):\n",
    "\n",
    "        # ---------------------------\n",
    "        #        Optimize over e\n",
    "        # ---------------------------\n",
    "\n",
    "        for e_iter in range(updates['e']['num_updates']):\n",
    "            e_losses = []\n",
    "            netE.zero_grad()\n",
    "\n",
    "            # X\n",
    "            populate_x(x, dataloader['train'])\n",
    "            # e(X)\n",
    "            ex = netE(x)\n",
    "\n",
    "            # KL_real: - \\Delta( e(X) , Z ) -> max_e\n",
    "            KL_real = KL_minimizer(ex)\n",
    "            e_losses.append(KL_real * updates['e']['KL_real'])\n",
    "\n",
    "            if updates['e']['match_x'] != 0:\n",
    "                # g(e(X))\n",
    "                gex = netG(ex)\n",
    "\n",
    "                # match_x: E_x||g(e(x)) - x|| -> min_e\n",
    "                err = match(gex, x, match_x)\n",
    "                e_losses.append(err * updates['e']['match_x'])\n",
    "\n",
    "            # Save some stats\n",
    "            stats['real_mean'] = KL_minimizer.samples_mean.data.mean()\n",
    "            stats['real_var'] = KL_minimizer.samples_var.data.mean()\n",
    "            stats['KL_real'] = KL_real.data[0]\n",
    "\n",
    "            # ================================================\n",
    "\n",
    "            # Z\n",
    "            populate_z(z)\n",
    "            # g(Z)\n",
    "            fake = netG(z).detach()\n",
    "            # e(g(Z))\n",
    "            egz = netE(fake)\n",
    "\n",
    "            # KL_fake: \\Delta( e(g(Z)) , Z ) -> max_e\n",
    "            KL_fake = KL_maximizer(egz)\n",
    "            e_losses.append(KL_fake * updates['e']['KL_fake'])\n",
    "\n",
    "            if updates['e']['match_z'] != 0:\n",
    "                # match_z: E_z||e(g(z)) - z|| -> min_e\n",
    "                err = match(egz, z, match_z)\n",
    "                e_losses.append(err * updates['e']['match_z'])\n",
    "\n",
    "            # Save some stats\n",
    "            stats['fake_mean'] = KL_maximizer.samples_mean.data.mean()\n",
    "            stats['fake_var'] = KL_maximizer.samples_var.data.mean()\n",
    "            stats['KL_fake'] = -KL_fake.data[0]\n",
    "\n",
    "            # Update e\n",
    "            sum(e_losses).backward()\n",
    "            optimizerD.step()\n",
    "\n",
    "        # ---------------------------\n",
    "        #        Minimize over g\n",
    "        # ---------------------------\n",
    "\n",
    "        for g_iter in range(updates['g']['num_updates']):\n",
    "            g_losses = []\n",
    "            netG.zero_grad()\n",
    "\n",
    "            # Z\n",
    "            populate_z(z)\n",
    "            # g(Z)\n",
    "            fake = netG(z)\n",
    "            # e(g(Z))\n",
    "            egz = netE(fake)\n",
    "\n",
    "            # KL_fake: \\Delta( e(g(Z)) , Z ) -> min_g\n",
    "            KL_fake_g = KL_minimizer(egz)\n",
    "            g_losses.append(KL_fake_g * updates['g']['KL_fake'])\n",
    "\n",
    "            if updates['g']['match_z'] != 0:\n",
    "                # match_z: E_z||e(g(z)) - z|| -> min_g\n",
    "                err = match(egz, z, match_z)\n",
    "                err = err * updates['g']['match_z']\n",
    "                g_losses.append(err)\n",
    "\n",
    "            # ==================================\n",
    "\n",
    "            if updates['g']['match_x'] != 0:\n",
    "                # X\n",
    "                populate_x(x, dataloader['train'])\n",
    "                # e(X)\n",
    "                ex = netE(x)\n",
    "\n",
    "                # g(e(X))\n",
    "                gex = netG(ex)\n",
    "\n",
    "                # match_x: E_x||g(e(x)) - x|| -> min_g\n",
    "                err = match(gex, x, match_x)\n",
    "                err = err * updates['g']['match_x']\n",
    "                g_losses.append(err)\n",
    "\n",
    "            # Step g\n",
    "            sum(g_losses).backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "        print('[{epoch}/{nepoch}][{iter}/{niter}] '\n",
    "              'KL_real/fake: {KL_real:.3f}/{KL_fake:.3f} '\n",
    "              'mean_real/fake: {real_mean:.3f}/{fake_mean:.3f} '\n",
    "              'var_real/fake: {real_var:.3f}/{fake_var:.3f} '\n",
    "              ''.format(epoch=epoch,\n",
    "                        nepoch=nepoch,\n",
    "                        iter=i,\n",
    "                        niter=len(dataloader['train']),\n",
    "                        **stats))\n",
    "\n",
    "#         if save_every_b:\n",
    "#             if i % save_every_b == 0: save_images(epoch)\n",
    "\n",
    "            \n",
    "        # If an epoch takes long time, dump intermediate\n",
    "        if dataset in ['lsun', 'imagenet'] and (i % 5000 == 0):\n",
    "            torch.save(netG, '%s/netG_epoch_%d_it_%d.pth' %\n",
    "                       (save_dir, epoch, i))\n",
    "            torch.save(netE, '%s/netE_epoch_%d_it_%d.pth' %\n",
    "                       (save_dir, epoch, i))\n",
    "    \n",
    "#     if epoch % save_every_e == 0: save_images(epoch)\n",
    "    # do checkpointing\n",
    "    torch.save(netG, '%s/netG_epoch_%d.pth' % (save_dir, epoch))\n",
    "    torch.save(netE, '%s/netE_epoch_%d.pth' % (save_dir, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(real_cpu.shape); print(real_cpu[:64].shape); print(real_cpu[0].shape)\n",
    "# # vutils.save_image(real_cpu[:64] / 2 + 0.5, save_path)\n",
    "# plt.imshow(real_cpu[0].numpy().reshape((64,64,3))) #[[2, 1, 0],:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# e_updates = '1;KL_fake:1,KL_real:1,match_z:0,match_x:10' \n",
    "# g_updates = '3;KL_fake:1,match_z:1000,match_x:0'\n",
    "\n",
    "# 10 * 50 * 64 - 32000 \n",
    "# 10 * 25 * 128\n",
    "# 10 * 13 * 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_every_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
