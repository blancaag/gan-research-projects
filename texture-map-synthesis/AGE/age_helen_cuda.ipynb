{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--g_updates'], dest='g_updates', nargs=None, const=None, default='2;KL_fake:1,match_z:1,match_x:0', type=None, choices=None, help='Update plan for generator <number of updates>;[<term:weight>]', metavar=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../utils')\n",
    "\n",
    "import libraries\n",
    "import utils_general\n",
    "from utils_general import *\n",
    "\n",
    "%matplotlib inline\n",
    "import imageio\n",
    "\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', required=True,\n",
    "                    help='cifar10 | lsun | imagenet | folder | lfw ')\n",
    "parser.add_argument('--dataroot', type=str, help='path to dataset')\n",
    "parser.add_argument('--workers', type=int,\n",
    "                    help='number of data loading workers', default=8)\n",
    "parser.add_argument('--batch_size', type=int,\n",
    "                    default=64, help='batch size')\n",
    "parser.add_argument('--image_size', type=int, default=32,\n",
    "                    help='the resolution of the input image to network')\n",
    "parser.add_argument('--nz', type=int, default=100,\n",
    "                    help='size of the latent z vector')\n",
    "parser.add_argument('--ngf', type=int, default=64)\n",
    "parser.add_argument('--ndf', type=int, default=64)\n",
    "parser.add_argument('--nc', type=int)\n",
    "\n",
    "parser.add_argument('--nepoch', type=int, default=25,\n",
    "                    help='number of epochs to train for')\n",
    "parser.add_argument('--lr', type=float, default=0.0002,\n",
    "                    help='learning rate, default=0.0002')\n",
    "parser.add_argument('--beta1', type=float, default=0.5,\n",
    "                    help='beta1 for adam. default=0.5')\n",
    "parser.add_argument('--cpu', action='store_true',\n",
    "                    help='use CPU instead of GPU')\n",
    "parser.add_argument('--ngpu', type=int, default=1,\n",
    "                    help='number of GPUs to use')\n",
    "\n",
    "parser.add_argument('--netG', default='',\n",
    "                    help=\"path to netG config\")\n",
    "parser.add_argument('--netE', default='',\n",
    "                    help=\"path to netE config\")\n",
    "parser.add_argument('--netG_chp', default='',\n",
    "                    help=\"path to netG (to continue training)\")\n",
    "parser.add_argument('--netE_chp', default='',\n",
    "                    help=\"path to netE (to continue training)\")\n",
    "\n",
    "parser.add_argument('--save_dir', default='.',\n",
    "                    help='folder to output images and model checkpoints')\n",
    "parser.add_argument('--criterion', default='param',\n",
    "                    help='param|nonparam, How to estimate KL')\n",
    "parser.add_argument('--KL', default='qp', help='pq|qp')\n",
    "parser.add_argument('--noise', default='sphere', help='normal|sphere')\n",
    "parser.add_argument('--match_z', default='cos', help='none|L1|L2|cos')\n",
    "parser.add_argument('--match_x', default='L1', help='none|L1|L2|cos')\n",
    "\n",
    "parser.add_argument('--drop_lr', default=5, type=int, help='')\n",
    "parser.add_argument('--save_every', default=50, type=int, help='')\n",
    "\n",
    "parser.add_argument('--manual_seed', type=int, default=123, help='manual seed')\n",
    "parser.add_argument('--start_epoch', type=int, default=0, help='epoch number to start with')\n",
    "\n",
    "parser.add_argument(\n",
    "    '--e_updates', default=\"1;KL_fake:1,KL_real:1,match_z:0,match_x:0\",\n",
    "    help='Update plan for encoder <number of updates>;[<term:weight>]'\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    '--g_updates', default=\"2;KL_fake:1,match_z:1,match_x:0\",\n",
    "    help='Update plan for generator <number of updates>;[<term:weight>]'\n",
    ")\n",
    "\n",
    "# opt = parser.parse_args()\n",
    "\n",
    "# python age.py \n",
    "# --dataset celeba \n",
    "# --dataroot <data_root> \n",
    "# --image_size 64 \n",
    "# --save_dir <save_dir> \n",
    "# --lr 0.0002 \n",
    "# --nz 64 \n",
    "# --batch_size 64 \n",
    "# --netG dcgan64px \n",
    "# --netE dcgan64px \n",
    "# --nepoch 5 \n",
    "# --drop_lr 5 \n",
    "# --e_updates '1;KL_fake:1,KL_real:1,match_z:0,match_x:10' \n",
    "# --g_updates '3;KL_fake:1,match_z:1000,match_x:0'\n",
    "\n",
    "# python age.py \n",
    "# --dataset celeba \n",
    "# --dataroot <data_root> \n",
    "# --image_size 64 \n",
    "# --save_dir <save_dir> \n",
    "# --start_epoch 5 \n",
    "# --lr 0.0002 \n",
    "# --nz 64 \n",
    "# --batch_size 256 \n",
    "# --netG dcgan64px \n",
    "# --netE dcgan64px \n",
    "# --nepoch 6 \n",
    "# --drop_lr 5   \n",
    "# --e_updates '1;KL_fake:1,KL_real:1,match_z:0,match_x:15' \n",
    "# --g_updates '3;KL_fake:1,match_z:1000,match_x:0' \n",
    "# --netE_chp  <save_dir>/netE_epoch_5.pth \n",
    "# --netG_chp <save_dir>/netG_epoch_5.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svmem(total=64388890624, available=63350505472, percent=1.6, used=556662784, free=63168655360, active=497311744, inactive=469098496, buffers=49991680, cached=613580800, shared=9654272)\n"
     ]
    }
   ],
   "source": [
    "# print(get_available_gpus())\n",
    "print(psutil.virtual_memory())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "import importlib\n",
    "# from .dataset import FolderWithImages\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "from PIL import Image\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory was not created.\n",
      "64_128_100_dlr:25_2017-12-19_18:19:33_Exg=1\n"
     ]
    }
   ],
   "source": [
    "# setup function @utils.py\n",
    "\n",
    "cuda = True # not opt.cpu\n",
    "torch.set_num_threads(4)\n",
    "dataset = 'helen'\n",
    "run = ''\n",
    "save_dir = 'output/helen/'\n",
    "try:\n",
    "    os.makedirs(save_dir)\n",
    "except OSError:\n",
    "    print('Directory was not created.')\n",
    "\n",
    "manual_seed = random.randint(1, 10000)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "if torch.cuda.is_available() and not cuda:\n",
    "    print(\"WARNING: You have a CUDA device,\"\n",
    "            \"so you should probably run with --cuda\")\n",
    "\n",
    "e_updates = '1;KL_fake:1,KL_real:1,match_z:0,match_x:10' \n",
    "g_updates = '3;KL_fake:1,match_z:1000,match_x:1'\n",
    "    \n",
    "updates = {'e': {}, 'g': {}}\n",
    "updates['e']['num_updates'] = int(e_updates.split(';')[0])\n",
    "updates['e'].update({x.split(':')[0]: float(x.split(':')[1]) \n",
    "                     for x in e_updates.split(';')[1].split(',')})\n",
    "\n",
    "updates['g']['num_updates'] = int(g_updates.split(';')[0])\n",
    "updates['g'].update({x.split(':')[0]: float(x.split(':')[1]) \n",
    "                     for x in g_updates.split(';')[1].split(',')})\n",
    "\n",
    "\n",
    "image_size = 64 # 512\n",
    "batch_size = 128 # 64\n",
    "workers = 16\n",
    "shuffle = True\n",
    "drop_last = True\n",
    "train = True\n",
    "\n",
    "nc = 3\n",
    "nz = 64 #100 #'size of the latent z vector')\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "ngpu = 0 # 'number of GPUs to use')\n",
    "pin_memory = True # True | If ``True``, the data loader will copy tensors into CUDA pinned memory before returning them.\n",
    "\n",
    "noise = 'sphere' #help='normal|sphere')\n",
    "\n",
    "# netG = 'dcgan64px' \n",
    "# netE = 'dcgan64px' \n",
    "\n",
    "netG_chp = 'output/helen/models_netG_last_epoch_64_128_15_dlr:100.pth' # \"path to netG (to continue training)\"\n",
    "netE_chp = 'output/helen/models_netE_last_epoch_64_128_15_dlr:100.pth' # \"path to netE (to continue training)\"\n",
    "\n",
    "lr = 0.0002\n",
    "drop_lr = 25\n",
    "beta1 = 0.5 # help='beta1 for adam. default=0.5'\n",
    "criterion = 'param'# help='param|nonparam, How to estimate KL'\n",
    "KL ='qp' # help='pq|qp'\n",
    "match_z = 'cos' # help='none|L1|L2|cos'\n",
    "match_x = 'L1' # help='none|L1|L2|cos'\n",
    "\n",
    "start_epoch = 0\n",
    "nepoch = 100\n",
    "\n",
    "save_every_e = 9\n",
    "save_every_b = None\n",
    "dataroot = '../data/data'\n",
    "\n",
    "now = str(datetime.now()).split('.')[0].split(' ')[0] + '_' + str(datetime.now()).split('.')[0].split(' ')[1] + '_Exg=1'\n",
    "\n",
    "run = '%d_%d_%d_dlr:%d_%s' %(image_size, batch_size, nepoch, drop_lr, now); print(run)\n",
    "# run = '%d_%d_%d_dlr:%d' %(image_size, batch_size, nepoch, drop_lr); print(run)\n",
    "\n",
    "# --lr 0.0002 \n",
    "# --nz 64 \n",
    "# --batch_size 64 \n",
    "# --netG dcgan64px \n",
    "# --netE dcgan64px \n",
    "# --nepoch 5 \n",
    "# --drop_lr 5 \n",
    "# --e_updates '1;KL_fake:1,KL_real:1,match_z:0,match_x:10' \n",
    "# --g_updates '3;KL_fake:1,match_z:1000,match_x:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to trainning](#train)\n",
    "<a id='init'.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/transforms/transforms.py:156: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "import importlib\n",
    "import random\n",
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "##\n",
    "import torch.utils.data as data\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from PIL import Image\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in [\".png\", \".jpg\", \".jpeg\"])\n",
    "\n",
    "def load_img(filepath):\n",
    "#     img = cv2.imread(filepath) #, cv2.IMREAD_UNCHANGED)\n",
    "    img = Image.open(filepath).convert('RGB')\n",
    "    return img\n",
    "\n",
    "class FolderWithImages(data.Dataset):\n",
    "    def __init__(self, root, input_transform=None, target_transform=None):\n",
    "        super(FolderWithImages, self).__init__()\n",
    "        self.image_filenames = [join(root, x)\n",
    "                                for x in listdir(root) if is_image_file(x.lower())]\n",
    "\n",
    "        self.input_transform = input_transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input = load_img(self.image_filenames[index])\n",
    "        target = input.copy()\n",
    "        if self.input_transform:\n",
    "            input = self.input_transform(input)\n",
    "        if self.target_transform:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return input, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    \n",
    "def setup_dataset(dataset, dataroot, train=True, shuffle=True, drop_last=True):\n",
    "    '''\n",
    "    Setups dataset.\n",
    "    '''\n",
    "    # Usual transform\n",
    "    t = transforms.Compose([\n",
    "        transforms.Scale([image_size, image_size]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "    if dataset in ['imagenet', 'folder', 'lfw']:\n",
    "        imdir = 'train' if train else 'val'\n",
    "        dataroot = os.path.join(dataroot, imdir)\n",
    "\n",
    "        dataset = dset.ImageFolder(root=dataroot, transform=t)\n",
    "    elif dataset == 'lsun':\n",
    "        dataset = dset.LSUN(db_path=dataroot,\n",
    "                            classes=['bedroom_train'],\n",
    "                            train=train,\n",
    "                            transform=t)\n",
    "    elif dataset == 'cifar10':\n",
    "        dataset = dset.CIFAR10(root='data/raw/cifar10',\n",
    "                               download=True,\n",
    "                               train=train,\n",
    "                               transform=t\n",
    "                               )\n",
    "    elif dataset == 'mnist':\n",
    "        dataset = dset.MNIST(root='data/raw/mnist',\n",
    "                             download=True,\n",
    "                             train=train,\n",
    "                             transform=t\n",
    "                             )\n",
    "    elif dataset == 'svhn':\n",
    "        dataset = dset.SVHN(root='data/raw/svhn',\n",
    "                            download=True,\n",
    "                            train=train,\n",
    "                            transform=t)\n",
    "    elif dataset == 'celeba':\n",
    "        imdir = 'train' if train else 'val'\n",
    "        dataroot = os.path.join(dataroot, imdir)\n",
    "\n",
    "        dataset = FolderWithImages(root=dataroot,\n",
    "                                   input_transform=transforms.Compose([\n",
    "                                       ALICropAndScale(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(\n",
    "                                           (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                   ]),\n",
    "                                   target_transform=transforms.ToTensor()\n",
    "                                   )\n",
    "    elif dataset == 'helen':\n",
    "        imdir = 'train' if train else 'val'\n",
    "        dataroot = os.path.join(dataroot, imdir)\n",
    "\n",
    "        dataset = FolderWithImages(root=dataroot,\n",
    "                                   input_transform=transforms.Compose([\n",
    "                                       Scale(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(\n",
    "                                           (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                   ]),\n",
    "                                   target_transform=transforms.ToTensor()\n",
    "                                   )\n",
    "    else:\n",
    "        assert False, 'Wrong dataset name.'\n",
    "\n",
    "    assert len(dataset) > 0, 'No images found, check your paths.'\n",
    "\n",
    "    # Shuffle and drop last when training\n",
    "    dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=shuffle,\n",
    "                                             num_workers=int(workers),\n",
    "                                             pin_memory=pin_memory,\n",
    "                                             drop_last=drop_last)\n",
    "#     print(len(dataloader))\n",
    "#     for i in dataloader: print(i[0].shape, i[1].shape)\n",
    "        \n",
    "    return InfiniteDataLoader(dataloader)\n",
    "#     return dataloader\n",
    "\n",
    "class InfiniteDataLoader(object):\n",
    "    \"\"\"docstring for InfiniteDataLoader\"\"\"\n",
    "\n",
    "    def __init__(self, dataloader):\n",
    "        super(InfiniteDataLoader, self).__init__()\n",
    "        self.dataloader = dataloader\n",
    "        self.data_iter = None\n",
    "\n",
    "    def next(self):\n",
    "        try:\n",
    "            data = self.data_iter.next()\n",
    "        except Exception:\n",
    "            # Reached end of the dataset\n",
    "            self.data_iter = iter(self.dataloader)\n",
    "            data = self.data_iter.next()\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataloader)\n",
    "\n",
    "class ALICropAndScale(object):\n",
    "    def __call__(self, img):\n",
    "        return img.resize((64, 78), Image.ANTIALIAS).crop((0, 7, 64, 64 + 7))\n",
    "    \n",
    "class Scale(object):\n",
    "    def __call__(self, img):\n",
    "#         img = cv2.resize(img, (64, 64), cv2.INTER_AREA)\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#         img = Image.fromarray(img)\n",
    "        img = img.resize((image_size, image_size), Image.ANTIALIAS)\n",
    "        return img \n",
    "\n",
    "# cv::INTER_AREA interpolation, whereas to\n",
    "# .   enlarge an image, it will generally look best with cv::INTER_CUBIC (slow) or cv::INTER_LINEAR\n",
    "# .   (faster but still looks OK).\n",
    "    \n",
    "# Setup dataset\n",
    "dataloader = dict(train=setup_dataset(dataset, dataroot, train=True),\n",
    "                  val=setup_dataset(dataset, dataroot, train=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dl = setup_dataset(dataset, dataroot, train=True)\n",
    "# # len(dataloader['val'])\n",
    "\n",
    "# def save_image(tensor, filename, nrow=8, padding=2,\n",
    "#                normalize=False, range=None, scale_each=False, pad_value=0):\n",
    "#     \"\"\"Save a given Tensor into an image file.\n",
    "#     Args:\n",
    "#         tensor (Tensor or list): Image to be saved. If given a mini-batch tensor,\n",
    "#             saves the tensor as a grid of images by calling ``make_grid``.\n",
    "#         **kwargs: Other arguments are documented in ``make_grid``.\n",
    "#     \"\"\"\n",
    "#     from PIL import Image\n",
    "#     grid = vutils.make_grid(tensor, nrow=nrow, padding=padding, pad_value=pad_value,\n",
    "#                      normalize=normalize, range=range, scale_each=scale_each)\n",
    "#     ndarr = grid.mul(255).clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy() # \n",
    "# #     im = Image.fromarray(ndarr)\n",
    "#     im = Image.fromarray(ndarr[:,:,::-1])    \n",
    "#     im.save(filename)\n",
    "\n",
    "\n",
    "# def save_images(epoch):\n",
    "\n",
    "#     real_cpu.resize_(x.data.size()).copy_(x.data)\n",
    "\n",
    "#     # Real samples\n",
    "#     save_path = '%s/real_samples.png' % save_dir\n",
    "#     save_image(real_cpu[:64] / 2 + 0.5, save_path)\n",
    "\n",
    "#     netG.eval()\n",
    "#     fake = netG(fixed_z)\n",
    "\n",
    "#     # Fake samples\n",
    "#     save_path = '%s/fake_samples_epoch_%03d.png' % (save_dir, epoch)\n",
    "#     save_image(fake.data[:64] / 2 + 0.5, save_path)\n",
    "\n",
    "#     # Save reconstructions\n",
    "#     populate_x(x, dataloader['val'])\n",
    "#     gex = netG(netE(x)) # here - at G entry\n",
    "\n",
    "#     t = torch.FloatTensor(x.size(0) * 2, x.size(1),\n",
    "#                           x.size(2), x.size(3))\n",
    "\n",
    "#     t[0::2] = x.data[:]\n",
    "#     t[1::2] = gex.data[:]\n",
    "\n",
    "#     save_path = '%s/reconstructions_epoch_%03d.png' % (save_dir, epoch)\n",
    "#     grid = save_image(t[:64] / 2 + 0.5, save_path)\n",
    "    \n",
    "#     netG.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(x, dim=0):\n",
    "    '''\n",
    "    Projects points to a sphere.\n",
    "    '''\n",
    "    return x.div(x.norm(2, dim=dim).expand_as(x))\n",
    "\n",
    "def normalize_(x, dim=0):\n",
    "    '''\n",
    "    Projects points to a sphere inplace.\n",
    "    '''\n",
    "    x.div_(x.norm(2, dim=dim).expand_as(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator\n",
      " _netG_Base(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d (64, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): ConvTranspose2d (512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): ConvTranspose2d (256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (8): ReLU(inplace)\n",
      "    (9): ConvTranspose2d (128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (11): ReLU(inplace)\n",
      "    (12): ConvTranspose2d (64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n",
      "Encoder\n",
      " _netE_Base(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d (3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(0.2, inplace)\n",
      "    (2): Conv2d (64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (4): LeakyReLU(0.2, inplace)\n",
      "    (5): Conv2d (128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (7): LeakyReLU(0.2, inplace)\n",
      "    (8): Conv2d (256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (10): LeakyReLU(0.2, inplace)\n",
      "    (11): Conv2d (512, 64, kernel_size=(4, 4), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def weights_init(m):\n",
    "    '''\n",
    "    Custom weights initialization called on netG and netE\n",
    "    '''\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "class _netE_Base(nn.Module):\n",
    "    def __init__(self, main):\n",
    "        super(_netE_Base, self).__init__()\n",
    "        self.noise = noise\n",
    "        self.ngpu = ngpu\n",
    "        self.main = main\n",
    "\n",
    "    def forward(self, input):\n",
    "        gpu_ids = None\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 0:\n",
    "            gpu_ids = range(self.ngpu)\n",
    "            output = nn.parallel.data_parallel(self.main, input, gpu_ids)\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        if self.noise == 'sphere':\n",
    "            output = normalize(output)\n",
    "        return output\n",
    "    \n",
    "class _netG_Base(nn.Module):\n",
    "    def __init__(self, main):\n",
    "        super(_netG_Base, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = main\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        # Check input is either (B,C,1,1) or (B,C)\n",
    "        assert input.nelement() == input.size(0) * input.size(1), 'wtf'\n",
    "        input = input.view(input.size(0), input.size(1), 1, 1)\n",
    "\n",
    "        gpu_ids = None\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 0:\n",
    "            gpu_ids = range(self.ngpu)\n",
    "            return nn.parallel.data_parallel(self.main, input, gpu_ids)\n",
    "        else:\n",
    "            return self.main(input)\n",
    "\n",
    "\n",
    "def _netE():\n",
    "#     ndf = opt.ndf\n",
    "#     nc = opt.nc\n",
    "#     nz = opt.nz\n",
    "\n",
    "    main = nn.Sequential(\n",
    "        # input is (nc) x 64 x 64\n",
    "        nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # state size. (ndf) x 16 x 16\n",
    "        nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf * 2),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # state size. (ndf*2) x 8 x 8\n",
    "        nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf * 4),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # state size. (ndf*4) x 4 x 4\n",
    "        nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ndf * 8),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # state size. (ndf*8) x 4 x 4\n",
    "        nn.Conv2d(ndf * 8, nz, 4, 1, 0, bias=True),\n",
    "    )\n",
    "\n",
    "    return _netE_Base(main)\n",
    "\n",
    "def _netG():\n",
    "#     ngf = opt.ngf\n",
    "#     nc = opt.nc\n",
    "#     nz = opt.nz\n",
    "\n",
    "    main = nn.Sequential(\n",
    "        # input is Z, going into a convolution\n",
    "        nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(ngf * 8),\n",
    "        nn.ReLU(True),\n",
    "        # state size. (ngf*8) x 4 x 4\n",
    "        nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ngf * 4),\n",
    "        nn.ReLU(True),\n",
    "        # state size. (ngf*4) x 8 x 8\n",
    "        nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ngf * 2),\n",
    "        nn.ReLU(True),\n",
    "        # state size. (ngf*2) x 16 x 16\n",
    "        nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(ngf),\n",
    "        nn.ReLU(True),\n",
    "        # state size. (ngf) x 32 x 32\n",
    "        nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "        nn.Tanh()\n",
    "        # state size. (nc) x 64 x 64\n",
    "    )\n",
    "\n",
    "    return _netG_Base(main)\n",
    "\n",
    "def load_G():\n",
    "    '''\n",
    "    Loads generator model.\n",
    "    '''\n",
    "    netG = _netG()\n",
    "    netG.apply(weights_init)\n",
    "    netG.train()\n",
    "    if netG_chp != '':\n",
    "        netG.load_state_dict(torch.load(netG_chp).state_dict())\n",
    "\n",
    "    print('Generator\\n', netG)\n",
    "    return netG\n",
    "\n",
    "def load_E():\n",
    "    '''\n",
    "    Loads encoder model.\n",
    "    '''\n",
    "    netE = _netE()\n",
    "    netE.apply(weights_init)\n",
    "    netE.train()\n",
    "    if netE_chp != '':\n",
    "        netE.load_state_dict(torch.load(netE_chp).state_dict())\n",
    "\n",
    "    print('Encoder\\n', netE)\n",
    "\n",
    "    return netE\n",
    "\n",
    "# Load generator\n",
    "netG = load_G()\n",
    "\n",
    "# Load encoder\n",
    "netE = load_E()\n",
    "\n",
    "# RuntimeError: Given transposed=1, weight[64, 512, 4, 4], so expected input[64, 256, 1, 1] to have 64 channels,\n",
    "# but got 256 channels instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretraining preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def var(x, dim=0):\n",
    "    '''\n",
    "    Calculates variance.\n",
    "    '''\n",
    "    x_zero_meaned = x - x.mean(dim).expand_as(x)\n",
    "    return x_zero_meaned.pow(2).mean(dim)\n",
    "\n",
    "\n",
    "class KLN01Loss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, direction, minimize):\n",
    "        super(KLN01Loss, self).__init__()\n",
    "        self.minimize = minimize\n",
    "        assert direction in ['pq', 'qp'], 'direction?'\n",
    "\n",
    "        self.direction = direction\n",
    "\n",
    "    def forward(self, samples):\n",
    "\n",
    "        assert samples.nelement() == samples.size(1) * samples.size(0), 'wtf?'\n",
    "\n",
    "        samples = samples.view(samples.size(0), -1)\n",
    "\n",
    "        self.samples_var = var(samples)\n",
    "        self.samples_mean = samples.mean(0)\n",
    "\n",
    "        samples_mean = self.samples_mean\n",
    "        samples_var = self.samples_var\n",
    "\n",
    "        if self.direction == 'pq':\n",
    "            # mu_1 = 0; sigma_1 = 1\n",
    "\n",
    "            t1 = (1 + samples_mean.pow(2)) / (2 * samples_var.pow(2))\n",
    "            t2 = samples_var.log()\n",
    "\n",
    "            KL = (t1 + t2 - 0.5).mean()\n",
    "        else:\n",
    "            # mu_2 = 0; sigma_2 = 1\n",
    "\n",
    "            t1 = (samples_var.pow(2) + samples_mean.pow(2)) / 2\n",
    "            t2 = -samples_var.log()\n",
    "\n",
    "            KL = (t1 + t2 - 0.5).mean()\n",
    "\n",
    "        if not self.minimize:\n",
    "            KL *= -1\n",
    "\n",
    "        return KL\n",
    "\n",
    "# ----------------------------\n",
    "\n",
    "def pairwise_euclidean(samples):\n",
    "\n",
    "    B = samples.size(0)\n",
    "\n",
    "    samples_norm = samples.mul(samples).sum(1)\n",
    "    samples_norm = samples_norm.expand(B, B)\n",
    "\n",
    "    dist_mat = samples.mm(samples.t()).mul(-2) + \\\n",
    "        samples_norm.add(samples_norm.t())\n",
    "    return dist_mat\n",
    "\n",
    "def sample_entropy(samples):\n",
    "\n",
    "        # Assume B x C input\n",
    "\n",
    "    dist_mat = pairwise_euclidean(samples)\n",
    "\n",
    "    # Get max and add it to diag\n",
    "    m = dist_mat.max().detach()\n",
    "    dist_mat_d = dist_mat + \\\n",
    "        Variable(torch.eye(dist_mat.size(0)) * (m.data[0] + 1)).cuda()\n",
    "\n",
    "    entropy = (dist_mat_d.min(1)[0] + 1e-4).log().sum()\n",
    "\n",
    "    entropy *= (samples.size(1) + 0.) / samples.size(0)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "class SampleKLN01Loss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, direction, minimize):\n",
    "        super(SampleKLN01Loss, self).__init__()\n",
    "        self.minimize = minimize\n",
    "        assert direction in ['pq', 'qp'], 'direction?'\n",
    "\n",
    "        self.direction = direction\n",
    "\n",
    "    def forward(self, samples):\n",
    "\n",
    "        assert samples.ndimension == 2, 'wft'\n",
    "        samples = samples.view(samples.size(0), -1)\n",
    "\n",
    "        self.samples_var = var(samples)\n",
    "        self.samples_mean = samples.mean(0)\n",
    "\n",
    "        if self.direction == 'pq':\n",
    "            assert False, 'not possible'\n",
    "        else:\n",
    "            entropy = sample_entropy(samples)\n",
    "\n",
    "            cross_entropy = - samples.pow(2).mean() / 2.\n",
    "\n",
    "            KL = - cross_entropy - entropy\n",
    "\n",
    "        if not self.minimize:\n",
    "            KL *= -1\n",
    "\n",
    "        return KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x = torch.FloatTensor(batch_size, nc, image_size, image_size)\n",
    "# z = torch.FloatTensor(batch_size, nz, 1, 1)\n",
    "# fixed_z = torch.FloatTensor(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "# z = fixed_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using parametric criterion KL_qp\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(batch_size, nc, image_size, image_size)\n",
    "z = torch.FloatTensor(batch_size, nz, 1, 1)\n",
    "fixed_z = torch.FloatTensor(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "\n",
    "def match(x, y, dist):\n",
    "    '''\n",
    "    Computes distance between corresponding points in `x` and `y`\n",
    "    using distance `dist`.\n",
    "    '''\n",
    "    if dist == 'L2':\n",
    "        return (x - y).pow(2).mean()\n",
    "    elif dist == 'L1':\n",
    "        return (x - y).abs().mean()\n",
    "    elif dist == 'cos':\n",
    "        x_n = normalize(x)\n",
    "        y_n = normalize(y)\n",
    "\n",
    "        return 2 - (x_n).mul(y_n).mean()\n",
    "    else:\n",
    "        assert dist == 'none', 'wtf ?'\n",
    "\n",
    "def normalize(x, dim=0):\n",
    "    '''\n",
    "    Projects points to a sphere.\n",
    "    '''\n",
    "    return x.div(x.norm(2, dim=dim).expand_as(x))\n",
    "\n",
    "def normalize_(x, dim=0):\n",
    "    '''\n",
    "    Projects points to a sphere inplace.\n",
    "    '''\n",
    "    x.div_(x.norm(2, dim=dim).expand_as(x))\n",
    "\n",
    "if noise == 'sphere':\n",
    "    normalize_(fixed_z)\n",
    "\n",
    "if cuda:\n",
    "    netE.cuda()\n",
    "    netG.cuda()\n",
    "    x = x.cuda()\n",
    "    z, fixed_z = z.cuda(), fixed_z.cuda()\n",
    "\n",
    "x = Variable(x)\n",
    "z = Variable(z)\n",
    "fixed_z = Variable(fixed_z)\n",
    "\n",
    "# Setup optimizers\n",
    "optimizerD = optim.Adam(netE.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "# Setup criterions\n",
    "if criterion == 'param':\n",
    "    print('Using parametric criterion KL_%s' % KL)\n",
    "    KL_minimizer = KLN01Loss(direction=KL, minimize=True)\n",
    "    KL_maximizer = KLN01Loss(direction=KL, minimize=False)\n",
    "elif criterion == 'nonparam':\n",
    "    print('Using NON-parametric criterion KL_%s' % KL)\n",
    "    KL_minimizer = SampleKLN01Loss(direction=KL, minimize=True)\n",
    "    KL_maximizer = SampleKLN01Loss(direction=KL, minimize=False)\n",
    "else:\n",
    "    assert False, 'criterion?'\n",
    "\n",
    "real_cpu = torch.FloatTensor()\n",
    "\n",
    "\n",
    "def save_image(tensor, filename, nrow=8, padding=2,\n",
    "               normalize=False, range=None, scale_each=False, pad_value=0):\n",
    "    \"\"\"Save a given Tensor into an image file.\n",
    "    Args:\n",
    "        tensor (Tensor or list): Image to be saved. If given a mini-batch tensor,\n",
    "            saves the tensor as a grid of images by calling ``make_grid``.\n",
    "        **kwargs: Other arguments are documented in ``make_grid``.\n",
    "    \"\"\"\n",
    "    from PIL import Image\n",
    "    grid = vutils.make_grid(tensor, nrow=nrow, padding=padding, pad_value=pad_value,\n",
    "                     normalize=normalize, range=range, scale_each=scale_each)\n",
    "    ndarr = grid.mul(255).clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy() # \n",
    "    im = Image.fromarray(ndarr)\n",
    "#     im = Image.fromarray(ndarr[:,:,::-1])    \n",
    "    im.save(filename)\n",
    "\n",
    "\n",
    "def save_images(epoch):\n",
    "\n",
    "    real_cpu.resize_(x.data.size()).copy_(x.data)\n",
    "\n",
    "    # Real samples\n",
    "    save_path = '%s/real_samples.png' % save_dir\n",
    "    save_image(real_cpu[:64] / 2 + 0.5, save_path)\n",
    "\n",
    "    netG.eval()\n",
    "    fake = netG(fixed_z)\n",
    "\n",
    "    # Fake samples\n",
    "    save_path = '%s/fake_samples_epoch_%03d.png' % (save_dir, epoch)\n",
    "    save_image(fake.data[:64] / 2 + 0.5, save_path)\n",
    "\n",
    "    # Save reconstructions\n",
    "    populate_x(x, dataloader['val'])\n",
    "    gex = netG(netE(x)) # here - at G entry\n",
    "\n",
    "    t = torch.FloatTensor(x.size(0) * 2, x.size(1),\n",
    "                          x.size(2), x.size(3))\n",
    "\n",
    "    t[0::2] = x.data[:]\n",
    "    t[1::2] = gex.data[:]\n",
    "\n",
    "    save_path = '%s/reconstructions_epoch_%03d.png' % (save_dir, epoch)\n",
    "    grid = save_image(t[:64] / 2 + 0.5, save_path)\n",
    "    \n",
    "    netG.train()\n",
    "\n",
    "def adjust_lr(epoch, drop_coef=2):\n",
    "    if (epoch + 1) % drop_lr == 0:\n",
    "        ###\n",
    "        assert optimizerD.param_groups[0]['lr'] == optimizerG.param_groups[0]['lr']\n",
    "        lr = optimizerD.param_groups[0]['lr']\n",
    "        print('Adjusting learning rate from %f to %f on E and G' % (lr, lr / drop_coef))\n",
    "        optimizerD.param_groups[0]['lr'] /= drop_coef\n",
    "        optimizerG.param_groups[0]['lr'] /= drop_coef\n",
    "        ###\n",
    "#         lr /= 2\n",
    "#         for param_group in optimizerD.param_groups:\n",
    "#             param_group['lr'] = lr\n",
    "\n",
    "#         for param_group in optimizerG.param_groups:\n",
    "#             param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def populate_x(x, dataloader):\n",
    "    '''\n",
    "    Fills input variable `x` with data generated with dataloader\n",
    "    '''\n",
    "    real_cpu, _ = dataloader.next()\n",
    "    x.data.resize_(real_cpu.size()).copy_(real_cpu)\n",
    "\n",
    "def populate_z(z):\n",
    "    '''\n",
    "    Fills noise variable `z` with noise U(S^M)\n",
    "    '''\n",
    "    z.data.resize_(batch_size, nz, 1, 1)\n",
    "    z.data.normal_(0, 1)\n",
    "    if noise == 'sphere':\n",
    "        normalize_(z.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 64, 64]) torch.Size([128, 3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "# print(len(dataloader['train'].next()))\n",
    "# print(len(dataloader['val'].next()))\n",
    "# print(dataloader['train'].next()[0].shape, dataloader['train'].next()[1].shape)\n",
    "print(dataloader['train'].next()[0].shape, dataloader['train'].next()[1].shape)\n",
    "\n",
    "# populate_x(x, dataloader['val'])\n",
    "# nepoch = 10\n",
    "# lr = 0.0002\n",
    "\n",
    "sim = dataloader['train'].next()[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/100][0/43] KL_real/fake: 4.570/4.543 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.007 \n",
      "[0/100][1/43] KL_real/fake: 4.607/4.572 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.007 \n",
      "[0/100][2/43] KL_real/fake: 4.614/4.586 mean_real/fake: -0.008/-0.005 var_real/fake: 0.006/0.006 \n",
      "[0/100][3/43] KL_real/fake: 4.599/4.567 mean_real/fake: -0.006/-0.007 var_real/fake: 0.006/0.007 \n",
      "[0/100][4/43] KL_real/fake: 4.603/4.578 mean_real/fake: -0.005/-0.007 var_real/fake: 0.006/0.006 \n",
      "[0/100][5/43] KL_real/fake: 4.602/4.572 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.007 \n",
      "[0/100][6/43] KL_real/fake: 4.612/4.582 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.007 \n",
      "[0/100][7/43] KL_real/fake: 4.564/4.543 mean_real/fake: -0.002/-0.001 var_real/fake: 0.007/0.007 \n",
      "[0/100][8/43] KL_real/fake: 4.543/4.532 mean_real/fake: 0.001/-0.002 var_real/fake: 0.007/0.007 \n",
      "[0/100][9/43] KL_real/fake: 4.552/4.530 mean_real/fake: -0.002/-0.005 var_real/fake: 0.007/0.007 \n",
      "[0/100][10/43] KL_real/fake: 4.564/4.532 mean_real/fake: -0.002/-0.003 var_real/fake: 0.007/0.007 \n",
      "[0/100][11/43] KL_real/fake: 4.567/4.540 mean_real/fake: -0.002/-0.004 var_real/fake: 0.007/0.007 \n",
      "[0/100][12/43] KL_real/fake: 4.588/4.559 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.007 \n",
      "[0/100][13/43] KL_real/fake: 4.593/4.572 mean_real/fake: -0.008/-0.005 var_real/fake: 0.006/0.007 \n",
      "[0/100][14/43] KL_real/fake: 4.625/4.590 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[0/100][15/43] KL_real/fake: 4.643/4.595 mean_real/fake: -0.001/-0.004 var_real/fake: 0.006/0.006 \n",
      "[0/100][16/43] KL_real/fake: 4.629/4.576 mean_real/fake: 0.001/-0.003 var_real/fake: 0.006/0.006 \n",
      "[0/100][17/43] KL_real/fake: 4.627/4.602 mean_real/fake: 0.001/-0.001 var_real/fake: 0.006/0.006 \n",
      "[0/100][18/43] KL_real/fake: 4.654/4.617 mean_real/fake: -0.003/-0.001 var_real/fake: 0.006/0.006 \n",
      "[0/100][19/43] KL_real/fake: 4.660/4.621 mean_real/fake: -0.006/-0.003 var_real/fake: 0.006/0.006 \n",
      "[0/100][20/43] KL_real/fake: 4.636/4.612 mean_real/fake: -0.006/-0.003 var_real/fake: 0.006/0.006 \n",
      "[0/100][21/43] KL_real/fake: 4.638/4.612 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.006 \n",
      "[0/100][22/43] KL_real/fake: 4.634/4.601 mean_real/fake: -0.003/-0.003 var_real/fake: 0.006/0.006 \n",
      "[0/100][23/43] KL_real/fake: 4.643/4.600 mean_real/fake: -0.002/-0.004 var_real/fake: 0.006/0.006 \n",
      "[0/100][24/43] KL_real/fake: 4.615/4.589 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[0/100][25/43] KL_real/fake: 4.577/4.555 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.007 \n",
      "[0/100][26/43] KL_real/fake: 4.579/4.556 mean_real/fake: -0.002/-0.002 var_real/fake: 0.006/0.007 \n",
      "[0/100][27/43] KL_real/fake: 4.565/4.547 mean_real/fake: -0.002/0.001 var_real/fake: 0.007/0.007 \n",
      "[0/100][28/43] KL_real/fake: 4.574/4.552 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.007 \n",
      "[0/100][29/43] KL_real/fake: 4.580/4.548 mean_real/fake: -0.003/-0.000 var_real/fake: 0.006/0.007 \n",
      "[0/100][30/43] KL_real/fake: 4.568/4.545 mean_real/fake: -0.002/-0.004 var_real/fake: 0.007/0.007 \n",
      "[0/100][31/43] KL_real/fake: 4.563/4.544 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[0/100][32/43] KL_real/fake: 4.578/4.547 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[0/100][33/43] KL_real/fake: 4.563/4.542 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[0/100][34/43] KL_real/fake: 4.567/4.542 mean_real/fake: -0.002/-0.005 var_real/fake: 0.007/0.007 \n",
      "[0/100][35/43] KL_real/fake: 4.560/4.539 mean_real/fake: -0.007/-0.004 var_real/fake: 0.007/0.007 \n",
      "[0/100][36/43] KL_real/fake: 4.563/4.542 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[0/100][37/43] KL_real/fake: 4.578/4.561 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.007 \n",
      "[0/100][38/43] KL_real/fake: 4.582/4.569 mean_real/fake: -0.003/-0.007 var_real/fake: 0.006/0.007 \n",
      "[0/100][39/43] KL_real/fake: 4.611/4.579 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[0/100][40/43] KL_real/fake: 4.626/4.597 mean_real/fake: -0.003/-0.006 var_real/fake: 0.006/0.006 \n",
      "[0/100][41/43] KL_real/fake: 4.651/4.634 mean_real/fake: -0.005/-0.002 var_real/fake: 0.006/0.006 \n",
      "[0/100][42/43] KL_real/fake: 4.692/4.659 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type _netG_Base. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type _netE_Base. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100][0/43] KL_real/fake: 4.686/4.637 mean_real/fake: -0.005/-0.003 var_real/fake: 0.006/0.006 \n",
      "[1/100][1/43] KL_real/fake: 4.651/4.620 mean_real/fake: -0.003/-0.002 var_real/fake: 0.006/0.006 \n",
      "[1/100][2/43] KL_real/fake: 4.652/4.610 mean_real/fake: 0.001/-0.004 var_real/fake: 0.006/0.006 \n",
      "[1/100][3/43] KL_real/fake: 4.619/4.597 mean_real/fake: -0.001/-0.004 var_real/fake: 0.006/0.006 \n",
      "[1/100][4/43] KL_real/fake: 4.612/4.578 mean_real/fake: -0.004/-0.002 var_real/fake: 0.006/0.006 \n",
      "[1/100][5/43] KL_real/fake: 4.581/4.544 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[1/100][6/43] KL_real/fake: 4.558/4.541 mean_real/fake: -0.002/-0.002 var_real/fake: 0.007/0.007 \n",
      "[1/100][7/43] KL_real/fake: 4.564/4.539 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[1/100][8/43] KL_real/fake: 4.578/4.559 mean_real/fake: -0.004/-0.002 var_real/fake: 0.007/0.007 \n",
      "[1/100][9/43] KL_real/fake: 4.611/4.578 mean_real/fake: -0.003/-0.001 var_real/fake: 0.006/0.006 \n",
      "[1/100][10/43] KL_real/fake: 4.622/4.583 mean_real/fake: -0.000/-0.001 var_real/fake: 0.006/0.006 \n",
      "[1/100][11/43] KL_real/fake: 4.612/4.585 mean_real/fake: -0.000/-0.003 var_real/fake: 0.006/0.006 \n",
      "[1/100][12/43] KL_real/fake: 4.617/4.583 mean_real/fake: 0.002/0.001 var_real/fake: 0.006/0.006 \n",
      "[1/100][13/43] KL_real/fake: 4.629/4.587 mean_real/fake: -0.004/-0.003 var_real/fake: 0.006/0.006 \n",
      "[1/100][14/43] KL_real/fake: 4.650/4.618 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[1/100][15/43] KL_real/fake: 4.682/4.638 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[1/100][16/43] KL_real/fake: 4.683/4.628 mean_real/fake: -0.008/-0.007 var_real/fake: 0.006/0.006 \n",
      "[1/100][17/43] KL_real/fake: 4.635/4.605 mean_real/fake: -0.005/-0.007 var_real/fake: 0.006/0.006 \n",
      "[1/100][18/43] KL_real/fake: 4.612/4.583 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[1/100][19/43] KL_real/fake: 4.586/4.574 mean_real/fake: -0.003/-0.007 var_real/fake: 0.006/0.007 \n",
      "[1/100][20/43] KL_real/fake: 4.571/4.542 mean_real/fake: -0.001/-0.005 var_real/fake: 0.007/0.007 \n",
      "[1/100][21/43] KL_real/fake: 4.578/4.557 mean_real/fake: -0.003/-0.006 var_real/fake: 0.007/0.007 \n",
      "[1/100][22/43] KL_real/fake: 4.591/4.561 mean_real/fake: -0.005/-0.003 var_real/fake: 0.006/0.007 \n",
      "[1/100][23/43] KL_real/fake: 4.596/4.559 mean_real/fake: -0.007/-0.003 var_real/fake: 0.006/0.007 \n",
      "[1/100][24/43] KL_real/fake: 4.596/4.570 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.007 \n",
      "[1/100][25/43] KL_real/fake: 4.602/4.574 mean_real/fake: -0.003/-0.001 var_real/fake: 0.006/0.006 \n",
      "[1/100][26/43] KL_real/fake: 4.608/4.583 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.006 \n",
      "[1/100][27/43] KL_real/fake: 4.604/4.585 mean_real/fake: -0.001/-0.003 var_real/fake: 0.006/0.006 \n",
      "[1/100][28/43] KL_real/fake: 4.621/4.588 mean_real/fake: -0.001/-0.004 var_real/fake: 0.006/0.006 \n",
      "[1/100][29/43] KL_real/fake: 4.616/4.578 mean_real/fake: -0.002/-0.002 var_real/fake: 0.006/0.006 \n",
      "[1/100][30/43] KL_real/fake: 4.609/4.585 mean_real/fake: -0.005/-0.003 var_real/fake: 0.006/0.006 \n",
      "[1/100][31/43] KL_real/fake: 4.589/4.570 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.007 \n",
      "[1/100][32/43] KL_real/fake: 4.567/4.550 mean_real/fake: -0.003/-0.003 var_real/fake: 0.007/0.007 \n",
      "[1/100][33/43] KL_real/fake: 4.578/4.565 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[1/100][34/43] KL_real/fake: 4.602/4.564 mean_real/fake: -0.002/-0.005 var_real/fake: 0.006/0.007 \n",
      "[1/100][35/43] KL_real/fake: 4.602/4.584 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.006 \n",
      "[1/100][36/43] KL_real/fake: 4.619/4.598 mean_real/fake: -0.002/-0.001 var_real/fake: 0.006/0.006 \n",
      "[1/100][37/43] KL_real/fake: 4.621/4.585 mean_real/fake: 0.000/0.000 var_real/fake: 0.006/0.006 \n",
      "[1/100][38/43] KL_real/fake: 4.611/4.594 mean_real/fake: -0.002/-0.001 var_real/fake: 0.006/0.006 \n",
      "[1/100][39/43] KL_real/fake: 4.583/4.574 mean_real/fake: 0.001/-0.003 var_real/fake: 0.006/0.007 \n",
      "[1/100][40/43] KL_real/fake: 4.584/4.572 mean_real/fake: -0.002/-0.004 var_real/fake: 0.006/0.007 \n",
      "[1/100][41/43] KL_real/fake: 4.579/4.560 mean_real/fake: -0.007/-0.004 var_real/fake: 0.007/0.007 \n",
      "[1/100][42/43] KL_real/fake: 4.600/4.576 mean_real/fake: -0.009/-0.006 var_real/fake: 0.006/0.007 \n",
      "[2/100][0/43] KL_real/fake: 4.622/4.605 mean_real/fake: -0.007/-0.007 var_real/fake: 0.006/0.006 \n",
      "[2/100][1/43] KL_real/fake: 4.650/4.624 mean_real/fake: -0.003/-0.002 var_real/fake: 0.006/0.006 \n",
      "[2/100][2/43] KL_real/fake: 4.640/4.604 mean_real/fake: -0.001/-0.004 var_real/fake: 0.006/0.006 \n",
      "[2/100][3/43] KL_real/fake: 4.626/4.612 mean_real/fake: -0.001/-0.003 var_real/fake: 0.006/0.006 \n",
      "[2/100][4/43] KL_real/fake: 4.616/4.600 mean_real/fake: -0.001/-0.002 var_real/fake: 0.006/0.006 \n",
      "[2/100][5/43] KL_real/fake: 4.620/4.600 mean_real/fake: -0.002/-0.004 var_real/fake: 0.006/0.006 \n",
      "[2/100][6/43] KL_real/fake: 4.638/4.607 mean_real/fake: -0.001/-0.002 var_real/fake: 0.006/0.006 \n",
      "[2/100][7/43] KL_real/fake: 4.624/4.601 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[2/100][8/43] KL_real/fake: 4.626/4.589 mean_real/fake: -0.004/-0.002 var_real/fake: 0.006/0.006 \n",
      "[2/100][9/43] KL_real/fake: 4.596/4.584 mean_real/fake: -0.006/-0.002 var_real/fake: 0.006/0.007 \n",
      "[2/100][10/43] KL_real/fake: 4.586/4.563 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.007 \n",
      "[2/100][11/43] KL_real/fake: 4.616/4.575 mean_real/fake: 0.000/-0.003 var_real/fake: 0.006/0.007 \n",
      "[2/100][12/43] KL_real/fake: 4.610/4.581 mean_real/fake: 0.002/0.001 var_real/fake: 0.006/0.006 \n",
      "[2/100][13/43] KL_real/fake: 4.627/4.597 mean_real/fake: 0.000/-0.002 var_real/fake: 0.006/0.006 \n",
      "[2/100][14/43] KL_real/fake: 4.629/4.600 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[2/100][15/43] KL_real/fake: 4.643/4.602 mean_real/fake: -0.008/-0.004 var_real/fake: 0.006/0.006 \n",
      "[2/100][16/43] KL_real/fake: 4.636/4.600 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[2/100][17/43] KL_real/fake: 4.650/4.629 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[2/100][18/43] KL_real/fake: 4.662/4.633 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[2/100][19/43] KL_real/fake: 4.666/4.634 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[2/100][20/43] KL_real/fake: 4.670/4.642 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[2/100][21/43] KL_real/fake: 4.656/4.624 mean_real/fake: -0.002/-0.005 var_real/fake: 0.006/0.006 \n",
      "[2/100][22/43] KL_real/fake: 4.645/4.633 mean_real/fake: -0.003/-0.003 var_real/fake: 0.006/0.006 \n",
      "[2/100][23/43] KL_real/fake: 4.644/4.626 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[2/100][24/43] KL_real/fake: 4.651/4.627 mean_real/fake: -0.008/-0.005 var_real/fake: 0.006/0.006 \n",
      "[2/100][25/43] KL_real/fake: 4.635/4.612 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[2/100][26/43] KL_real/fake: 4.616/4.597 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[2/100][27/43] KL_real/fake: 4.615/4.587 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[2/100][28/43] KL_real/fake: 4.606/4.588 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[2/100][29/43] KL_real/fake: 4.604/4.583 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[2/100][30/43] KL_real/fake: 4.599/4.585 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[2/100][31/43] KL_real/fake: 4.613/4.593 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[2/100][32/43] KL_real/fake: 4.628/4.609 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[2/100][33/43] KL_real/fake: 4.638/4.618 mean_real/fake: -0.008/-0.008 var_real/fake: 0.006/0.006 \n",
      "[2/100][34/43] KL_real/fake: 4.656/4.618 mean_real/fake: -0.008/-0.005 var_real/fake: 0.006/0.006 \n",
      "[2/100][35/43] KL_real/fake: 4.681/4.644 mean_real/fake: -0.009/-0.007 var_real/fake: 0.006/0.006 \n",
      "[2/100][36/43] KL_real/fake: 4.688/4.660 mean_real/fake: -0.008/-0.009 var_real/fake: 0.006/0.006 \n",
      "[2/100][37/43] KL_real/fake: 4.673/4.654 mean_real/fake: -0.008/-0.007 var_real/fake: 0.006/0.006 \n",
      "[2/100][38/43] KL_real/fake: 4.658/4.635 mean_real/fake: -0.006/-0.008 var_real/fake: 0.006/0.006 \n",
      "[2/100][39/43] KL_real/fake: 4.630/4.608 mean_real/fake: -0.004/-0.007 var_real/fake: 0.006/0.006 \n",
      "[2/100][40/43] KL_real/fake: 4.624/4.600 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/100][41/43] KL_real/fake: 4.612/4.598 mean_real/fake: -0.003/-0.003 var_real/fake: 0.006/0.006 \n",
      "[2/100][42/43] KL_real/fake: 4.606/4.594 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[3/100][0/43] KL_real/fake: 4.626/4.614 mean_real/fake: -0.005/-0.008 var_real/fake: 0.006/0.006 \n",
      "[3/100][1/43] KL_real/fake: 4.637/4.618 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[3/100][2/43] KL_real/fake: 4.640/4.618 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[3/100][3/43] KL_real/fake: 4.652/4.618 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[3/100][4/43] KL_real/fake: 4.668/4.632 mean_real/fake: -0.010/-0.009 var_real/fake: 0.006/0.006 \n",
      "[3/100][5/43] KL_real/fake: 4.667/4.634 mean_real/fake: -0.010/-0.008 var_real/fake: 0.006/0.006 \n",
      "[3/100][6/43] KL_real/fake: 4.660/4.630 mean_real/fake: -0.009/-0.009 var_real/fake: 0.006/0.006 \n",
      "[3/100][7/43] KL_real/fake: 4.649/4.626 mean_real/fake: -0.011/-0.007 var_real/fake: 0.006/0.006 \n",
      "[3/100][8/43] KL_real/fake: 4.626/4.604 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[3/100][9/43] KL_real/fake: 4.628/4.603 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[3/100][10/43] KL_real/fake: 4.618/4.596 mean_real/fake: -0.005/-0.007 var_real/fake: 0.006/0.006 \n",
      "[3/100][11/43] KL_real/fake: 4.606/4.587 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[3/100][12/43] KL_real/fake: 4.612/4.592 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[3/100][13/43] KL_real/fake: 4.613/4.590 mean_real/fake: -0.007/-0.003 var_real/fake: 0.006/0.006 \n",
      "[3/100][14/43] KL_real/fake: 4.622/4.583 mean_real/fake: -0.006/-0.008 var_real/fake: 0.006/0.006 \n",
      "[3/100][15/43] KL_real/fake: 4.612/4.587 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[3/100][16/43] KL_real/fake: 4.603/4.580 mean_real/fake: -0.007/-0.008 var_real/fake: 0.006/0.006 \n",
      "[3/100][17/43] KL_real/fake: 4.594/4.573 mean_real/fake: -0.005/-0.007 var_real/fake: 0.006/0.007 \n",
      "[3/100][18/43] KL_real/fake: 4.592/4.568 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.007 \n",
      "[3/100][19/43] KL_real/fake: 4.601/4.572 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.007 \n",
      "[3/100][20/43] KL_real/fake: 4.581/4.552 mean_real/fake: -0.002/-0.004 var_real/fake: 0.007/0.007 \n",
      "[3/100][21/43] KL_real/fake: 4.582/4.557 mean_real/fake: -0.002/-0.004 var_real/fake: 0.006/0.007 \n",
      "[3/100][22/43] KL_real/fake: 4.582/4.559 mean_real/fake: -0.004/-0.002 var_real/fake: 0.006/0.007 \n",
      "[3/100][23/43] KL_real/fake: 4.601/4.585 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[3/100][24/43] KL_real/fake: 4.622/4.591 mean_real/fake: -0.007/-0.007 var_real/fake: 0.006/0.006 \n",
      "[3/100][25/43] KL_real/fake: 4.643/4.609 mean_real/fake: -0.009/-0.007 var_real/fake: 0.006/0.006 \n",
      "[3/100][26/43] KL_real/fake: 4.654/4.619 mean_real/fake: -0.011/-0.007 var_real/fake: 0.006/0.006 \n",
      "[3/100][27/43] KL_real/fake: 4.637/4.615 mean_real/fake: -0.009/-0.006 var_real/fake: 0.006/0.006 \n",
      "[3/100][28/43] KL_real/fake: 4.660/4.628 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[3/100][29/43] KL_real/fake: 4.670/4.629 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[3/100][30/43] KL_real/fake: 4.658/4.644 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[3/100][31/43] KL_real/fake: 4.673/4.634 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.006 \n",
      "[3/100][32/43] KL_real/fake: 4.661/4.626 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[3/100][33/43] KL_real/fake: 4.653/4.612 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[3/100][34/43] KL_real/fake: 4.630/4.600 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[3/100][35/43] KL_real/fake: 4.629/4.606 mean_real/fake: -0.009/-0.006 var_real/fake: 0.006/0.006 \n",
      "[3/100][36/43] KL_real/fake: 4.642/4.610 mean_real/fake: -0.009/-0.009 var_real/fake: 0.006/0.006 \n",
      "[3/100][37/43] KL_real/fake: 4.634/4.611 mean_real/fake: -0.008/-0.009 var_real/fake: 0.006/0.006 \n",
      "[3/100][38/43] KL_real/fake: 4.627/4.591 mean_real/fake: -0.008/-0.008 var_real/fake: 0.006/0.006 \n",
      "[3/100][39/43] KL_real/fake: 4.628/4.592 mean_real/fake: -0.010/-0.007 var_real/fake: 0.006/0.006 \n",
      "[3/100][40/43] KL_real/fake: 4.611/4.587 mean_real/fake: -0.008/-0.008 var_real/fake: 0.006/0.006 \n",
      "[3/100][41/43] KL_real/fake: 4.611/4.590 mean_real/fake: -0.007/-0.009 var_real/fake: 0.006/0.006 \n",
      "[3/100][42/43] KL_real/fake: 4.621/4.602 mean_real/fake: -0.010/-0.007 var_real/fake: 0.006/0.006 \n",
      "[4/100][0/43] KL_real/fake: 4.621/4.597 mean_real/fake: -0.009/-0.007 var_real/fake: 0.006/0.006 \n",
      "[4/100][1/43] KL_real/fake: 4.625/4.603 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[4/100][2/43] KL_real/fake: 4.623/4.607 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[4/100][3/43] KL_real/fake: 4.636/4.615 mean_real/fake: -0.002/-0.006 var_real/fake: 0.006/0.006 \n",
      "[4/100][4/43] KL_real/fake: 4.657/4.630 mean_real/fake: -0.003/-0.003 var_real/fake: 0.006/0.006 \n",
      "[4/100][5/43] KL_real/fake: 4.673/4.650 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.006 \n",
      "[4/100][6/43] KL_real/fake: 4.665/4.648 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[4/100][7/43] KL_real/fake: 4.660/4.637 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[4/100][8/43] KL_real/fake: 4.653/4.630 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[4/100][9/43] KL_real/fake: 4.650/4.635 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[4/100][10/43] KL_real/fake: 4.636/4.621 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[4/100][11/43] KL_real/fake: 4.637/4.611 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[4/100][12/43] KL_real/fake: 4.642/4.612 mean_real/fake: -0.005/-0.003 var_real/fake: 0.006/0.006 \n",
      "[4/100][13/43] KL_real/fake: 4.637/4.610 mean_real/fake: -0.004/-0.002 var_real/fake: 0.006/0.006 \n",
      "[4/100][14/43] KL_real/fake: 4.637/4.604 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.006 \n",
      "[4/100][15/43] KL_real/fake: 4.629/4.614 mean_real/fake: -0.004/-0.007 var_real/fake: 0.006/0.006 \n",
      "[4/100][16/43] KL_real/fake: 4.635/4.620 mean_real/fake: -0.004/-0.008 var_real/fake: 0.006/0.006 \n",
      "[4/100][17/43] KL_real/fake: 4.647/4.614 mean_real/fake: -0.007/-0.007 var_real/fake: 0.006/0.006 \n",
      "[4/100][18/43] KL_real/fake: 4.658/4.623 mean_real/fake: -0.011/-0.008 var_real/fake: 0.006/0.006 \n",
      "[4/100][19/43] KL_real/fake: 4.650/4.623 mean_real/fake: -0.012/-0.007 var_real/fake: 0.006/0.006 \n",
      "[4/100][20/43] KL_real/fake: 4.637/4.610 mean_real/fake: -0.008/-0.009 var_real/fake: 0.006/0.006 \n",
      "[4/100][21/43] KL_real/fake: 4.626/4.600 mean_real/fake: -0.007/-0.007 var_real/fake: 0.006/0.006 \n",
      "[4/100][22/43] KL_real/fake: 4.629/4.603 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[4/100][23/43] KL_real/fake: 4.621/4.596 mean_real/fake: -0.005/-0.007 var_real/fake: 0.006/0.006 \n",
      "[4/100][24/43] KL_real/fake: 4.615/4.597 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[4/100][25/43] KL_real/fake: 4.608/4.589 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[4/100][26/43] KL_real/fake: 4.587/4.568 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.007 \n",
      "[4/100][27/43] KL_real/fake: 4.583/4.562 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.007 \n",
      "[4/100][28/43] KL_real/fake: 4.581/4.557 mean_real/fake: -0.006/-0.008 var_real/fake: 0.006/0.007 \n",
      "[4/100][29/43] KL_real/fake: 4.593/4.562 mean_real/fake: -0.007/-0.008 var_real/fake: 0.006/0.007 \n",
      "[4/100][30/43] KL_real/fake: 4.606/4.573 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.007 \n",
      "[4/100][31/43] KL_real/fake: 4.604/4.578 mean_real/fake: -0.005/-0.009 var_real/fake: 0.006/0.006 \n",
      "[4/100][32/43] KL_real/fake: 4.614/4.589 mean_real/fake: -0.004/-0.007 var_real/fake: 0.006/0.006 \n",
      "[4/100][33/43] KL_real/fake: 4.627/4.597 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[4/100][34/43] KL_real/fake: 4.627/4.595 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[4/100][35/43] KL_real/fake: 4.610/4.589 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[4/100][36/43] KL_real/fake: 4.584/4.568 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.007 \n",
      "[4/100][37/43] KL_real/fake: 4.581/4.558 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.007 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/100][38/43] KL_real/fake: 4.571/4.547 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[4/100][39/43] KL_real/fake: 4.568/4.552 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[4/100][40/43] KL_real/fake: 4.575/4.560 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.007 \n",
      "[4/100][41/43] KL_real/fake: 4.576/4.565 mean_real/fake: -0.005/-0.003 var_real/fake: 0.006/0.007 \n",
      "[4/100][42/43] KL_real/fake: 4.580/4.563 mean_real/fake: -0.003/-0.006 var_real/fake: 0.006/0.007 \n",
      "[5/100][0/43] KL_real/fake: 4.588/4.572 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[5/100][1/43] KL_real/fake: 4.580/4.567 mean_real/fake: -0.007/-0.004 var_real/fake: 0.006/0.007 \n",
      "[5/100][2/43] KL_real/fake: 4.591/4.570 mean_real/fake: -0.007/-0.009 var_real/fake: 0.006/0.007 \n",
      "[5/100][3/43] KL_real/fake: 4.579/4.566 mean_real/fake: -0.006/-0.007 var_real/fake: 0.006/0.007 \n",
      "[5/100][4/43] KL_real/fake: 4.570/4.549 mean_real/fake: -0.008/-0.006 var_real/fake: 0.007/0.007 \n",
      "[5/100][5/43] KL_real/fake: 4.570/4.552 mean_real/fake: -0.006/-0.008 var_real/fake: 0.007/0.007 \n",
      "[5/100][6/43] KL_real/fake: 4.581/4.565 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.007 \n",
      "[5/100][7/43] KL_real/fake: 4.581/4.560 mean_real/fake: -0.006/-0.008 var_real/fake: 0.006/0.007 \n",
      "[5/100][8/43] KL_real/fake: 4.575/4.555 mean_real/fake: -0.005/-0.007 var_real/fake: 0.006/0.007 \n",
      "[5/100][9/43] KL_real/fake: 4.575/4.551 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.007 \n",
      "[5/100][10/43] KL_real/fake: 4.582/4.555 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.007 \n",
      "[5/100][11/43] KL_real/fake: 4.597/4.565 mean_real/fake: -0.008/-0.007 var_real/fake: 0.006/0.007 \n",
      "[5/100][12/43] KL_real/fake: 4.607/4.571 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[5/100][13/43] KL_real/fake: 4.603/4.584 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[5/100][14/43] KL_real/fake: 4.605/4.587 mean_real/fake: -0.002/-0.003 var_real/fake: 0.006/0.006 \n",
      "[5/100][15/43] KL_real/fake: 4.603/4.581 mean_real/fake: -0.000/-0.003 var_real/fake: 0.006/0.006 \n",
      "[5/100][16/43] KL_real/fake: 4.591/4.574 mean_real/fake: -0.001/-0.004 var_real/fake: 0.006/0.006 \n",
      "[5/100][17/43] KL_real/fake: 4.577/4.562 mean_real/fake: -0.000/-0.004 var_real/fake: 0.007/0.007 \n",
      "[5/100][18/43] KL_real/fake: 4.574/4.551 mean_real/fake: -0.004/-0.002 var_real/fake: 0.007/0.007 \n",
      "[5/100][19/43] KL_real/fake: 4.569/4.550 mean_real/fake: -0.006/-0.002 var_real/fake: 0.007/0.007 \n",
      "[5/100][20/43] KL_real/fake: 4.585/4.561 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.007 \n",
      "[5/100][21/43] KL_real/fake: 4.591/4.568 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.007 \n",
      "[5/100][22/43] KL_real/fake: 4.587/4.570 mean_real/fake: -0.004/-0.003 var_real/fake: 0.006/0.006 \n",
      "[5/100][23/43] KL_real/fake: 4.590/4.570 mean_real/fake: -0.002/-0.002 var_real/fake: 0.006/0.006 \n",
      "[5/100][24/43] KL_real/fake: 4.599/4.567 mean_real/fake: 0.002/-0.002 var_real/fake: 0.006/0.007 \n",
      "[5/100][25/43] KL_real/fake: 4.621/4.577 mean_real/fake: 0.000/-0.004 var_real/fake: 0.006/0.006 \n",
      "[5/100][26/43] KL_real/fake: 4.624/4.599 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[5/100][27/43] KL_real/fake: 4.640/4.615 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[5/100][28/43] KL_real/fake: 4.652/4.629 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[5/100][29/43] KL_real/fake: 4.671/4.648 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[5/100][30/43] KL_real/fake: 4.697/4.662 mean_real/fake: -0.007/-0.008 var_real/fake: 0.006/0.006 \n",
      "[5/100][31/43] KL_real/fake: 4.726/4.677 mean_real/fake: -0.005/-0.003 var_real/fake: 0.006/0.006 \n",
      "[5/100][32/43] KL_real/fake: 4.777/4.697 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[5/100][33/43] KL_real/fake: 4.784/4.707 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[5/100][34/43] KL_real/fake: 4.782/4.705 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.006 \n",
      "[5/100][35/43] KL_real/fake: 4.796/4.707 mean_real/fake: -0.003/-0.006 var_real/fake: 0.006/0.006 \n",
      "[5/100][36/43] KL_real/fake: 4.762/4.682 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[5/100][37/43] KL_real/fake: 4.732/4.663 mean_real/fake: -0.009/-0.003 var_real/fake: 0.006/0.006 \n",
      "[5/100][38/43] KL_real/fake: 4.728/4.668 mean_real/fake: -0.006/-0.008 var_real/fake: 0.006/0.006 \n",
      "[5/100][39/43] KL_real/fake: 4.699/4.646 mean_real/fake: -0.002/-0.007 var_real/fake: 0.006/0.006 \n",
      "[5/100][40/43] KL_real/fake: 4.680/4.648 mean_real/fake: -0.004/-0.007 var_real/fake: 0.006/0.006 \n",
      "[5/100][41/43] KL_real/fake: 4.681/4.655 mean_real/fake: -0.008/-0.008 var_real/fake: 0.006/0.006 \n",
      "[5/100][42/43] KL_real/fake: 4.692/4.658 mean_real/fake: -0.009/-0.006 var_real/fake: 0.006/0.006 \n",
      "[6/100][0/43] KL_real/fake: 4.691/4.654 mean_real/fake: -0.010/-0.008 var_real/fake: 0.006/0.006 \n",
      "[6/100][1/43] KL_real/fake: 4.704/4.659 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[6/100][2/43] KL_real/fake: 4.717/4.677 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[6/100][3/43] KL_real/fake: 4.724/4.690 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[6/100][4/43] KL_real/fake: 4.731/4.683 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[6/100][5/43] KL_real/fake: 4.706/4.665 mean_real/fake: -0.006/-0.007 var_real/fake: 0.006/0.006 \n",
      "[6/100][6/43] KL_real/fake: 4.692/4.652 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[6/100][7/43] KL_real/fake: 4.669/4.649 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[6/100][8/43] KL_real/fake: 4.653/4.628 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[6/100][9/43] KL_real/fake: 4.652/4.616 mean_real/fake: -0.006/-0.010 var_real/fake: 0.006/0.006 \n",
      "[6/100][10/43] KL_real/fake: 4.657/4.620 mean_real/fake: -0.007/-0.007 var_real/fake: 0.006/0.006 \n",
      "[6/100][11/43] KL_real/fake: 4.667/4.637 mean_real/fake: -0.008/-0.010 var_real/fake: 0.006/0.006 \n",
      "[6/100][12/43] KL_real/fake: 4.671/4.634 mean_real/fake: -0.010/-0.010 var_real/fake: 0.006/0.006 \n",
      "[6/100][13/43] KL_real/fake: 4.677/4.636 mean_real/fake: -0.009/-0.006 var_real/fake: 0.006/0.006 \n",
      "[6/100][14/43] KL_real/fake: 4.673/4.649 mean_real/fake: -0.009/-0.007 var_real/fake: 0.006/0.006 \n",
      "[6/100][15/43] KL_real/fake: 4.689/4.645 mean_real/fake: -0.006/-0.011 var_real/fake: 0.006/0.006 \n",
      "[6/100][16/43] KL_real/fake: 4.700/4.665 mean_real/fake: -0.010/-0.008 var_real/fake: 0.006/0.006 \n",
      "[6/100][17/43] KL_real/fake: 4.706/4.671 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[6/100][18/43] KL_real/fake: 4.708/4.668 mean_real/fake: -0.008/-0.007 var_real/fake: 0.006/0.006 \n",
      "[6/100][19/43] KL_real/fake: 4.718/4.672 mean_real/fake: -0.007/-0.007 var_real/fake: 0.006/0.006 \n",
      "[6/100][20/43] KL_real/fake: 4.707/4.678 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[6/100][21/43] KL_real/fake: 4.705/4.681 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[6/100][22/43] KL_real/fake: 4.703/4.676 mean_real/fake: -0.002/-0.007 var_real/fake: 0.006/0.006 \n",
      "[6/100][23/43] KL_real/fake: 4.706/4.673 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[6/100][24/43] KL_real/fake: 4.693/4.661 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[6/100][25/43] KL_real/fake: 4.682/4.646 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[6/100][26/43] KL_real/fake: 4.659/4.627 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[6/100][27/43] KL_real/fake: 4.655/4.620 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[6/100][28/43] KL_real/fake: 4.653/4.616 mean_real/fake: -0.004/-0.003 var_real/fake: 0.006/0.006 \n",
      "[6/100][29/43] KL_real/fake: 4.650/4.626 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[6/100][30/43] KL_real/fake: 4.655/4.633 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[6/100][31/43] KL_real/fake: 4.663/4.640 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[6/100][32/43] KL_real/fake: 4.669/4.642 mean_real/fake: -0.007/-0.008 var_real/fake: 0.006/0.006 \n",
      "[6/100][33/43] KL_real/fake: 4.668/4.642 mean_real/fake: -0.009/-0.007 var_real/fake: 0.006/0.006 \n",
      "[6/100][34/43] KL_real/fake: 4.666/4.648 mean_real/fake: -0.008/-0.007 var_real/fake: 0.006/0.006 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/100][35/43] KL_real/fake: 4.669/4.644 mean_real/fake: -0.008/-0.008 var_real/fake: 0.006/0.006 \n",
      "[6/100][36/43] KL_real/fake: 4.665/4.634 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[6/100][37/43] KL_real/fake: 4.652/4.628 mean_real/fake: -0.005/-0.008 var_real/fake: 0.006/0.006 \n",
      "[6/100][38/43] KL_real/fake: 4.655/4.629 mean_real/fake: -0.007/-0.007 var_real/fake: 0.006/0.006 \n",
      "[6/100][39/43] KL_real/fake: 4.667/4.640 mean_real/fake: -0.009/-0.009 var_real/fake: 0.006/0.006 \n",
      "[6/100][40/43] KL_real/fake: 4.675/4.648 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[6/100][41/43] KL_real/fake: 4.668/4.647 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[6/100][42/43] KL_real/fake: 4.662/4.647 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[7/100][0/43] KL_real/fake: 4.656/4.637 mean_real/fake: -0.005/-0.007 var_real/fake: 0.006/0.006 \n",
      "[7/100][1/43] KL_real/fake: 4.655/4.639 mean_real/fake: -0.002/-0.004 var_real/fake: 0.006/0.006 \n",
      "[7/100][2/43] KL_real/fake: 4.644/4.613 mean_real/fake: -0.002/-0.004 var_real/fake: 0.006/0.006 \n",
      "[7/100][3/43] KL_real/fake: 4.631/4.607 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[7/100][4/43] KL_real/fake: 4.632/4.608 mean_real/fake: -0.002/-0.006 var_real/fake: 0.006/0.006 \n",
      "[7/100][5/43] KL_real/fake: 4.637/4.618 mean_real/fake: -0.003/-0.002 var_real/fake: 0.006/0.006 \n",
      "[7/100][6/43] KL_real/fake: 4.653/4.637 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[7/100][7/43] KL_real/fake: 4.652/4.629 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[7/100][8/43] KL_real/fake: 4.641/4.620 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[7/100][9/43] KL_real/fake: 4.637/4.610 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[7/100][10/43] KL_real/fake: 4.634/4.610 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[7/100][11/43] KL_real/fake: 4.647/4.619 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[7/100][12/43] KL_real/fake: 4.644/4.610 mean_real/fake: -0.005/-0.007 var_real/fake: 0.006/0.006 \n",
      "[7/100][13/43] KL_real/fake: 4.647/4.628 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[7/100][14/43] KL_real/fake: 4.653/4.624 mean_real/fake: -0.005/-0.007 var_real/fake: 0.006/0.006 \n",
      "[7/100][15/43] KL_real/fake: 4.662/4.630 mean_real/fake: -0.009/-0.008 var_real/fake: 0.006/0.006 \n",
      "[7/100][16/43] KL_real/fake: 4.663/4.626 mean_real/fake: -0.010/-0.007 var_real/fake: 0.006/0.006 \n",
      "[7/100][17/43] KL_real/fake: 4.663/4.620 mean_real/fake: -0.011/-0.008 var_real/fake: 0.006/0.006 \n",
      "[7/100][18/43] KL_real/fake: 4.656/4.616 mean_real/fake: -0.011/-0.007 var_real/fake: 0.006/0.006 \n",
      "[7/100][19/43] KL_real/fake: 4.643/4.614 mean_real/fake: -0.008/-0.009 var_real/fake: 0.006/0.006 \n",
      "[7/100][20/43] KL_real/fake: 4.634/4.606 mean_real/fake: -0.004/-0.007 var_real/fake: 0.006/0.006 \n",
      "[7/100][21/43] KL_real/fake: 4.629/4.601 mean_real/fake: -0.005/-0.007 var_real/fake: 0.006/0.006 \n",
      "[7/100][22/43] KL_real/fake: 4.615/4.602 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[7/100][23/43] KL_real/fake: 4.621/4.599 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[7/100][24/43] KL_real/fake: 4.618/4.608 mean_real/fake: -0.007/-0.007 var_real/fake: 0.006/0.006 \n",
      "[7/100][25/43] KL_real/fake: 4.614/4.604 mean_real/fake: -0.008/-0.005 var_real/fake: 0.006/0.006 \n",
      "[7/100][26/43] KL_real/fake: 4.608/4.596 mean_real/fake: -0.005/-0.008 var_real/fake: 0.006/0.006 \n",
      "[7/100][27/43] KL_real/fake: 4.605/4.589 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[7/100][28/43] KL_real/fake: 4.605/4.588 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[7/100][29/43] KL_real/fake: 4.609/4.581 mean_real/fake: -0.004/-0.007 var_real/fake: 0.006/0.006 \n",
      "[7/100][30/43] KL_real/fake: 4.607/4.582 mean_real/fake: -0.002/-0.005 var_real/fake: 0.006/0.006 \n",
      "[7/100][31/43] KL_real/fake: 4.598/4.582 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[7/100][32/43] KL_real/fake: 4.603/4.581 mean_real/fake: -0.008/-0.007 var_real/fake: 0.006/0.006 \n",
      "[7/100][33/43] KL_real/fake: 4.601/4.583 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[7/100][34/43] KL_real/fake: 4.608/4.587 mean_real/fake: -0.006/-0.007 var_real/fake: 0.006/0.006 \n",
      "[7/100][35/43] KL_real/fake: 4.609/4.585 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[7/100][36/43] KL_real/fake: 4.617/4.595 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[7/100][37/43] KL_real/fake: 4.619/4.599 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[7/100][38/43] KL_real/fake: 4.622/4.605 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[7/100][39/43] KL_real/fake: 4.648/4.613 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.006 \n",
      "[7/100][40/43] KL_real/fake: 4.642/4.624 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[7/100][41/43] KL_real/fake: 4.650/4.629 mean_real/fake: -0.003/-0.001 var_real/fake: 0.006/0.006 \n",
      "[7/100][42/43] KL_real/fake: 4.659/4.631 mean_real/fake: -0.002/-0.005 var_real/fake: 0.006/0.006 \n",
      "[8/100][0/43] KL_real/fake: 4.660/4.636 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.006 \n",
      "[8/100][1/43] KL_real/fake: 4.662/4.640 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[8/100][2/43] KL_real/fake: 4.649/4.631 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[8/100][3/43] KL_real/fake: 4.649/4.634 mean_real/fake: -0.008/-0.005 var_real/fake: 0.006/0.006 \n",
      "[8/100][4/43] KL_real/fake: 4.642/4.620 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[8/100][5/43] KL_real/fake: 4.632/4.617 mean_real/fake: -0.009/-0.006 var_real/fake: 0.006/0.006 \n",
      "[8/100][6/43] KL_real/fake: 4.639/4.619 mean_real/fake: -0.007/-0.007 var_real/fake: 0.006/0.006 \n",
      "[8/100][7/43] KL_real/fake: 4.644/4.619 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[8/100][8/43] KL_real/fake: 4.646/4.618 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.006 \n",
      "[8/100][9/43] KL_real/fake: 4.639/4.619 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.006 \n",
      "[8/100][10/43] KL_real/fake: 4.644/4.624 mean_real/fake: -0.005/-0.007 var_real/fake: 0.006/0.006 \n",
      "[8/100][11/43] KL_real/fake: 4.643/4.630 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[8/100][12/43] KL_real/fake: 4.659/4.632 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[8/100][13/43] KL_real/fake: 4.643/4.624 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[8/100][14/43] KL_real/fake: 4.634/4.616 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[8/100][15/43] KL_real/fake: 4.629/4.612 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[8/100][16/43] KL_real/fake: 4.630/4.619 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[8/100][17/43] KL_real/fake: 4.633/4.619 mean_real/fake: -0.008/-0.008 var_real/fake: 0.006/0.006 \n",
      "[8/100][18/43] KL_real/fake: 4.630/4.611 mean_real/fake: -0.010/-0.010 var_real/fake: 0.006/0.006 \n",
      "[8/100][19/43] KL_real/fake: 4.625/4.606 mean_real/fake: -0.007/-0.009 var_real/fake: 0.006/0.006 \n",
      "[8/100][20/43] KL_real/fake: 4.624/4.608 mean_real/fake: -0.008/-0.009 var_real/fake: 0.006/0.006 \n",
      "[8/100][21/43] KL_real/fake: 4.635/4.612 mean_real/fake: -0.011/-0.008 var_real/fake: 0.006/0.006 \n",
      "[8/100][22/43] KL_real/fake: 4.640/4.605 mean_real/fake: -0.011/-0.009 var_real/fake: 0.006/0.006 \n",
      "[8/100][23/43] KL_real/fake: 4.618/4.596 mean_real/fake: -0.010/-0.007 var_real/fake: 0.006/0.006 \n",
      "[8/100][24/43] KL_real/fake: 4.607/4.591 mean_real/fake: -0.010/-0.008 var_real/fake: 0.006/0.006 \n",
      "[8/100][25/43] KL_real/fake: 4.597/4.584 mean_real/fake: -0.008/-0.009 var_real/fake: 0.006/0.006 \n",
      "[8/100][26/43] KL_real/fake: 4.602/4.583 mean_real/fake: -0.008/-0.008 var_real/fake: 0.006/0.006 \n",
      "[8/100][27/43] KL_real/fake: 4.604/4.589 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[8/100][28/43] KL_real/fake: 4.606/4.592 mean_real/fake: -0.006/-0.008 var_real/fake: 0.006/0.006 \n",
      "[8/100][29/43] KL_real/fake: 4.609/4.593 mean_real/fake: -0.006/-0.007 var_real/fake: 0.006/0.006 \n",
      "[8/100][30/43] KL_real/fake: 4.608/4.600 mean_real/fake: -0.005/-0.008 var_real/fake: 0.006/0.006 \n",
      "[8/100][31/43] KL_real/fake: 4.611/4.597 mean_real/fake: -0.007/-0.008 var_real/fake: 0.006/0.006 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/100][32/43] KL_real/fake: 4.617/4.602 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[8/100][33/43] KL_real/fake: 4.622/4.611 mean_real/fake: -0.008/-0.005 var_real/fake: 0.006/0.006 \n",
      "[8/100][34/43] KL_real/fake: 4.637/4.621 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[8/100][35/43] KL_real/fake: 4.649/4.633 mean_real/fake: -0.007/-0.004 var_real/fake: 0.006/0.006 \n",
      "[8/100][36/43] KL_real/fake: 4.647/4.640 mean_real/fake: -0.003/-0.002 var_real/fake: 0.006/0.006 \n",
      "[8/100][37/43] KL_real/fake: 4.654/4.630 mean_real/fake: -0.002/-0.004 var_real/fake: 0.006/0.006 \n",
      "[8/100][38/43] KL_real/fake: 4.653/4.625 mean_real/fake: -0.002/-0.002 var_real/fake: 0.006/0.006 \n",
      "[8/100][39/43] KL_real/fake: 4.641/4.625 mean_real/fake: -0.001/-0.004 var_real/fake: 0.006/0.006 \n",
      "[8/100][40/43] KL_real/fake: 4.641/4.618 mean_real/fake: -0.003/-0.006 var_real/fake: 0.006/0.006 \n",
      "[8/100][41/43] KL_real/fake: 4.629/4.602 mean_real/fake: -0.005/-0.003 var_real/fake: 0.006/0.006 \n",
      "[8/100][42/43] KL_real/fake: 4.622/4.602 mean_real/fake: -0.004/-0.003 var_real/fake: 0.006/0.006 \n",
      "[9/100][0/43] KL_real/fake: 4.638/4.603 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[9/100][1/43] KL_real/fake: 4.622/4.598 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[9/100][2/43] KL_real/fake: 4.629/4.601 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.006 \n",
      "[9/100][3/43] KL_real/fake: 4.628/4.609 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[9/100][4/43] KL_real/fake: 4.645/4.622 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[9/100][5/43] KL_real/fake: 4.659/4.633 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[9/100][6/43] KL_real/fake: 4.664/4.642 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[9/100][7/43] KL_real/fake: 4.670/4.642 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[9/100][8/43] KL_real/fake: 4.652/4.638 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.006 \n",
      "[9/100][9/43] KL_real/fake: 4.648/4.632 mean_real/fake: -0.005/-0.003 var_real/fake: 0.006/0.006 \n",
      "[9/100][10/43] KL_real/fake: 4.642/4.617 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[9/100][11/43] KL_real/fake: 4.621/4.604 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[9/100][12/43] KL_real/fake: 4.614/4.602 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[9/100][13/43] KL_real/fake: 4.610/4.591 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[9/100][14/43] KL_real/fake: 4.608/4.587 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[9/100][15/43] KL_real/fake: 4.598/4.583 mean_real/fake: -0.005/-0.007 var_real/fake: 0.006/0.006 \n",
      "[9/100][16/43] KL_real/fake: 4.596/4.583 mean_real/fake: -0.007/-0.007 var_real/fake: 0.006/0.006 \n",
      "[9/100][17/43] KL_real/fake: 4.608/4.587 mean_real/fake: -0.008/-0.005 var_real/fake: 0.006/0.006 \n",
      "[9/100][18/43] KL_real/fake: 4.610/4.592 mean_real/fake: -0.007/-0.007 var_real/fake: 0.006/0.006 \n",
      "[9/100][19/43] KL_real/fake: 4.615/4.597 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[9/100][20/43] KL_real/fake: 4.617/4.602 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[9/100][21/43] KL_real/fake: 4.610/4.597 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[9/100][22/43] KL_real/fake: 4.608/4.593 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[9/100][23/43] KL_real/fake: 4.626/4.583 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[9/100][24/43] KL_real/fake: 4.612/4.588 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[9/100][25/43] KL_real/fake: 4.611/4.601 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[9/100][26/43] KL_real/fake: 4.627/4.607 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[9/100][27/43] KL_real/fake: 4.639/4.610 mean_real/fake: -0.003/-0.006 var_real/fake: 0.006/0.006 \n",
      "[9/100][28/43] KL_real/fake: 4.643/4.620 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[9/100][29/43] KL_real/fake: 4.642/4.618 mean_real/fake: -0.007/-0.008 var_real/fake: 0.006/0.006 \n",
      "[9/100][30/43] KL_real/fake: 4.619/4.611 mean_real/fake: -0.006/-0.007 var_real/fake: 0.006/0.006 \n",
      "[9/100][31/43] KL_real/fake: 4.612/4.599 mean_real/fake: -0.006/-0.003 var_real/fake: 0.006/0.006 \n",
      "[9/100][32/43] KL_real/fake: 4.602/4.589 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.006 \n",
      "[9/100][33/43] KL_real/fake: 4.598/4.585 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[9/100][34/43] KL_real/fake: 4.595/4.586 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[9/100][35/43] KL_real/fake: 4.601/4.590 mean_real/fake: -0.004/-0.007 var_real/fake: 0.006/0.006 \n",
      "[9/100][36/43] KL_real/fake: 4.607/4.595 mean_real/fake: -0.005/-0.003 var_real/fake: 0.006/0.006 \n",
      "[9/100][37/43] KL_real/fake: 4.600/4.592 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[9/100][38/43] KL_real/fake: 4.603/4.592 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[9/100][39/43] KL_real/fake: 4.601/4.581 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[9/100][40/43] KL_real/fake: 4.598/4.572 mean_real/fake: -0.002/-0.003 var_real/fake: 0.006/0.007 \n",
      "[9/100][41/43] KL_real/fake: 4.592/4.573 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[9/100][42/43] KL_real/fake: 4.586/4.577 mean_real/fake: -0.006/-0.007 var_real/fake: 0.006/0.006 \n",
      "[10/100][0/43] KL_real/fake: 4.604/4.591 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[10/100][1/43] KL_real/fake: 4.614/4.598 mean_real/fake: -0.009/-0.007 var_real/fake: 0.006/0.006 \n",
      "[10/100][2/43] KL_real/fake: 4.632/4.607 mean_real/fake: -0.010/-0.006 var_real/fake: 0.006/0.006 \n",
      "[10/100][3/43] KL_real/fake: 4.630/4.605 mean_real/fake: -0.009/-0.008 var_real/fake: 0.006/0.006 \n",
      "[10/100][4/43] KL_real/fake: 4.620/4.608 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[10/100][5/43] KL_real/fake: 4.619/4.612 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.006 \n",
      "[10/100][6/43] KL_real/fake: 4.621/4.606 mean_real/fake: -0.002/-0.005 var_real/fake: 0.006/0.006 \n",
      "[10/100][7/43] KL_real/fake: 4.625/4.614 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[10/100][8/43] KL_real/fake: 4.620/4.608 mean_real/fake: -0.006/-0.003 var_real/fake: 0.006/0.006 \n",
      "[10/100][9/43] KL_real/fake: 4.629/4.606 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[10/100][10/43] KL_real/fake: 4.624/4.609 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[10/100][11/43] KL_real/fake: 4.626/4.607 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[10/100][12/43] KL_real/fake: 4.621/4.610 mean_real/fake: -0.004/-0.007 var_real/fake: 0.006/0.006 \n",
      "[10/100][13/43] KL_real/fake: 4.627/4.604 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[10/100][14/43] KL_real/fake: 4.635/4.612 mean_real/fake: -0.008/-0.005 var_real/fake: 0.006/0.006 \n",
      "[10/100][15/43] KL_real/fake: 4.639/4.616 mean_real/fake: -0.008/-0.005 var_real/fake: 0.006/0.006 \n",
      "[10/100][16/43] KL_real/fake: 4.635/4.616 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[10/100][17/43] KL_real/fake: 4.641/4.620 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.006 \n",
      "[10/100][18/43] KL_real/fake: 4.642/4.629 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[10/100][19/43] KL_real/fake: 4.658/4.639 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[10/100][20/43] KL_real/fake: 4.663/4.645 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[10/100][21/43] KL_real/fake: 4.652/4.636 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[10/100][22/43] KL_real/fake: 4.657/4.635 mean_real/fake: -0.008/-0.007 var_real/fake: 0.006/0.006 \n",
      "[10/100][23/43] KL_real/fake: 4.652/4.633 mean_real/fake: -0.009/-0.007 var_real/fake: 0.006/0.006 \n",
      "[10/100][24/43] KL_real/fake: 4.645/4.631 mean_real/fake: -0.008/-0.008 var_real/fake: 0.006/0.006 \n",
      "[10/100][25/43] KL_real/fake: 4.650/4.636 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[10/100][26/43] KL_real/fake: 4.656/4.634 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[10/100][27/43] KL_real/fake: 4.654/4.642 mean_real/fake: -0.006/-0.007 var_real/fake: 0.006/0.006 \n",
      "[10/100][28/43] KL_real/fake: 4.671/4.647 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/100][29/43] KL_real/fake: 4.671/4.644 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[10/100][30/43] KL_real/fake: 4.651/4.641 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.006 \n",
      "[10/100][31/43] KL_real/fake: 4.649/4.632 mean_real/fake: -0.002/-0.005 var_real/fake: 0.006/0.006 \n",
      "[10/100][32/43] KL_real/fake: 4.658/4.636 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[10/100][33/43] KL_real/fake: 4.642/4.624 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[10/100][34/43] KL_real/fake: 4.637/4.621 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[10/100][35/43] KL_real/fake: 4.631/4.612 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.006 \n",
      "[10/100][36/43] KL_real/fake: 4.626/4.609 mean_real/fake: -0.003/-0.003 var_real/fake: 0.006/0.006 \n",
      "[10/100][37/43] KL_real/fake: 4.629/4.600 mean_real/fake: -0.003/-0.003 var_real/fake: 0.006/0.006 \n",
      "[10/100][38/43] KL_real/fake: 4.626/4.605 mean_real/fake: -0.005/-0.003 var_real/fake: 0.006/0.006 \n",
      "[10/100][39/43] KL_real/fake: 4.642/4.620 mean_real/fake: -0.004/-0.003 var_real/fake: 0.006/0.006 \n",
      "[10/100][40/43] KL_real/fake: 4.644/4.618 mean_real/fake: -0.001/-0.004 var_real/fake: 0.006/0.006 \n",
      "[10/100][41/43] KL_real/fake: 4.628/4.613 mean_real/fake: -0.002/-0.003 var_real/fake: 0.006/0.006 \n",
      "[10/100][42/43] KL_real/fake: 4.620/4.604 mean_real/fake: -0.002/-0.003 var_real/fake: 0.006/0.006 \n",
      "[11/100][0/43] KL_real/fake: 4.620/4.602 mean_real/fake: -0.002/-0.003 var_real/fake: 0.006/0.006 \n",
      "[11/100][1/43] KL_real/fake: 4.609/4.598 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.006 \n",
      "[11/100][2/43] KL_real/fake: 4.614/4.596 mean_real/fake: -0.004/-0.003 var_real/fake: 0.006/0.006 \n",
      "[11/100][3/43] KL_real/fake: 4.611/4.588 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[11/100][4/43] KL_real/fake: 4.595/4.586 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[11/100][5/43] KL_real/fake: 4.600/4.588 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[11/100][6/43] KL_real/fake: 4.597/4.577 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[11/100][7/43] KL_real/fake: 4.591/4.576 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[11/100][8/43] KL_real/fake: 4.593/4.577 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.006 \n",
      "[11/100][9/43] KL_real/fake: 4.589/4.577 mean_real/fake: -0.006/-0.003 var_real/fake: 0.006/0.006 \n",
      "[11/100][10/43] KL_real/fake: 4.595/4.571 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.007 \n",
      "[11/100][11/43] KL_real/fake: 4.585/4.571 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[11/100][12/43] KL_real/fake: 4.593/4.578 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[11/100][13/43] KL_real/fake: 4.601/4.578 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[11/100][14/43] KL_real/fake: 4.603/4.576 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[11/100][15/43] KL_real/fake: 4.596/4.577 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[11/100][16/43] KL_real/fake: 4.592/4.581 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.006 \n",
      "[11/100][17/43] KL_real/fake: 4.594/4.581 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[11/100][18/43] KL_real/fake: 4.599/4.580 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[11/100][19/43] KL_real/fake: 4.598/4.580 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[11/100][20/43] KL_real/fake: 4.586/4.575 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[11/100][21/43] KL_real/fake: 4.585/4.576 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[11/100][22/43] KL_real/fake: 4.603/4.579 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[11/100][23/43] KL_real/fake: 4.599/4.579 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[11/100][24/43] KL_real/fake: 4.609/4.595 mean_real/fake: -0.005/-0.007 var_real/fake: 0.006/0.006 \n",
      "[11/100][25/43] KL_real/fake: 4.623/4.606 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[11/100][26/43] KL_real/fake: 4.635/4.604 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[11/100][27/43] KL_real/fake: 4.623/4.599 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[11/100][28/43] KL_real/fake: 4.606/4.593 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[11/100][29/43] KL_real/fake: 4.596/4.584 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[11/100][30/43] KL_real/fake: 4.597/4.581 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[11/100][31/43] KL_real/fake: 4.595/4.577 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[11/100][32/43] KL_real/fake: 4.596/4.573 mean_real/fake: -0.002/-0.004 var_real/fake: 0.006/0.006 \n",
      "[11/100][33/43] KL_real/fake: 4.585/4.576 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[11/100][34/43] KL_real/fake: 4.594/4.576 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[11/100][35/43] KL_real/fake: 4.618/4.583 mean_real/fake: -0.006/-0.003 var_real/fake: 0.006/0.006 \n",
      "[11/100][36/43] KL_real/fake: 4.602/4.584 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[11/100][37/43] KL_real/fake: 4.592/4.583 mean_real/fake: -0.006/-0.007 var_real/fake: 0.006/0.006 \n",
      "[11/100][38/43] KL_real/fake: 4.592/4.574 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[11/100][39/43] KL_real/fake: 4.590/4.571 mean_real/fake: -0.002/-0.005 var_real/fake: 0.006/0.006 \n",
      "[11/100][40/43] KL_real/fake: 4.604/4.576 mean_real/fake: -0.001/-0.005 var_real/fake: 0.006/0.006 \n",
      "[11/100][41/43] KL_real/fake: 4.605/4.581 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.006 \n",
      "[11/100][42/43] KL_real/fake: 4.610/4.592 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[12/100][0/43] KL_real/fake: 4.608/4.599 mean_real/fake: -0.006/-0.007 var_real/fake: 0.006/0.006 \n",
      "[12/100][1/43] KL_real/fake: 4.604/4.595 mean_real/fake: -0.008/-0.005 var_real/fake: 0.006/0.006 \n",
      "[12/100][2/43] KL_real/fake: 4.619/4.600 mean_real/fake: -0.010/-0.005 var_real/fake: 0.006/0.006 \n",
      "[12/100][3/43] KL_real/fake: 4.619/4.598 mean_real/fake: -0.008/-0.007 var_real/fake: 0.006/0.006 \n",
      "[12/100][4/43] KL_real/fake: 4.622/4.600 mean_real/fake: -0.008/-0.005 var_real/fake: 0.006/0.006 \n",
      "[12/100][5/43] KL_real/fake: 4.615/4.601 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[12/100][6/43] KL_real/fake: 4.616/4.590 mean_real/fake: -0.003/-0.006 var_real/fake: 0.006/0.006 \n",
      "[12/100][7/43] KL_real/fake: 4.598/4.585 mean_real/fake: -0.002/-0.008 var_real/fake: 0.006/0.006 \n",
      "[12/100][8/43] KL_real/fake: 4.604/4.583 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.006 \n",
      "[12/100][9/43] KL_real/fake: 4.610/4.587 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.006 \n",
      "[12/100][10/43] KL_real/fake: 4.603/4.590 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[12/100][11/43] KL_real/fake: 4.608/4.590 mean_real/fake: -0.008/-0.003 var_real/fake: 0.006/0.006 \n",
      "[12/100][12/43] KL_real/fake: 4.611/4.595 mean_real/fake: -0.010/-0.006 var_real/fake: 0.006/0.006 \n",
      "[12/100][13/43] KL_real/fake: 4.611/4.590 mean_real/fake: -0.008/-0.008 var_real/fake: 0.006/0.006 \n",
      "[12/100][14/43] KL_real/fake: 4.608/4.586 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[12/100][15/43] KL_real/fake: 4.604/4.582 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[12/100][16/43] KL_real/fake: 4.613/4.586 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.006 \n",
      "[12/100][17/43] KL_real/fake: 4.613/4.581 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[12/100][18/43] KL_real/fake: 4.607/4.573 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.007 \n",
      "[12/100][19/43] KL_real/fake: 4.611/4.582 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[12/100][20/43] KL_real/fake: 4.607/4.582 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[12/100][21/43] KL_real/fake: 4.611/4.592 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[12/100][22/43] KL_real/fake: 4.611/4.594 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[12/100][23/43] KL_real/fake: 4.623/4.598 mean_real/fake: -0.008/-0.007 var_real/fake: 0.006/0.006 \n",
      "[12/100][24/43] KL_real/fake: 4.618/4.596 mean_real/fake: -0.007/-0.008 var_real/fake: 0.006/0.006 \n",
      "[12/100][25/43] KL_real/fake: 4.612/4.595 mean_real/fake: -0.008/-0.008 var_real/fake: 0.006/0.006 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/100][26/43] KL_real/fake: 4.610/4.600 mean_real/fake: -0.008/-0.007 var_real/fake: 0.006/0.006 \n",
      "[12/100][27/43] KL_real/fake: 4.619/4.599 mean_real/fake: -0.009/-0.008 var_real/fake: 0.006/0.006 \n",
      "[12/100][28/43] KL_real/fake: 4.614/4.590 mean_real/fake: -0.008/-0.007 var_real/fake: 0.006/0.006 \n",
      "[12/100][29/43] KL_real/fake: 4.603/4.584 mean_real/fake: -0.008/-0.007 var_real/fake: 0.006/0.006 \n",
      "[12/100][30/43] KL_real/fake: 4.596/4.583 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[12/100][31/43] KL_real/fake: 4.585/4.576 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[12/100][32/43] KL_real/fake: 4.587/4.571 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[12/100][33/43] KL_real/fake: 4.592/4.573 mean_real/fake: -0.007/-0.004 var_real/fake: 0.006/0.006 \n",
      "[12/100][34/43] KL_real/fake: 4.600/4.585 mean_real/fake: -0.007/-0.007 var_real/fake: 0.006/0.006 \n",
      "[12/100][35/43] KL_real/fake: 4.616/4.594 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[12/100][36/43] KL_real/fake: 4.597/4.585 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[12/100][37/43] KL_real/fake: 4.602/4.584 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[12/100][38/43] KL_real/fake: 4.587/4.573 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[12/100][39/43] KL_real/fake: 4.581/4.567 mean_real/fake: -0.006/-0.008 var_real/fake: 0.006/0.006 \n",
      "[12/100][40/43] KL_real/fake: 4.587/4.564 mean_real/fake: -0.007/-0.007 var_real/fake: 0.006/0.007 \n",
      "[12/100][41/43] KL_real/fake: 4.576/4.561 mean_real/fake: -0.006/-0.008 var_real/fake: 0.006/0.007 \n",
      "[12/100][42/43] KL_real/fake: 4.579/4.569 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[13/100][0/43] KL_real/fake: 4.584/4.566 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[13/100][1/43] KL_real/fake: 4.588/4.565 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[13/100][2/43] KL_real/fake: 4.593/4.575 mean_real/fake: -0.006/-0.003 var_real/fake: 0.006/0.006 \n",
      "[13/100][3/43] KL_real/fake: 4.594/4.576 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[13/100][4/43] KL_real/fake: 4.593/4.574 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[13/100][5/43] KL_real/fake: 4.583/4.567 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[13/100][6/43] KL_real/fake: 4.589/4.569 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[13/100][7/43] KL_real/fake: 4.602/4.578 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[13/100][8/43] KL_real/fake: 4.606/4.582 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[13/100][9/43] KL_real/fake: 4.615/4.594 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.006 \n",
      "[13/100][10/43] KL_real/fake: 4.619/4.595 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.006 \n",
      "[13/100][11/43] KL_real/fake: 4.611/4.591 mean_real/fake: -0.001/-0.004 var_real/fake: 0.006/0.006 \n",
      "[13/100][12/43] KL_real/fake: 4.605/4.581 mean_real/fake: -0.001/-0.003 var_real/fake: 0.006/0.006 \n",
      "[13/100][13/43] KL_real/fake: 4.592/4.577 mean_real/fake: -0.002/-0.006 var_real/fake: 0.006/0.006 \n",
      "[13/100][14/43] KL_real/fake: 4.587/4.566 mean_real/fake: -0.002/-0.004 var_real/fake: 0.006/0.007 \n",
      "[13/100][15/43] KL_real/fake: 4.588/4.567 mean_real/fake: -0.004/-0.001 var_real/fake: 0.006/0.007 \n",
      "[13/100][16/43] KL_real/fake: 4.586/4.560 mean_real/fake: -0.004/-0.002 var_real/fake: 0.006/0.007 \n",
      "[13/100][17/43] KL_real/fake: 4.592/4.562 mean_real/fake: -0.002/-0.003 var_real/fake: 0.006/0.007 \n",
      "[13/100][18/43] KL_real/fake: 4.588/4.564 mean_real/fake: -0.001/-0.000 var_real/fake: 0.006/0.007 \n",
      "[13/100][19/43] KL_real/fake: 4.593/4.571 mean_real/fake: -0.000/-0.003 var_real/fake: 0.006/0.007 \n",
      "[13/100][20/43] KL_real/fake: 4.591/4.571 mean_real/fake: -0.001/-0.000 var_real/fake: 0.006/0.007 \n",
      "[13/100][21/43] KL_real/fake: 4.585/4.566 mean_real/fake: -0.001/-0.004 var_real/fake: 0.006/0.007 \n",
      "[13/100][22/43] KL_real/fake: 4.590/4.572 mean_real/fake: -0.002/-0.002 var_real/fake: 0.006/0.006 \n",
      "[13/100][23/43] KL_real/fake: 4.595/4.572 mean_real/fake: -0.003/-0.003 var_real/fake: 0.006/0.006 \n",
      "[13/100][24/43] KL_real/fake: 4.616/4.581 mean_real/fake: -0.006/-0.003 var_real/fake: 0.006/0.006 \n",
      "[13/100][25/43] KL_real/fake: 4.618/4.586 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[13/100][26/43] KL_real/fake: 4.622/4.592 mean_real/fake: -0.006/-0.007 var_real/fake: 0.006/0.006 \n",
      "[13/100][27/43] KL_real/fake: 4.612/4.594 mean_real/fake: -0.004/-0.003 var_real/fake: 0.006/0.006 \n",
      "[13/100][28/43] KL_real/fake: 4.626/4.600 mean_real/fake: -0.005/-0.003 var_real/fake: 0.006/0.006 \n",
      "[13/100][29/43] KL_real/fake: 4.621/4.593 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[13/100][30/43] KL_real/fake: 4.617/4.581 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[13/100][31/43] KL_real/fake: 4.611/4.591 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[13/100][32/43] KL_real/fake: 4.622/4.603 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[13/100][33/43] KL_real/fake: 4.632/4.617 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[13/100][34/43] KL_real/fake: 4.638/4.621 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[13/100][35/43] KL_real/fake: 4.654/4.630 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[13/100][36/43] KL_real/fake: 4.650/4.632 mean_real/fake: -0.007/-0.007 var_real/fake: 0.006/0.006 \n",
      "[13/100][37/43] KL_real/fake: 4.649/4.627 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[13/100][38/43] KL_real/fake: 4.642/4.626 mean_real/fake: -0.008/-0.007 var_real/fake: 0.006/0.006 \n",
      "[13/100][39/43] KL_real/fake: 4.617/4.602 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[13/100][40/43] KL_real/fake: 4.607/4.595 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[13/100][41/43] KL_real/fake: 4.609/4.592 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[13/100][42/43] KL_real/fake: 4.599/4.580 mean_real/fake: -0.002/-0.006 var_real/fake: 0.006/0.006 \n",
      "[14/100][0/43] KL_real/fake: 4.590/4.573 mean_real/fake: -0.003/-0.006 var_real/fake: 0.006/0.006 \n",
      "[14/100][1/43] KL_real/fake: 4.588/4.573 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[14/100][2/43] KL_real/fake: 4.586/4.567 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.007 \n",
      "[14/100][3/43] KL_real/fake: 4.582/4.567 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.007 \n",
      "[14/100][4/43] KL_real/fake: 4.582/4.565 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.007 \n",
      "[14/100][5/43] KL_real/fake: 4.585/4.569 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[14/100][6/43] KL_real/fake: 4.595/4.574 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[14/100][7/43] KL_real/fake: 4.590/4.571 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.006 \n",
      "[14/100][8/43] KL_real/fake: 4.589/4.572 mean_real/fake: -0.002/-0.005 var_real/fake: 0.006/0.006 \n",
      "[14/100][9/43] KL_real/fake: 4.598/4.578 mean_real/fake: -0.001/-0.003 var_real/fake: 0.006/0.006 \n",
      "[14/100][10/43] KL_real/fake: 4.608/4.587 mean_real/fake: -0.003/-0.002 var_real/fake: 0.006/0.006 \n",
      "[14/100][11/43] KL_real/fake: 4.612/4.600 mean_real/fake: -0.004/-0.002 var_real/fake: 0.006/0.006 \n",
      "[14/100][12/43] KL_real/fake: 4.623/4.606 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[14/100][13/43] KL_real/fake: 4.646/4.608 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.006 \n",
      "[14/100][14/43] KL_real/fake: 4.635/4.604 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[14/100][15/43] KL_real/fake: 4.610/4.597 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[14/100][16/43] KL_real/fake: 4.610/4.591 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[14/100][17/43] KL_real/fake: 4.617/4.603 mean_real/fake: -0.007/-0.004 var_real/fake: 0.006/0.006 \n",
      "[14/100][18/43] KL_real/fake: 4.620/4.602 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[14/100][19/43] KL_real/fake: 4.620/4.598 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[14/100][20/43] KL_real/fake: 4.615/4.599 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[14/100][21/43] KL_real/fake: 4.623/4.599 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[14/100][22/43] KL_real/fake: 4.617/4.596 mean_real/fake: -0.004/-0.008 var_real/fake: 0.006/0.006 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/100][23/43] KL_real/fake: 4.615/4.593 mean_real/fake: -0.003/-0.006 var_real/fake: 0.006/0.006 \n",
      "[14/100][24/43] KL_real/fake: 4.621/4.592 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[14/100][25/43] KL_real/fake: 4.630/4.599 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[14/100][26/43] KL_real/fake: 4.623/4.591 mean_real/fake: -0.008/-0.005 var_real/fake: 0.006/0.006 \n",
      "[14/100][27/43] KL_real/fake: 4.631/4.605 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[14/100][28/43] KL_real/fake: 4.625/4.606 mean_real/fake: -0.007/-0.008 var_real/fake: 0.006/0.006 \n",
      "[14/100][29/43] KL_real/fake: 4.642/4.610 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[14/100][30/43] KL_real/fake: 4.635/4.619 mean_real/fake: -0.004/-0.003 var_real/fake: 0.006/0.006 \n",
      "[14/100][31/43] KL_real/fake: 4.640/4.625 mean_real/fake: -0.003/-0.006 var_real/fake: 0.006/0.006 \n",
      "[14/100][32/43] KL_real/fake: 4.645/4.633 mean_real/fake: -0.002/-0.003 var_real/fake: 0.006/0.006 \n",
      "[14/100][33/43] KL_real/fake: 4.663/4.637 mean_real/fake: -0.002/-0.003 var_real/fake: 0.006/0.006 \n",
      "[14/100][34/43] KL_real/fake: 4.679/4.651 mean_real/fake: -0.002/-0.004 var_real/fake: 0.006/0.006 \n",
      "[14/100][35/43] KL_real/fake: 4.666/4.646 mean_real/fake: -0.004/-0.003 var_real/fake: 0.006/0.006 \n",
      "[14/100][36/43] KL_real/fake: 4.661/4.639 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[14/100][37/43] KL_real/fake: 4.652/4.629 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[14/100][38/43] KL_real/fake: 4.637/4.622 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[14/100][39/43] KL_real/fake: 4.634/4.613 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[14/100][40/43] KL_real/fake: 4.627/4.606 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[14/100][41/43] KL_real/fake: 4.615/4.600 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[14/100][42/43] KL_real/fake: 4.614/4.597 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[15/100][0/43] KL_real/fake: 4.622/4.602 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[15/100][1/43] KL_real/fake: 4.625/4.610 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[15/100][2/43] KL_real/fake: 4.621/4.603 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[15/100][3/43] KL_real/fake: 4.624/4.607 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[15/100][4/43] KL_real/fake: 4.630/4.614 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[15/100][5/43] KL_real/fake: 4.626/4.619 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[15/100][6/43] KL_real/fake: 4.633/4.621 mean_real/fake: -0.005/-0.007 var_real/fake: 0.006/0.006 \n",
      "[15/100][7/43] KL_real/fake: 4.631/4.617 mean_real/fake: -0.005/-0.007 var_real/fake: 0.006/0.006 \n",
      "[15/100][8/43] KL_real/fake: 4.629/4.615 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[15/100][9/43] KL_real/fake: 4.629/4.618 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[15/100][10/43] KL_real/fake: 4.637/4.621 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[15/100][11/43] KL_real/fake: 4.627/4.619 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[15/100][12/43] KL_real/fake: 4.630/4.611 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[15/100][13/43] KL_real/fake: 4.625/4.605 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[15/100][14/43] KL_real/fake: 4.625/4.602 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[15/100][15/43] KL_real/fake: 4.623/4.599 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[15/100][16/43] KL_real/fake: 4.618/4.603 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[15/100][17/43] KL_real/fake: 4.626/4.611 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[15/100][18/43] KL_real/fake: 4.626/4.607 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[15/100][19/43] KL_real/fake: 4.622/4.604 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[15/100][20/43] KL_real/fake: 4.627/4.612 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[15/100][21/43] KL_real/fake: 4.622/4.607 mean_real/fake: -0.005/-0.003 var_real/fake: 0.006/0.006 \n",
      "[15/100][22/43] KL_real/fake: 4.609/4.600 mean_real/fake: -0.008/-0.007 var_real/fake: 0.006/0.006 \n",
      "[15/100][23/43] KL_real/fake: 4.613/4.592 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[15/100][24/43] KL_real/fake: 4.620/4.600 mean_real/fake: -0.007/-0.008 var_real/fake: 0.006/0.006 \n",
      "[15/100][25/43] KL_real/fake: 4.606/4.589 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[15/100][26/43] KL_real/fake: 4.593/4.582 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[15/100][27/43] KL_real/fake: 4.599/4.583 mean_real/fake: -0.004/-0.007 var_real/fake: 0.006/0.006 \n",
      "[15/100][28/43] KL_real/fake: 4.604/4.589 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[15/100][29/43] KL_real/fake: 4.607/4.594 mean_real/fake: -0.002/-0.006 var_real/fake: 0.006/0.006 \n",
      "[15/100][30/43] KL_real/fake: 4.612/4.594 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[15/100][31/43] KL_real/fake: 4.625/4.605 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[15/100][32/43] KL_real/fake: 4.629/4.611 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[15/100][33/43] KL_real/fake: 4.629/4.611 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[15/100][34/43] KL_real/fake: 4.630/4.617 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[15/100][35/43] KL_real/fake: 4.632/4.619 mean_real/fake: -0.007/-0.003 var_real/fake: 0.006/0.006 \n",
      "[15/100][36/43] KL_real/fake: 4.640/4.615 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[15/100][37/43] KL_real/fake: 4.633/4.614 mean_real/fake: -0.003/-0.006 var_real/fake: 0.006/0.006 \n",
      "[15/100][38/43] KL_real/fake: 4.625/4.610 mean_real/fake: -0.005/-0.007 var_real/fake: 0.006/0.006 \n",
      "[15/100][39/43] KL_real/fake: 4.612/4.600 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[15/100][40/43] KL_real/fake: 4.615/4.592 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[15/100][41/43] KL_real/fake: 4.598/4.587 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[15/100][42/43] KL_real/fake: 4.600/4.585 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[16/100][0/43] KL_real/fake: 4.596/4.586 mean_real/fake: -0.006/-0.007 var_real/fake: 0.006/0.006 \n",
      "[16/100][1/43] KL_real/fake: 4.594/4.580 mean_real/fake: -0.006/-0.008 var_real/fake: 0.006/0.006 \n",
      "[16/100][2/43] KL_real/fake: 4.597/4.578 mean_real/fake: -0.007/-0.007 var_real/fake: 0.006/0.006 \n",
      "[16/100][3/43] KL_real/fake: 4.582/4.562 mean_real/fake: -0.007/-0.008 var_real/fake: 0.006/0.007 \n",
      "[16/100][4/43] KL_real/fake: 4.588/4.558 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.007 \n",
      "[16/100][5/43] KL_real/fake: 4.578/4.555 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.007 \n",
      "[16/100][6/43] KL_real/fake: 4.575/4.558 mean_real/fake: -0.008/-0.007 var_real/fake: 0.006/0.007 \n",
      "[16/100][7/43] KL_real/fake: 4.568/4.551 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.007 \n",
      "[16/100][8/43] KL_real/fake: 4.565/4.550 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[16/100][9/43] KL_real/fake: 4.564/4.548 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[16/100][10/43] KL_real/fake: 4.563/4.549 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[16/100][11/43] KL_real/fake: 4.577/4.556 mean_real/fake: -0.003/-0.002 var_real/fake: 0.006/0.007 \n",
      "[16/100][12/43] KL_real/fake: 4.585/4.572 mean_real/fake: -0.005/-0.003 var_real/fake: 0.006/0.006 \n",
      "[16/100][13/43] KL_real/fake: 4.592/4.572 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[16/100][14/43] KL_real/fake: 4.606/4.577 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[16/100][15/43] KL_real/fake: 4.598/4.584 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[16/100][16/43] KL_real/fake: 4.608/4.581 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[16/100][17/43] KL_real/fake: 4.616/4.582 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[16/100][18/43] KL_real/fake: 4.622/4.583 mean_real/fake: -0.007/-0.007 var_real/fake: 0.006/0.006 \n",
      "[16/100][19/43] KL_real/fake: 4.627/4.590 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/100][20/43] KL_real/fake: 4.637/4.596 mean_real/fake: -0.009/-0.006 var_real/fake: 0.006/0.006 \n",
      "[16/100][21/43] KL_real/fake: 4.636/4.610 mean_real/fake: -0.008/-0.009 var_real/fake: 0.006/0.006 \n",
      "[16/100][22/43] KL_real/fake: 4.639/4.616 mean_real/fake: -0.006/-0.008 var_real/fake: 0.006/0.006 \n",
      "[16/100][23/43] KL_real/fake: 4.639/4.615 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[16/100][24/43] KL_real/fake: 4.651/4.622 mean_real/fake: -0.009/-0.005 var_real/fake: 0.006/0.006 \n",
      "[16/100][25/43] KL_real/fake: 4.642/4.620 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[16/100][26/43] KL_real/fake: 4.648/4.617 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[16/100][27/43] KL_real/fake: 4.634/4.616 mean_real/fake: -0.002/-0.003 var_real/fake: 0.006/0.006 \n",
      "[16/100][28/43] KL_real/fake: 4.636/4.619 mean_real/fake: 0.000/-0.002 var_real/fake: 0.006/0.006 \n",
      "[16/100][29/43] KL_real/fake: 4.629/4.614 mean_real/fake: -0.001/-0.005 var_real/fake: 0.006/0.006 \n",
      "[16/100][30/43] KL_real/fake: 4.624/4.613 mean_real/fake: -0.003/-0.001 var_real/fake: 0.006/0.006 \n",
      "[16/100][31/43] KL_real/fake: 4.622/4.610 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[16/100][32/43] KL_real/fake: 4.628/4.609 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[16/100][33/43] KL_real/fake: 4.624/4.607 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[16/100][34/43] KL_real/fake: 4.632/4.608 mean_real/fake: -0.010/-0.008 var_real/fake: 0.006/0.006 \n",
      "[16/100][35/43] KL_real/fake: 4.640/4.608 mean_real/fake: -0.009/-0.007 var_real/fake: 0.006/0.006 \n",
      "[16/100][36/43] KL_real/fake: 4.627/4.604 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[16/100][37/43] KL_real/fake: 4.608/4.597 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[16/100][38/43] KL_real/fake: 4.620/4.592 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[16/100][39/43] KL_real/fake: 4.609/4.589 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[16/100][40/43] KL_real/fake: 4.603/4.583 mean_real/fake: -0.002/-0.004 var_real/fake: 0.006/0.006 \n",
      "[16/100][41/43] KL_real/fake: 4.595/4.584 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.006 \n",
      "[16/100][42/43] KL_real/fake: 4.598/4.587 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.006 \n",
      "[17/100][0/43] KL_real/fake: 4.609/4.587 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[17/100][1/43] KL_real/fake: 4.606/4.592 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[17/100][2/43] KL_real/fake: 4.611/4.590 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[17/100][3/43] KL_real/fake: 4.610/4.593 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[17/100][4/43] KL_real/fake: 4.613/4.598 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[17/100][5/43] KL_real/fake: 4.613/4.599 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[17/100][6/43] KL_real/fake: 4.618/4.601 mean_real/fake: -0.002/-0.007 var_real/fake: 0.006/0.006 \n",
      "[17/100][7/43] KL_real/fake: 4.623/4.606 mean_real/fake: -0.003/-0.007 var_real/fake: 0.006/0.006 \n",
      "[17/100][8/43] KL_real/fake: 4.626/4.616 mean_real/fake: -0.007/-0.007 var_real/fake: 0.006/0.006 \n",
      "[17/100][9/43] KL_real/fake: 4.634/4.618 mean_real/fake: -0.009/-0.006 var_real/fake: 0.006/0.006 \n",
      "[17/100][10/43] KL_real/fake: 4.651/4.618 mean_real/fake: -0.008/-0.007 var_real/fake: 0.006/0.006 \n",
      "[17/100][11/43] KL_real/fake: 4.643/4.624 mean_real/fake: -0.009/-0.005 var_real/fake: 0.006/0.006 \n",
      "[17/100][12/43] KL_real/fake: 4.644/4.621 mean_real/fake: -0.008/-0.007 var_real/fake: 0.006/0.006 \n",
      "[17/100][13/43] KL_real/fake: 4.640/4.624 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[17/100][14/43] KL_real/fake: 4.648/4.625 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[17/100][15/43] KL_real/fake: 4.642/4.625 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.006 \n",
      "[17/100][16/43] KL_real/fake: 4.650/4.625 mean_real/fake: -0.002/-0.005 var_real/fake: 0.006/0.006 \n",
      "[17/100][17/43] KL_real/fake: 4.633/4.623 mean_real/fake: -0.004/-0.008 var_real/fake: 0.006/0.006 \n",
      "[17/100][18/43] KL_real/fake: 4.623/4.609 mean_real/fake: -0.005/-0.007 var_real/fake: 0.006/0.006 \n",
      "[17/100][19/43] KL_real/fake: 4.620/4.597 mean_real/fake: -0.009/-0.009 var_real/fake: 0.006/0.006 \n",
      "[17/100][20/43] KL_real/fake: 4.625/4.588 mean_real/fake: -0.011/-0.007 var_real/fake: 0.006/0.006 \n",
      "[17/100][21/43] KL_real/fake: 4.619/4.588 mean_real/fake: -0.011/-0.008 var_real/fake: 0.006/0.006 \n",
      "[17/100][22/43] KL_real/fake: 4.616/4.588 mean_real/fake: -0.009/-0.008 var_real/fake: 0.006/0.006 \n",
      "[17/100][23/43] KL_real/fake: 4.624/4.601 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[17/100][24/43] KL_real/fake: 4.638/4.612 mean_real/fake: -0.006/-0.007 var_real/fake: 0.006/0.006 \n",
      "[17/100][25/43] KL_real/fake: 4.634/4.616 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[17/100][26/43] KL_real/fake: 4.632/4.623 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[17/100][27/43] KL_real/fake: 4.636/4.621 mean_real/fake: -0.006/-0.007 var_real/fake: 0.006/0.006 \n",
      "[17/100][28/43] KL_real/fake: 4.632/4.613 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[17/100][29/43] KL_real/fake: 4.636/4.602 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[17/100][30/43] KL_real/fake: 4.611/4.594 mean_real/fake: -0.006/-0.008 var_real/fake: 0.006/0.006 \n",
      "[17/100][31/43] KL_real/fake: 4.609/4.593 mean_real/fake: -0.009/-0.008 var_real/fake: 0.006/0.006 \n",
      "[17/100][32/43] KL_real/fake: 4.606/4.592 mean_real/fake: -0.008/-0.007 var_real/fake: 0.006/0.006 \n",
      "[17/100][33/43] KL_real/fake: 4.605/4.593 mean_real/fake: -0.008/-0.008 var_real/fake: 0.006/0.006 \n",
      "[17/100][34/43] KL_real/fake: 4.611/4.595 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[17/100][35/43] KL_real/fake: 4.621/4.597 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[17/100][36/43] KL_real/fake: 4.625/4.607 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[17/100][37/43] KL_real/fake: 4.627/4.611 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[17/100][38/43] KL_real/fake: 4.628/4.616 mean_real/fake: -0.005/-0.007 var_real/fake: 0.006/0.006 \n",
      "[17/100][39/43] KL_real/fake: 4.627/4.613 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[17/100][40/43] KL_real/fake: 4.619/4.614 mean_real/fake: -0.006/-0.008 var_real/fake: 0.006/0.006 \n",
      "[17/100][41/43] KL_real/fake: 4.614/4.603 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[17/100][42/43] KL_real/fake: 4.621/4.600 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[18/100][0/43] KL_real/fake: 4.620/4.597 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[18/100][1/43] KL_real/fake: 4.619/4.603 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[18/100][2/43] KL_real/fake: 4.620/4.604 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[18/100][3/43] KL_real/fake: 4.624/4.610 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[18/100][4/43] KL_real/fake: 4.628/4.612 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[18/100][5/43] KL_real/fake: 4.635/4.617 mean_real/fake: -0.004/-0.003 var_real/fake: 0.006/0.006 \n",
      "[18/100][6/43] KL_real/fake: 4.626/4.617 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.006 \n",
      "[18/100][7/43] KL_real/fake: 4.626/4.608 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[18/100][8/43] KL_real/fake: 4.617/4.607 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[18/100][9/43] KL_real/fake: 4.619/4.601 mean_real/fake: -0.003/-0.003 var_real/fake: 0.006/0.006 \n",
      "[18/100][10/43] KL_real/fake: 4.618/4.605 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.006 \n",
      "[18/100][11/43] KL_real/fake: 4.631/4.607 mean_real/fake: -0.005/-0.002 var_real/fake: 0.006/0.006 \n",
      "[18/100][12/43] KL_real/fake: 4.635/4.614 mean_real/fake: -0.004/-0.002 var_real/fake: 0.006/0.006 \n",
      "[18/100][13/43] KL_real/fake: 4.627/4.616 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[18/100][14/43] KL_real/fake: 4.630/4.614 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[18/100][15/43] KL_real/fake: 4.619/4.610 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[18/100][16/43] KL_real/fake: 4.618/4.603 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/100][17/43] KL_real/fake: 4.618/4.599 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[18/100][18/43] KL_real/fake: 4.610/4.601 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[18/100][19/43] KL_real/fake: 4.616/4.593 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[18/100][20/43] KL_real/fake: 4.615/4.593 mean_real/fake: -0.007/-0.004 var_real/fake: 0.006/0.006 \n",
      "[18/100][21/43] KL_real/fake: 4.617/4.599 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[18/100][22/43] KL_real/fake: 4.619/4.601 mean_real/fake: -0.008/-0.007 var_real/fake: 0.006/0.006 \n",
      "[18/100][23/43] KL_real/fake: 4.609/4.597 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[18/100][24/43] KL_real/fake: 4.610/4.598 mean_real/fake: -0.005/-0.007 var_real/fake: 0.006/0.006 \n",
      "[18/100][25/43] KL_real/fake: 4.609/4.594 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[18/100][26/43] KL_real/fake: 4.605/4.590 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[18/100][27/43] KL_real/fake: 4.613/4.590 mean_real/fake: -0.002/-0.007 var_real/fake: 0.006/0.006 \n",
      "[18/100][28/43] KL_real/fake: 4.617/4.591 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[18/100][29/43] KL_real/fake: 4.608/4.586 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[18/100][30/43] KL_real/fake: 4.617/4.590 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[18/100][31/43] KL_real/fake: 4.611/4.586 mean_real/fake: -0.005/-0.003 var_real/fake: 0.006/0.006 \n",
      "[18/100][32/43] KL_real/fake: 4.602/4.586 mean_real/fake: -0.004/-0.003 var_real/fake: 0.006/0.006 \n",
      "[18/100][33/43] KL_real/fake: 4.598/4.583 mean_real/fake: -0.002/-0.004 var_real/fake: 0.006/0.006 \n",
      "[18/100][34/43] KL_real/fake: 4.601/4.580 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[18/100][35/43] KL_real/fake: 4.601/4.579 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.006 \n",
      "[18/100][36/43] KL_real/fake: 4.600/4.578 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[18/100][37/43] KL_real/fake: 4.611/4.579 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[18/100][38/43] KL_real/fake: 4.594/4.578 mean_real/fake: -0.008/-0.005 var_real/fake: 0.006/0.006 \n",
      "[18/100][39/43] KL_real/fake: 4.596/4.575 mean_real/fake: -0.008/-0.003 var_real/fake: 0.006/0.006 \n",
      "[18/100][40/43] KL_real/fake: 4.597/4.574 mean_real/fake: -0.007/-0.004 var_real/fake: 0.006/0.006 \n",
      "[18/100][41/43] KL_real/fake: 4.595/4.580 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[18/100][42/43] KL_real/fake: 4.596/4.581 mean_real/fake: -0.002/-0.003 var_real/fake: 0.006/0.006 \n",
      "[19/100][0/43] KL_real/fake: 4.603/4.583 mean_real/fake: 0.000/-0.002 var_real/fake: 0.006/0.006 \n",
      "[19/100][1/43] KL_real/fake: 4.612/4.590 mean_real/fake: 0.000/-0.003 var_real/fake: 0.006/0.006 \n",
      "[19/100][2/43] KL_real/fake: 4.607/4.591 mean_real/fake: -0.000/-0.004 var_real/fake: 0.006/0.006 \n",
      "[19/100][3/43] KL_real/fake: 4.615/4.594 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[19/100][4/43] KL_real/fake: 4.611/4.598 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[19/100][5/43] KL_real/fake: 4.607/4.592 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[19/100][6/43] KL_real/fake: 4.609/4.590 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[19/100][7/43] KL_real/fake: 4.607/4.587 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[19/100][8/43] KL_real/fake: 4.604/4.584 mean_real/fake: -0.007/-0.004 var_real/fake: 0.006/0.006 \n",
      "[19/100][9/43] KL_real/fake: 4.607/4.586 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[19/100][10/43] KL_real/fake: 4.605/4.585 mean_real/fake: -0.005/-0.007 var_real/fake: 0.006/0.006 \n",
      "[19/100][11/43] KL_real/fake: 4.603/4.586 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[19/100][12/43] KL_real/fake: 4.605/4.595 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[19/100][13/43] KL_real/fake: 4.626/4.599 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[19/100][14/43] KL_real/fake: 4.638/4.609 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[19/100][15/43] KL_real/fake: 4.637/4.615 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[19/100][16/43] KL_real/fake: 4.648/4.615 mean_real/fake: -0.009/-0.004 var_real/fake: 0.006/0.006 \n",
      "[19/100][17/43] KL_real/fake: 4.637/4.620 mean_real/fake: -0.007/-0.004 var_real/fake: 0.006/0.006 \n",
      "[19/100][18/43] KL_real/fake: 4.636/4.614 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[19/100][19/43] KL_real/fake: 4.635/4.614 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[19/100][20/43] KL_real/fake: 4.643/4.617 mean_real/fake: -0.002/-0.004 var_real/fake: 0.006/0.006 \n",
      "[19/100][21/43] KL_real/fake: 4.638/4.613 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[19/100][22/43] KL_real/fake: 4.644/4.612 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[19/100][23/43] KL_real/fake: 4.632/4.615 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[19/100][24/43] KL_real/fake: 4.633/4.613 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[19/100][25/43] KL_real/fake: 4.620/4.605 mean_real/fake: -0.007/-0.007 var_real/fake: 0.006/0.006 \n",
      "[19/100][26/43] KL_real/fake: 4.619/4.600 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[19/100][27/43] KL_real/fake: 4.612/4.598 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[19/100][28/43] KL_real/fake: 4.609/4.591 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[19/100][29/43] KL_real/fake: 4.611/4.588 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[19/100][30/43] KL_real/fake: 4.602/4.584 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[19/100][31/43] KL_real/fake: 4.601/4.577 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[19/100][32/43] KL_real/fake: 4.592/4.575 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[19/100][33/43] KL_real/fake: 4.597/4.574 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[19/100][34/43] KL_real/fake: 4.603/4.580 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[19/100][35/43] KL_real/fake: 4.605/4.578 mean_real/fake: -0.007/-0.004 var_real/fake: 0.006/0.006 \n",
      "[19/100][36/43] KL_real/fake: 4.602/4.581 mean_real/fake: -0.006/-0.007 var_real/fake: 0.006/0.006 \n",
      "[19/100][37/43] KL_real/fake: 4.600/4.586 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[19/100][38/43] KL_real/fake: 4.605/4.596 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[19/100][39/43] KL_real/fake: 4.612/4.597 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[19/100][40/43] KL_real/fake: 4.614/4.600 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[19/100][41/43] KL_real/fake: 4.617/4.599 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[19/100][42/43] KL_real/fake: 4.616/4.601 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[20/100][0/43] KL_real/fake: 4.615/4.594 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[20/100][1/43] KL_real/fake: 4.602/4.594 mean_real/fake: -0.005/-0.007 var_real/fake: 0.006/0.006 \n",
      "[20/100][2/43] KL_real/fake: 4.606/4.588 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[20/100][3/43] KL_real/fake: 4.613/4.587 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[20/100][4/43] KL_real/fake: 4.610/4.586 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[20/100][5/43] KL_real/fake: 4.599/4.589 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[20/100][6/43] KL_real/fake: 4.606/4.588 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[20/100][7/43] KL_real/fake: 4.606/4.592 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[20/100][8/43] KL_real/fake: 4.605/4.596 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[20/100][9/43] KL_real/fake: 4.614/4.593 mean_real/fake: -0.002/-0.005 var_real/fake: 0.006/0.006 \n",
      "[20/100][10/43] KL_real/fake: 4.612/4.593 mean_real/fake: -0.002/-0.004 var_real/fake: 0.006/0.006 \n",
      "[20/100][11/43] KL_real/fake: 4.607/4.600 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[20/100][12/43] KL_real/fake: 4.617/4.596 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.006 \n",
      "[20/100][13/43] KL_real/fake: 4.610/4.604 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/100][14/43] KL_real/fake: 4.617/4.607 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[20/100][15/43] KL_real/fake: 4.617/4.607 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[20/100][16/43] KL_real/fake: 4.614/4.600 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[20/100][17/43] KL_real/fake: 4.614/4.604 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[20/100][18/43] KL_real/fake: 4.609/4.599 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[20/100][19/43] KL_real/fake: 4.607/4.600 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[20/100][20/43] KL_real/fake: 4.622/4.592 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[20/100][21/43] KL_real/fake: 4.612/4.591 mean_real/fake: -0.006/-0.003 var_real/fake: 0.006/0.006 \n",
      "[20/100][22/43] KL_real/fake: 4.600/4.586 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[20/100][23/43] KL_real/fake: 4.598/4.582 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[20/100][24/43] KL_real/fake: 4.596/4.583 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[20/100][25/43] KL_real/fake: 4.598/4.584 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[20/100][26/43] KL_real/fake: 4.622/4.586 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[20/100][27/43] KL_real/fake: 4.617/4.601 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[20/100][28/43] KL_real/fake: 4.618/4.599 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[20/100][29/43] KL_real/fake: 4.613/4.599 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.006 \n",
      "[20/100][30/43] KL_real/fake: 4.615/4.608 mean_real/fake: -0.002/-0.004 var_real/fake: 0.006/0.006 \n",
      "[20/100][31/43] KL_real/fake: 4.625/4.608 mean_real/fake: -0.003/-0.003 var_real/fake: 0.006/0.006 \n",
      "[20/100][32/43] KL_real/fake: 4.633/4.603 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[20/100][33/43] KL_real/fake: 4.616/4.606 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[20/100][34/43] KL_real/fake: 4.621/4.601 mean_real/fake: -0.008/-0.004 var_real/fake: 0.006/0.006 \n",
      "[20/100][35/43] KL_real/fake: 4.618/4.599 mean_real/fake: -0.007/-0.007 var_real/fake: 0.006/0.006 \n",
      "[20/100][36/43] KL_real/fake: 4.602/4.587 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[20/100][37/43] KL_real/fake: 4.606/4.578 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[20/100][38/43] KL_real/fake: 4.601/4.582 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[20/100][39/43] KL_real/fake: 4.602/4.583 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[20/100][40/43] KL_real/fake: 4.606/4.584 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[20/100][41/43] KL_real/fake: 4.613/4.591 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[20/100][42/43] KL_real/fake: 4.618/4.596 mean_real/fake: -0.003/-0.003 var_real/fake: 0.006/0.006 \n",
      "[21/100][0/43] KL_real/fake: 4.618/4.602 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[21/100][1/43] KL_real/fake: 4.627/4.610 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[21/100][2/43] KL_real/fake: 4.634/4.616 mean_real/fake: -0.007/-0.007 var_real/fake: 0.006/0.006 \n",
      "[21/100][3/43] KL_real/fake: 4.624/4.613 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[21/100][4/43] KL_real/fake: 4.629/4.609 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.006 \n",
      "[21/100][5/43] KL_real/fake: 4.614/4.599 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[21/100][6/43] KL_real/fake: 4.614/4.591 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[21/100][7/43] KL_real/fake: 4.593/4.578 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[21/100][8/43] KL_real/fake: 4.585/4.567 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.007 \n",
      "[21/100][9/43] KL_real/fake: 4.587/4.572 mean_real/fake: -0.002/-0.006 var_real/fake: 0.006/0.006 \n",
      "[21/100][10/43] KL_real/fake: 4.585/4.574 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[21/100][11/43] KL_real/fake: 4.589/4.573 mean_real/fake: -0.005/-0.003 var_real/fake: 0.006/0.006 \n",
      "[21/100][12/43] KL_real/fake: 4.590/4.581 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[21/100][13/43] KL_real/fake: 4.589/4.579 mean_real/fake: -0.006/-0.007 var_real/fake: 0.006/0.006 \n",
      "[21/100][14/43] KL_real/fake: 4.592/4.583 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[21/100][15/43] KL_real/fake: 4.601/4.586 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[21/100][16/43] KL_real/fake: 4.605/4.591 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[21/100][17/43] KL_real/fake: 4.614/4.603 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[21/100][18/43] KL_real/fake: 4.621/4.601 mean_real/fake: -0.003/-0.002 var_real/fake: 0.006/0.006 \n",
      "[21/100][19/43] KL_real/fake: 4.626/4.605 mean_real/fake: -0.003/-0.002 var_real/fake: 0.006/0.006 \n",
      "[21/100][20/43] KL_real/fake: 4.620/4.604 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.006 \n",
      "[21/100][21/43] KL_real/fake: 4.620/4.606 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[21/100][22/43] KL_real/fake: 4.610/4.600 mean_real/fake: -0.004/-0.003 var_real/fake: 0.006/0.006 \n",
      "[21/100][23/43] KL_real/fake: 4.613/4.603 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[21/100][24/43] KL_real/fake: 4.607/4.593 mean_real/fake: -0.006/-0.002 var_real/fake: 0.006/0.006 \n",
      "[21/100][25/43] KL_real/fake: 4.608/4.588 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[21/100][26/43] KL_real/fake: 4.599/4.591 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[21/100][27/43] KL_real/fake: 4.599/4.592 mean_real/fake: -0.004/-0.003 var_real/fake: 0.006/0.006 \n",
      "[21/100][28/43] KL_real/fake: 4.605/4.593 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.006 \n",
      "[21/100][29/43] KL_real/fake: 4.607/4.592 mean_real/fake: -0.002/-0.003 var_real/fake: 0.006/0.006 \n",
      "[21/100][30/43] KL_real/fake: 4.607/4.595 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[21/100][31/43] KL_real/fake: 4.611/4.597 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[21/100][32/43] KL_real/fake: 4.615/4.596 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[21/100][33/43] KL_real/fake: 4.619/4.599 mean_real/fake: -0.008/-0.005 var_real/fake: 0.006/0.006 \n",
      "[21/100][34/43] KL_real/fake: 4.620/4.602 mean_real/fake: -0.007/-0.007 var_real/fake: 0.006/0.006 \n",
      "[21/100][35/43] KL_real/fake: 4.629/4.609 mean_real/fake: -0.008/-0.007 var_real/fake: 0.006/0.006 \n",
      "[21/100][36/43] KL_real/fake: 4.630/4.613 mean_real/fake: -0.007/-0.009 var_real/fake: 0.006/0.006 \n",
      "[21/100][37/43] KL_real/fake: 4.631/4.617 mean_real/fake: -0.008/-0.007 var_real/fake: 0.006/0.006 \n",
      "[21/100][38/43] KL_real/fake: 4.635/4.615 mean_real/fake: -0.008/-0.009 var_real/fake: 0.006/0.006 \n",
      "[21/100][39/43] KL_real/fake: 4.624/4.612 mean_real/fake: -0.008/-0.009 var_real/fake: 0.006/0.006 \n",
      "[21/100][40/43] KL_real/fake: 4.624/4.611 mean_real/fake: -0.007/-0.009 var_real/fake: 0.006/0.006 \n",
      "[21/100][41/43] KL_real/fake: 4.613/4.599 mean_real/fake: -0.007/-0.007 var_real/fake: 0.006/0.006 \n",
      "[21/100][42/43] KL_real/fake: 4.614/4.599 mean_real/fake: -0.008/-0.009 var_real/fake: 0.006/0.006 \n",
      "[22/100][0/43] KL_real/fake: 4.602/4.591 mean_real/fake: -0.009/-0.009 var_real/fake: 0.006/0.006 \n",
      "[22/100][1/43] KL_real/fake: 4.606/4.591 mean_real/fake: -0.009/-0.006 var_real/fake: 0.006/0.006 \n",
      "[22/100][2/43] KL_real/fake: 4.606/4.587 mean_real/fake: -0.010/-0.008 var_real/fake: 0.006/0.006 \n",
      "[22/100][3/43] KL_real/fake: 4.610/4.592 mean_real/fake: -0.009/-0.010 var_real/fake: 0.006/0.006 \n",
      "[22/100][4/43] KL_real/fake: 4.610/4.593 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.006 \n",
      "[22/100][5/43] KL_real/fake: 4.613/4.588 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[22/100][6/43] KL_real/fake: 4.605/4.588 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[22/100][7/43] KL_real/fake: 4.610/4.597 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[22/100][8/43] KL_real/fake: 4.608/4.596 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[22/100][9/43] KL_real/fake: 4.614/4.599 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[22/100][10/43] KL_real/fake: 4.607/4.596 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/100][11/43] KL_real/fake: 4.605/4.593 mean_real/fake: -0.002/-0.005 var_real/fake: 0.006/0.006 \n",
      "[22/100][12/43] KL_real/fake: 4.603/4.594 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[22/100][13/43] KL_real/fake: 4.602/4.591 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[22/100][14/43] KL_real/fake: 4.604/4.591 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[22/100][15/43] KL_real/fake: 4.604/4.593 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[22/100][16/43] KL_real/fake: 4.601/4.585 mean_real/fake: -0.002/-0.005 var_real/fake: 0.006/0.006 \n",
      "[22/100][17/43] KL_real/fake: 4.589/4.577 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.006 \n",
      "[22/100][18/43] KL_real/fake: 4.583/4.567 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.007 \n",
      "[22/100][19/43] KL_real/fake: 4.578/4.562 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[22/100][20/43] KL_real/fake: 4.585/4.557 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.007 \n",
      "[22/100][21/43] KL_real/fake: 4.597/4.565 mean_real/fake: -0.007/-0.003 var_real/fake: 0.006/0.007 \n",
      "[22/100][22/43] KL_real/fake: 4.582/4.563 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.007 \n",
      "[22/100][23/43] KL_real/fake: 4.576/4.558 mean_real/fake: -0.006/-0.003 var_real/fake: 0.006/0.007 \n",
      "[22/100][24/43] KL_real/fake: 4.572/4.562 mean_real/fake: -0.003/-0.002 var_real/fake: 0.006/0.007 \n",
      "[22/100][25/43] KL_real/fake: 4.578/4.557 mean_real/fake: -0.000/-0.002 var_real/fake: 0.006/0.007 \n",
      "[22/100][26/43] KL_real/fake: 4.571/4.553 mean_real/fake: -0.000/-0.001 var_real/fake: 0.006/0.007 \n",
      "[22/100][27/43] KL_real/fake: 4.577/4.558 mean_real/fake: 0.001/-0.001 var_real/fake: 0.006/0.007 \n",
      "[22/100][28/43] KL_real/fake: 4.572/4.557 mean_real/fake: -0.001/-0.002 var_real/fake: 0.006/0.007 \n",
      "[22/100][29/43] KL_real/fake: 4.579/4.558 mean_real/fake: -0.001/-0.002 var_real/fake: 0.006/0.007 \n",
      "[22/100][30/43] KL_real/fake: 4.574/4.564 mean_real/fake: -0.002/-0.004 var_real/fake: 0.006/0.007 \n",
      "[22/100][31/43] KL_real/fake: 4.575/4.568 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[22/100][32/43] KL_real/fake: 4.589/4.569 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[22/100][33/43] KL_real/fake: 4.587/4.565 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[22/100][34/43] KL_real/fake: 4.590/4.569 mean_real/fake: -0.005/-0.003 var_real/fake: 0.006/0.006 \n",
      "[22/100][35/43] KL_real/fake: 4.586/4.571 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.006 \n",
      "[22/100][36/43] KL_real/fake: 4.583/4.577 mean_real/fake: -0.005/-0.007 var_real/fake: 0.006/0.006 \n",
      "[22/100][37/43] KL_real/fake: 4.577/4.571 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[22/100][38/43] KL_real/fake: 4.569/4.556 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.007 \n",
      "[22/100][39/43] KL_real/fake: 4.558/4.540 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[22/100][40/43] KL_real/fake: 4.562/4.533 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[22/100][41/43] KL_real/fake: 4.565/4.535 mean_real/fake: -0.003/-0.003 var_real/fake: 0.006/0.007 \n",
      "[22/100][42/43] KL_real/fake: 4.558/4.537 mean_real/fake: -0.002/-0.002 var_real/fake: 0.007/0.007 \n",
      "[23/100][0/43] KL_real/fake: 4.566/4.540 mean_real/fake: -0.002/-0.001 var_real/fake: 0.007/0.007 \n",
      "[23/100][1/43] KL_real/fake: 4.570/4.548 mean_real/fake: -0.001/-0.001 var_real/fake: 0.006/0.007 \n",
      "[23/100][2/43] KL_real/fake: 4.572/4.554 mean_real/fake: -0.002/-0.004 var_real/fake: 0.006/0.007 \n",
      "[23/100][3/43] KL_real/fake: 4.576/4.549 mean_real/fake: -0.002/-0.002 var_real/fake: 0.006/0.007 \n",
      "[23/100][4/43] KL_real/fake: 4.571/4.547 mean_real/fake: -0.002/-0.004 var_real/fake: 0.006/0.007 \n",
      "[23/100][5/43] KL_real/fake: 4.563/4.548 mean_real/fake: -0.001/-0.002 var_real/fake: 0.007/0.007 \n",
      "[23/100][6/43] KL_real/fake: 4.560/4.543 mean_real/fake: -0.002/-0.004 var_real/fake: 0.007/0.007 \n",
      "[23/100][7/43] KL_real/fake: 4.561/4.549 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[23/100][8/43] KL_real/fake: 4.553/4.540 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[23/100][9/43] KL_real/fake: 4.553/4.540 mean_real/fake: -0.003/-0.006 var_real/fake: 0.007/0.007 \n",
      "[23/100][10/43] KL_real/fake: 4.558/4.543 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[23/100][11/43] KL_real/fake: 4.566/4.551 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.007 \n",
      "[23/100][12/43] KL_real/fake: 4.571/4.560 mean_real/fake: -0.006/-0.003 var_real/fake: 0.006/0.007 \n",
      "[23/100][13/43] KL_real/fake: 4.571/4.563 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[23/100][14/43] KL_real/fake: 4.577/4.564 mean_real/fake: -0.002/-0.004 var_real/fake: 0.006/0.006 \n",
      "[23/100][15/43] KL_real/fake: 4.579/4.568 mean_real/fake: -0.002/-0.003 var_real/fake: 0.006/0.006 \n",
      "[23/100][16/43] KL_real/fake: 4.575/4.557 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.007 \n",
      "[23/100][17/43] KL_real/fake: 4.568/4.557 mean_real/fake: -0.002/-0.001 var_real/fake: 0.006/0.007 \n",
      "[23/100][18/43] KL_real/fake: 4.565/4.551 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.007 \n",
      "[23/100][19/43] KL_real/fake: 4.556/4.543 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[23/100][20/43] KL_real/fake: 4.549/4.538 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[23/100][21/43] KL_real/fake: 4.546/4.536 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[23/100][22/43] KL_real/fake: 4.550/4.537 mean_real/fake: -0.007/-0.007 var_real/fake: 0.007/0.007 \n",
      "[23/100][23/43] KL_real/fake: 4.551/4.540 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[23/100][24/43] KL_real/fake: 4.558/4.543 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[23/100][25/43] KL_real/fake: 4.558/4.542 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[23/100][26/43] KL_real/fake: 4.557/4.542 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[23/100][27/43] KL_real/fake: 4.552/4.545 mean_real/fake: -0.003/-0.003 var_real/fake: 0.007/0.007 \n",
      "[23/100][28/43] KL_real/fake: 4.558/4.542 mean_real/fake: -0.001/-0.002 var_real/fake: 0.007/0.007 \n",
      "[23/100][29/43] KL_real/fake: 4.561/4.547 mean_real/fake: -0.000/-0.003 var_real/fake: 0.007/0.007 \n",
      "[23/100][30/43] KL_real/fake: 4.570/4.554 mean_real/fake: 0.001/-0.001 var_real/fake: 0.006/0.007 \n",
      "[23/100][31/43] KL_real/fake: 4.576/4.555 mean_real/fake: -0.002/-0.004 var_real/fake: 0.006/0.007 \n",
      "[23/100][32/43] KL_real/fake: 4.578/4.565 mean_real/fake: -0.001/-0.002 var_real/fake: 0.006/0.006 \n",
      "[23/100][33/43] KL_real/fake: 4.576/4.567 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.006 \n",
      "[23/100][34/43] KL_real/fake: 4.574/4.567 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[23/100][35/43] KL_real/fake: 4.577/4.557 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.007 \n",
      "[23/100][36/43] KL_real/fake: 4.568/4.556 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.007 \n",
      "[23/100][37/43] KL_real/fake: 4.572/4.553 mean_real/fake: -0.007/-0.004 var_real/fake: 0.006/0.007 \n",
      "[23/100][38/43] KL_real/fake: 4.563/4.554 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[23/100][39/43] KL_real/fake: 4.568/4.556 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.007 \n",
      "[23/100][40/43] KL_real/fake: 4.561/4.552 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[23/100][41/43] KL_real/fake: 4.558/4.551 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[23/100][42/43] KL_real/fake: 4.564/4.553 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[24/100][0/43] KL_real/fake: 4.566/4.551 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.007 \n",
      "[24/100][1/43] KL_real/fake: 4.564/4.545 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.007 \n",
      "[24/100][2/43] KL_real/fake: 4.564/4.549 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.007 \n",
      "[24/100][3/43] KL_real/fake: 4.565/4.552 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.007 \n",
      "[24/100][4/43] KL_real/fake: 4.564/4.555 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.007 \n",
      "[24/100][5/43] KL_real/fake: 4.579/4.552 mean_real/fake: -0.008/-0.004 var_real/fake: 0.006/0.007 \n",
      "[24/100][6/43] KL_real/fake: 4.577/4.561 mean_real/fake: -0.007/-0.003 var_real/fake: 0.006/0.007 \n",
      "[24/100][7/43] KL_real/fake: 4.582/4.564 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24/100][8/43] KL_real/fake: 4.586/4.565 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.006 \n",
      "[24/100][9/43] KL_real/fake: 4.581/4.561 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.007 \n",
      "[24/100][10/43] KL_real/fake: 4.585/4.557 mean_real/fake: -0.001/-0.005 var_real/fake: 0.006/0.007 \n",
      "[24/100][11/43] KL_real/fake: 4.577/4.559 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.007 \n",
      "[24/100][12/43] KL_real/fake: 4.584/4.559 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.007 \n",
      "[24/100][13/43] KL_real/fake: 4.583/4.559 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.007 \n",
      "[24/100][14/43] KL_real/fake: 4.576/4.561 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.007 \n",
      "[24/100][15/43] KL_real/fake: 4.576/4.560 mean_real/fake: -0.005/-0.007 var_real/fake: 0.006/0.007 \n",
      "[24/100][16/43] KL_real/fake: 4.575/4.557 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.007 \n",
      "[24/100][17/43] KL_real/fake: 4.565/4.555 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[24/100][18/43] KL_real/fake: 4.566/4.553 mean_real/fake: -0.006/-0.007 var_real/fake: 0.006/0.007 \n",
      "[24/100][19/43] KL_real/fake: 4.567/4.557 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.007 \n",
      "[24/100][20/43] KL_real/fake: 4.567/4.551 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[24/100][21/43] KL_real/fake: 4.560/4.550 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.007 \n",
      "[24/100][22/43] KL_real/fake: 4.561/4.549 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.007 \n",
      "[24/100][23/43] KL_real/fake: 4.556/4.549 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[24/100][24/43] KL_real/fake: 4.563/4.552 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.007 \n",
      "[24/100][25/43] KL_real/fake: 4.559/4.550 mean_real/fake: -0.003/-0.002 var_real/fake: 0.007/0.007 \n",
      "[24/100][26/43] KL_real/fake: 4.564/4.559 mean_real/fake: -0.002/-0.002 var_real/fake: 0.006/0.007 \n",
      "[24/100][27/43] KL_real/fake: 4.563/4.551 mean_real/fake: 0.000/-0.003 var_real/fake: 0.007/0.007 \n",
      "[24/100][28/43] KL_real/fake: 4.561/4.547 mean_real/fake: 0.000/-0.002 var_real/fake: 0.007/0.007 \n",
      "[24/100][29/43] KL_real/fake: 4.555/4.550 mean_real/fake: -0.002/-0.000 var_real/fake: 0.007/0.007 \n",
      "[24/100][30/43] KL_real/fake: 4.567/4.548 mean_real/fake: -0.002/-0.004 var_real/fake: 0.006/0.007 \n",
      "[24/100][31/43] KL_real/fake: 4.564/4.551 mean_real/fake: 0.001/-0.002 var_real/fake: 0.007/0.007 \n",
      "[24/100][32/43] KL_real/fake: 4.566/4.549 mean_real/fake: 0.000/-0.004 var_real/fake: 0.007/0.007 \n",
      "[24/100][33/43] KL_real/fake: 4.566/4.557 mean_real/fake: -0.001/-0.004 var_real/fake: 0.007/0.007 \n",
      "[24/100][34/43] KL_real/fake: 4.571/4.550 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.007 \n",
      "[24/100][35/43] KL_real/fake: 4.571/4.551 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[24/100][36/43] KL_real/fake: 4.565/4.550 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[24/100][37/43] KL_real/fake: 4.569/4.550 mean_real/fake: -0.008/-0.005 var_real/fake: 0.007/0.007 \n",
      "[24/100][38/43] KL_real/fake: 4.570/4.551 mean_real/fake: -0.007/-0.004 var_real/fake: 0.007/0.007 \n",
      "[24/100][39/43] KL_real/fake: 4.583/4.550 mean_real/fake: -0.007/-0.004 var_real/fake: 0.006/0.007 \n",
      "[24/100][40/43] KL_real/fake: 4.582/4.559 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.007 \n",
      "[24/100][41/43] KL_real/fake: 4.581/4.567 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.007 \n",
      "[24/100][42/43] KL_real/fake: 4.597/4.566 mean_real/fake: -0.002/-0.004 var_real/fake: 0.006/0.007 \n",
      "Adjusting learning rate from 0.000200 to 0.000100 on E and G\n",
      "[25/100][0/43] KL_real/fake: 4.605/4.574 mean_real/fake: -0.001/-0.004 var_real/fake: 0.006/0.006 \n",
      "[25/100][1/43] KL_real/fake: 4.587/4.570 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[25/100][2/43] KL_real/fake: 4.597/4.571 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.007 \n",
      "[25/100][3/43] KL_real/fake: 4.609/4.571 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.007 \n",
      "[25/100][4/43] KL_real/fake: 4.582/4.569 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.007 \n",
      "[25/100][5/43] KL_real/fake: 4.584/4.571 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.007 \n",
      "[25/100][6/43] KL_real/fake: 4.579/4.574 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[25/100][7/43] KL_real/fake: 4.579/4.566 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.007 \n",
      "[25/100][8/43] KL_real/fake: 4.579/4.566 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.007 \n",
      "[25/100][9/43] KL_real/fake: 4.577/4.566 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.007 \n",
      "[25/100][10/43] KL_real/fake: 4.574/4.567 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.007 \n",
      "[25/100][11/43] KL_real/fake: 4.569/4.560 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[25/100][12/43] KL_real/fake: 4.572/4.561 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[25/100][13/43] KL_real/fake: 4.565/4.556 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[25/100][14/43] KL_real/fake: 4.564/4.554 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[25/100][15/43] KL_real/fake: 4.561/4.553 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[25/100][16/43] KL_real/fake: 4.574/4.551 mean_real/fake: -0.003/-0.006 var_real/fake: 0.007/0.007 \n",
      "[25/100][17/43] KL_real/fake: 4.562/4.551 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[25/100][18/43] KL_real/fake: 4.563/4.557 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[25/100][19/43] KL_real/fake: 4.566/4.556 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[25/100][20/43] KL_real/fake: 4.565/4.560 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[25/100][21/43] KL_real/fake: 4.574/4.560 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[25/100][22/43] KL_real/fake: 4.574/4.560 mean_real/fake: -0.006/-0.003 var_real/fake: 0.006/0.007 \n",
      "[25/100][23/43] KL_real/fake: 4.566/4.559 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[25/100][24/43] KL_real/fake: 4.566/4.563 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[25/100][25/43] KL_real/fake: 4.576/4.563 mean_real/fake: -0.004/-0.003 var_real/fake: 0.006/0.007 \n",
      "[25/100][26/43] KL_real/fake: 4.566/4.563 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[25/100][27/43] KL_real/fake: 4.569/4.560 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[25/100][28/43] KL_real/fake: 4.569/4.566 mean_real/fake: -0.004/-0.002 var_real/fake: 0.007/0.007 \n",
      "[25/100][29/43] KL_real/fake: 4.575/4.561 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[25/100][30/43] KL_real/fake: 4.570/4.564 mean_real/fake: -0.006/-0.003 var_real/fake: 0.007/0.007 \n",
      "[25/100][31/43] KL_real/fake: 4.571/4.562 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[25/100][32/43] KL_real/fake: 4.572/4.563 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[25/100][33/43] KL_real/fake: 4.566/4.563 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[25/100][34/43] KL_real/fake: 4.568/4.562 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[25/100][35/43] KL_real/fake: 4.569/4.564 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[25/100][36/43] KL_real/fake: 4.569/4.564 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[25/100][37/43] KL_real/fake: 4.583/4.569 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.007 \n",
      "[25/100][38/43] KL_real/fake: 4.574/4.572 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.007 \n",
      "[25/100][39/43] KL_real/fake: 4.578/4.568 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.007 \n",
      "[25/100][40/43] KL_real/fake: 4.580/4.572 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.007 \n",
      "[25/100][41/43] KL_real/fake: 4.579/4.574 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[25/100][42/43] KL_real/fake: 4.586/4.575 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[26/100][0/43] KL_real/fake: 4.581/4.578 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[26/100][1/43] KL_real/fake: 4.581/4.581 mean_real/fake: -0.007/-0.007 var_real/fake: 0.006/0.006 \n",
      "[26/100][2/43] KL_real/fake: 4.580/4.577 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[26/100][3/43] KL_real/fake: 4.581/4.572 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26/100][4/43] KL_real/fake: 4.578/4.573 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[26/100][5/43] KL_real/fake: 4.577/4.572 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[26/100][6/43] KL_real/fake: 4.574/4.571 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[26/100][7/43] KL_real/fake: 4.581/4.571 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.006 \n",
      "[26/100][8/43] KL_real/fake: 4.576/4.569 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[26/100][9/43] KL_real/fake: 4.575/4.571 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[26/100][10/43] KL_real/fake: 4.577/4.570 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[26/100][11/43] KL_real/fake: 4.578/4.570 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[26/100][12/43] KL_real/fake: 4.577/4.571 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[26/100][13/43] KL_real/fake: 4.571/4.569 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[26/100][14/43] KL_real/fake: 4.572/4.567 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[26/100][15/43] KL_real/fake: 4.571/4.567 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.007 \n",
      "[26/100][16/43] KL_real/fake: 4.571/4.565 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[26/100][17/43] KL_real/fake: 4.570/4.565 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[26/100][18/43] KL_real/fake: 4.570/4.563 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[26/100][19/43] KL_real/fake: 4.567/4.562 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[26/100][20/43] KL_real/fake: 4.570/4.563 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[26/100][21/43] KL_real/fake: 4.572/4.570 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[26/100][22/43] KL_real/fake: 4.575/4.567 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[26/100][23/43] KL_real/fake: 4.573/4.570 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.007 \n",
      "[26/100][24/43] KL_real/fake: 4.571/4.566 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.007 \n",
      "[26/100][25/43] KL_real/fake: 4.570/4.567 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[26/100][26/43] KL_real/fake: 4.572/4.562 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.007 \n",
      "[26/100][27/43] KL_real/fake: 4.569/4.563 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[26/100][28/43] KL_real/fake: 4.570/4.560 mean_real/fake: -0.002/-0.003 var_real/fake: 0.007/0.007 \n",
      "[26/100][29/43] KL_real/fake: 4.569/4.559 mean_real/fake: -0.003/-0.003 var_real/fake: 0.007/0.007 \n",
      "[26/100][30/43] KL_real/fake: 4.565/4.561 mean_real/fake: -0.002/-0.005 var_real/fake: 0.007/0.007 \n",
      "[26/100][31/43] KL_real/fake: 4.568/4.561 mean_real/fake: -0.002/-0.004 var_real/fake: 0.007/0.007 \n",
      "[26/100][32/43] KL_real/fake: 4.570/4.562 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[26/100][33/43] KL_real/fake: 4.564/4.560 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[26/100][34/43] KL_real/fake: 4.563/4.558 mean_real/fake: -0.003/-0.003 var_real/fake: 0.007/0.007 \n",
      "[26/100][35/43] KL_real/fake: 4.565/4.558 mean_real/fake: -0.002/-0.005 var_real/fake: 0.007/0.007 \n",
      "[26/100][36/43] KL_real/fake: 4.565/4.558 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[26/100][37/43] KL_real/fake: 4.572/4.563 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[26/100][38/43] KL_real/fake: 4.564/4.561 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[26/100][39/43] KL_real/fake: 4.567/4.555 mean_real/fake: -0.006/-0.003 var_real/fake: 0.007/0.007 \n",
      "[26/100][40/43] KL_real/fake: 4.559/4.558 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[26/100][41/43] KL_real/fake: 4.559/4.559 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[26/100][42/43] KL_real/fake: 4.561/4.556 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[27/100][0/43] KL_real/fake: 4.563/4.559 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[27/100][1/43] KL_real/fake: 4.561/4.554 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[27/100][2/43] KL_real/fake: 4.567/4.559 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[27/100][3/43] KL_real/fake: 4.569/4.558 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[27/100][4/43] KL_real/fake: 4.563/4.558 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[27/100][5/43] KL_real/fake: 4.564/4.556 mean_real/fake: -0.007/-0.007 var_real/fake: 0.007/0.007 \n",
      "[27/100][6/43] KL_real/fake: 4.568/4.560 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.007 \n",
      "[27/100][7/43] KL_real/fake: 4.564/4.560 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[27/100][8/43] KL_real/fake: 4.565/4.561 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[27/100][9/43] KL_real/fake: 4.570/4.563 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[27/100][10/43] KL_real/fake: 4.567/4.560 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[27/100][11/43] KL_real/fake: 4.569/4.563 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.007 \n",
      "[27/100][12/43] KL_real/fake: 4.567/4.565 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[27/100][13/43] KL_real/fake: 4.570/4.565 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[27/100][14/43] KL_real/fake: 4.572/4.566 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[27/100][15/43] KL_real/fake: 4.566/4.564 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[27/100][16/43] KL_real/fake: 4.568/4.561 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[27/100][17/43] KL_real/fake: 4.569/4.559 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[27/100][18/43] KL_real/fake: 4.561/4.557 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[27/100][19/43] KL_real/fake: 4.564/4.558 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[27/100][20/43] KL_real/fake: 4.565/4.560 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[27/100][21/43] KL_real/fake: 4.566/4.560 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[27/100][22/43] KL_real/fake: 4.567/4.565 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[27/100][23/43] KL_real/fake: 4.570/4.562 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[27/100][24/43] KL_real/fake: 4.565/4.565 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[27/100][25/43] KL_real/fake: 4.567/4.562 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[27/100][26/43] KL_real/fake: 4.568/4.561 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[27/100][27/43] KL_real/fake: 4.568/4.562 mean_real/fake: -0.004/-0.003 var_real/fake: 0.006/0.007 \n",
      "[27/100][28/43] KL_real/fake: 4.568/4.558 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[27/100][29/43] KL_real/fake: 4.565/4.559 mean_real/fake: -0.002/-0.005 var_real/fake: 0.007/0.007 \n",
      "[27/100][30/43] KL_real/fake: 4.565/4.560 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[27/100][31/43] KL_real/fake: 4.565/4.560 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[27/100][32/43] KL_real/fake: 4.566/4.566 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[27/100][33/43] KL_real/fake: 4.566/4.563 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[27/100][34/43] KL_real/fake: 4.570/4.564 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.007 \n",
      "[27/100][35/43] KL_real/fake: 4.572/4.566 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.007 \n",
      "[27/100][36/43] KL_real/fake: 4.565/4.561 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[27/100][37/43] KL_real/fake: 4.566/4.558 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[27/100][38/43] KL_real/fake: 4.563/4.558 mean_real/fake: -0.006/-0.003 var_real/fake: 0.007/0.007 \n",
      "[27/100][39/43] KL_real/fake: 4.568/4.562 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[27/100][40/43] KL_real/fake: 4.569/4.564 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.007 \n",
      "[27/100][41/43] KL_real/fake: 4.570/4.565 mean_real/fake: -0.005/-0.003 var_real/fake: 0.006/0.007 \n",
      "[27/100][42/43] KL_real/fake: 4.571/4.566 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.007 \n",
      "[28/100][0/43] KL_real/fake: 4.568/4.564 mean_real/fake: -0.002/-0.005 var_real/fake: 0.006/0.007 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28/100][1/43] KL_real/fake: 4.569/4.563 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.007 \n",
      "[28/100][2/43] KL_real/fake: 4.565/4.561 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[28/100][3/43] KL_real/fake: 4.558/4.555 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[28/100][4/43] KL_real/fake: 4.560/4.553 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[28/100][5/43] KL_real/fake: 4.553/4.548 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[28/100][6/43] KL_real/fake: 4.556/4.543 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[28/100][7/43] KL_real/fake: 4.558/4.539 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[28/100][8/43] KL_real/fake: 4.550/4.542 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[28/100][9/43] KL_real/fake: 4.548/4.545 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[28/100][10/43] KL_real/fake: 4.556/4.551 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[28/100][11/43] KL_real/fake: 4.566/4.557 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[28/100][12/43] KL_real/fake: 4.563/4.556 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[28/100][13/43] KL_real/fake: 4.572/4.559 mean_real/fake: -0.005/-0.002 var_real/fake: 0.006/0.007 \n",
      "[28/100][14/43] KL_real/fake: 4.569/4.559 mean_real/fake: -0.005/-0.002 var_real/fake: 0.006/0.007 \n",
      "[28/100][15/43] KL_real/fake: 4.567/4.560 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.007 \n",
      "[28/100][16/43] KL_real/fake: 4.568/4.561 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.007 \n",
      "[28/100][17/43] KL_real/fake: 4.567/4.558 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.007 \n",
      "[28/100][18/43] KL_real/fake: 4.561/4.554 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[28/100][19/43] KL_real/fake: 4.557/4.555 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[28/100][20/43] KL_real/fake: 4.560/4.556 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[28/100][21/43] KL_real/fake: 4.567/4.557 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[28/100][22/43] KL_real/fake: 4.561/4.562 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[28/100][23/43] KL_real/fake: 4.563/4.558 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[28/100][24/43] KL_real/fake: 4.557/4.554 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[28/100][25/43] KL_real/fake: 4.558/4.551 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[28/100][26/43] KL_real/fake: 4.550/4.545 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[28/100][27/43] KL_real/fake: 4.548/4.544 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[28/100][28/43] KL_real/fake: 4.543/4.537 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[28/100][29/43] KL_real/fake: 4.539/4.535 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[28/100][30/43] KL_real/fake: 4.535/4.525 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[28/100][31/43] KL_real/fake: 4.538/4.524 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[28/100][32/43] KL_real/fake: 4.534/4.528 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[28/100][33/43] KL_real/fake: 4.535/4.530 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[28/100][34/43] KL_real/fake: 4.539/4.534 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[28/100][35/43] KL_real/fake: 4.548/4.540 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[28/100][36/43] KL_real/fake: 4.554/4.547 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[28/100][37/43] KL_real/fake: 4.551/4.549 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[28/100][38/43] KL_real/fake: 4.550/4.549 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[28/100][39/43] KL_real/fake: 4.554/4.543 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[28/100][40/43] KL_real/fake: 4.555/4.546 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[28/100][41/43] KL_real/fake: 4.557/4.551 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[28/100][42/43] KL_real/fake: 4.562/4.555 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[29/100][0/43] KL_real/fake: 4.559/4.550 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[29/100][1/43] KL_real/fake: 4.557/4.555 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[29/100][2/43] KL_real/fake: 4.557/4.552 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[29/100][3/43] KL_real/fake: 4.555/4.549 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[29/100][4/43] KL_real/fake: 4.554/4.553 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[29/100][5/43] KL_real/fake: 4.556/4.548 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[29/100][6/43] KL_real/fake: 4.557/4.550 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[29/100][7/43] KL_real/fake: 4.556/4.550 mean_real/fake: -0.005/-0.007 var_real/fake: 0.007/0.007 \n",
      "[29/100][8/43] KL_real/fake: 4.551/4.544 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[29/100][9/43] KL_real/fake: 4.544/4.543 mean_real/fake: -0.005/-0.008 var_real/fake: 0.007/0.007 \n",
      "[29/100][10/43] KL_real/fake: 4.543/4.540 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[29/100][11/43] KL_real/fake: 4.548/4.541 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[29/100][12/43] KL_real/fake: 4.546/4.537 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[29/100][13/43] KL_real/fake: 4.549/4.541 mean_real/fake: -0.008/-0.005 var_real/fake: 0.007/0.007 \n",
      "[29/100][14/43] KL_real/fake: 4.548/4.536 mean_real/fake: -0.008/-0.005 var_real/fake: 0.007/0.007 \n",
      "[29/100][15/43] KL_real/fake: 4.549/4.544 mean_real/fake: -0.008/-0.004 var_real/fake: 0.007/0.007 \n",
      "[29/100][16/43] KL_real/fake: 4.556/4.550 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[29/100][17/43] KL_real/fake: 4.555/4.552 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[29/100][18/43] KL_real/fake: 4.551/4.547 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[29/100][19/43] KL_real/fake: 4.547/4.544 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[29/100][20/43] KL_real/fake: 4.554/4.541 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[29/100][21/43] KL_real/fake: 4.551/4.537 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[29/100][22/43] KL_real/fake: 4.538/4.535 mean_real/fake: -0.003/-0.006 var_real/fake: 0.007/0.007 \n",
      "[29/100][23/43] KL_real/fake: 4.539/4.533 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[29/100][24/43] KL_real/fake: 4.538/4.533 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[29/100][25/43] KL_real/fake: 4.537/4.530 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[29/100][26/43] KL_real/fake: 4.538/4.533 mean_real/fake: -0.007/-0.007 var_real/fake: 0.007/0.007 \n",
      "[29/100][27/43] KL_real/fake: 4.538/4.536 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[29/100][28/43] KL_real/fake: 4.549/4.539 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[29/100][29/43] KL_real/fake: 4.550/4.551 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[29/100][30/43] KL_real/fake: 4.558/4.552 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[29/100][31/43] KL_real/fake: 4.560/4.555 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[29/100][32/43] KL_real/fake: 4.567/4.559 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.007 \n",
      "[29/100][33/43] KL_real/fake: 4.572/4.559 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.007 \n",
      "[29/100][34/43] KL_real/fake: 4.569/4.560 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.007 \n",
      "[29/100][35/43] KL_real/fake: 4.570/4.559 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.007 \n",
      "[29/100][36/43] KL_real/fake: 4.563/4.554 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.007 \n",
      "[29/100][37/43] KL_real/fake: 4.560/4.556 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.007 \n",
      "[29/100][38/43] KL_real/fake: 4.565/4.557 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.007 \n",
      "[29/100][39/43] KL_real/fake: 4.554/4.549 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[29/100][40/43] KL_real/fake: 4.557/4.549 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29/100][41/43] KL_real/fake: 4.559/4.552 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[29/100][42/43] KL_real/fake: 4.555/4.551 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[30/100][0/43] KL_real/fake: 4.553/4.551 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[30/100][1/43] KL_real/fake: 4.553/4.549 mean_real/fake: -0.005/-0.007 var_real/fake: 0.007/0.007 \n",
      "[30/100][2/43] KL_real/fake: 4.550/4.545 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[30/100][3/43] KL_real/fake: 4.549/4.544 mean_real/fake: -0.005/-0.007 var_real/fake: 0.007/0.007 \n",
      "[30/100][4/43] KL_real/fake: 4.548/4.547 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[30/100][5/43] KL_real/fake: 4.552/4.547 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[30/100][6/43] KL_real/fake: 4.559/4.552 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[30/100][7/43] KL_real/fake: 4.552/4.548 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[30/100][8/43] KL_real/fake: 4.550/4.544 mean_real/fake: -0.005/-0.007 var_real/fake: 0.007/0.007 \n",
      "[30/100][9/43] KL_real/fake: 4.543/4.539 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[30/100][10/43] KL_real/fake: 4.544/4.539 mean_real/fake: -0.007/-0.007 var_real/fake: 0.007/0.007 \n",
      "[30/100][11/43] KL_real/fake: 4.547/4.542 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[30/100][12/43] KL_real/fake: 4.551/4.543 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[30/100][13/43] KL_real/fake: 4.553/4.547 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[30/100][14/43] KL_real/fake: 4.558/4.549 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[30/100][15/43] KL_real/fake: 4.552/4.551 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[30/100][16/43] KL_real/fake: 4.550/4.546 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[30/100][17/43] KL_real/fake: 4.557/4.548 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[30/100][18/43] KL_real/fake: 4.549/4.549 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[30/100][19/43] KL_real/fake: 4.547/4.545 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[30/100][20/43] KL_real/fake: 4.549/4.545 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[30/100][21/43] KL_real/fake: 4.557/4.545 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[30/100][22/43] KL_real/fake: 4.550/4.544 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[30/100][23/43] KL_real/fake: 4.551/4.549 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[30/100][24/43] KL_real/fake: 4.556/4.552 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[30/100][25/43] KL_real/fake: 4.567/4.560 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.007 \n",
      "[30/100][26/43] KL_real/fake: 4.576/4.565 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[30/100][27/43] KL_real/fake: 4.572/4.563 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.007 \n",
      "[30/100][28/43] KL_real/fake: 4.569/4.560 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.007 \n",
      "[30/100][29/43] KL_real/fake: 4.569/4.563 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.007 \n",
      "[30/100][30/43] KL_real/fake: 4.565/4.560 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.007 \n",
      "[30/100][31/43] KL_real/fake: 4.562/4.556 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[30/100][32/43] KL_real/fake: 4.560/4.553 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[30/100][33/43] KL_real/fake: 4.556/4.552 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[30/100][34/43] KL_real/fake: 4.557/4.551 mean_real/fake: -0.004/-0.007 var_real/fake: 0.007/0.007 \n",
      "[30/100][35/43] KL_real/fake: 4.557/4.550 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[30/100][36/43] KL_real/fake: 4.558/4.553 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[30/100][37/43] KL_real/fake: 4.563/4.551 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.007 \n",
      "[30/100][38/43] KL_real/fake: 4.558/4.550 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[30/100][39/43] KL_real/fake: 4.559/4.552 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[30/100][40/43] KL_real/fake: 4.561/4.553 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[30/100][41/43] KL_real/fake: 4.560/4.550 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[30/100][42/43] KL_real/fake: 4.554/4.544 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[31/100][0/43] KL_real/fake: 4.553/4.545 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[31/100][1/43] KL_real/fake: 4.549/4.543 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[31/100][2/43] KL_real/fake: 4.553/4.544 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[31/100][3/43] KL_real/fake: 4.551/4.545 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[31/100][4/43] KL_real/fake: 4.550/4.543 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[31/100][5/43] KL_real/fake: 4.545/4.542 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[31/100][6/43] KL_real/fake: 4.547/4.540 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[31/100][7/43] KL_real/fake: 4.549/4.541 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[31/100][8/43] KL_real/fake: 4.543/4.538 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[31/100][9/43] KL_real/fake: 4.544/4.536 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[31/100][10/43] KL_real/fake: 4.551/4.540 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[31/100][11/43] KL_real/fake: 4.551/4.542 mean_real/fake: -0.003/-0.007 var_real/fake: 0.007/0.007 \n",
      "[31/100][12/43] KL_real/fake: 4.547/4.545 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[31/100][13/43] KL_real/fake: 4.550/4.546 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[31/100][14/43] KL_real/fake: 4.555/4.549 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[31/100][15/43] KL_real/fake: 4.555/4.551 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[31/100][16/43] KL_real/fake: 4.554/4.550 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[31/100][17/43] KL_real/fake: 4.549/4.545 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[31/100][18/43] KL_real/fake: 4.551/4.545 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[31/100][19/43] KL_real/fake: 4.548/4.545 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[31/100][20/43] KL_real/fake: 4.552/4.544 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[31/100][21/43] KL_real/fake: 4.549/4.540 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[31/100][22/43] KL_real/fake: 4.546/4.541 mean_real/fake: -0.006/-0.003 var_real/fake: 0.007/0.007 \n",
      "[31/100][23/43] KL_real/fake: 4.545/4.536 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[31/100][24/43] KL_real/fake: 4.547/4.536 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[31/100][25/43] KL_real/fake: 4.548/4.538 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[31/100][26/43] KL_real/fake: 4.550/4.540 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[31/100][27/43] KL_real/fake: 4.552/4.544 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[31/100][28/43] KL_real/fake: 4.550/4.543 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[31/100][29/43] KL_real/fake: 4.552/4.541 mean_real/fake: -0.001/-0.005 var_real/fake: 0.007/0.007 \n",
      "[31/100][30/43] KL_real/fake: 4.543/4.543 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[31/100][31/43] KL_real/fake: 4.546/4.541 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[31/100][32/43] KL_real/fake: 4.544/4.540 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[31/100][33/43] KL_real/fake: 4.543/4.541 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[31/100][34/43] KL_real/fake: 4.545/4.542 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[31/100][35/43] KL_real/fake: 4.543/4.541 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[31/100][36/43] KL_real/fake: 4.549/4.542 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[31/100][37/43] KL_real/fake: 4.548/4.540 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31/100][38/43] KL_real/fake: 4.548/4.544 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[31/100][39/43] KL_real/fake: 4.548/4.545 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[31/100][40/43] KL_real/fake: 4.547/4.544 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[31/100][41/43] KL_real/fake: 4.545/4.540 mean_real/fake: -0.007/-0.004 var_real/fake: 0.007/0.007 \n",
      "[31/100][42/43] KL_real/fake: 4.544/4.541 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[32/100][0/43] KL_real/fake: 4.541/4.539 mean_real/fake: -0.002/-0.004 var_real/fake: 0.007/0.007 \n",
      "[32/100][1/43] KL_real/fake: 4.548/4.540 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[32/100][2/43] KL_real/fake: 4.541/4.537 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[32/100][3/43] KL_real/fake: 4.538/4.533 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[32/100][4/43] KL_real/fake: 4.538/4.531 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[32/100][5/43] KL_real/fake: 4.539/4.533 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[32/100][6/43] KL_real/fake: 4.541/4.533 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[32/100][7/43] KL_real/fake: 4.539/4.535 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[32/100][8/43] KL_real/fake: 4.541/4.536 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[32/100][9/43] KL_real/fake: 4.539/4.536 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[32/100][10/43] KL_real/fake: 4.548/4.535 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[32/100][11/43] KL_real/fake: 4.544/4.537 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[32/100][12/43] KL_real/fake: 4.543/4.534 mean_real/fake: -0.002/-0.004 var_real/fake: 0.007/0.007 \n",
      "[32/100][13/43] KL_real/fake: 4.536/4.536 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[32/100][14/43] KL_real/fake: 4.539/4.534 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[32/100][15/43] KL_real/fake: 4.532/4.531 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[32/100][16/43] KL_real/fake: 4.537/4.532 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[32/100][17/43] KL_real/fake: 4.536/4.532 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[32/100][18/43] KL_real/fake: 4.536/4.534 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[32/100][19/43] KL_real/fake: 4.539/4.532 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[32/100][20/43] KL_real/fake: 4.539/4.534 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[32/100][21/43] KL_real/fake: 4.544/4.537 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[32/100][22/43] KL_real/fake: 4.543/4.536 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[32/100][23/43] KL_real/fake: 4.548/4.541 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[32/100][24/43] KL_real/fake: 4.551/4.543 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[32/100][25/43] KL_real/fake: 4.555/4.547 mean_real/fake: -0.008/-0.005 var_real/fake: 0.007/0.007 \n",
      "[32/100][26/43] KL_real/fake: 4.551/4.546 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[32/100][27/43] KL_real/fake: 4.554/4.546 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[32/100][28/43] KL_real/fake: 4.549/4.542 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[32/100][29/43] KL_real/fake: 4.549/4.541 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[32/100][30/43] KL_real/fake: 4.551/4.544 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[32/100][31/43] KL_real/fake: 4.552/4.542 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[32/100][32/43] KL_real/fake: 4.550/4.542 mean_real/fake: -0.002/-0.005 var_real/fake: 0.007/0.007 \n",
      "[32/100][33/43] KL_real/fake: 4.550/4.539 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[32/100][34/43] KL_real/fake: 4.543/4.537 mean_real/fake: -0.002/-0.004 var_real/fake: 0.007/0.007 \n",
      "[32/100][35/43] KL_real/fake: 4.539/4.535 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[32/100][36/43] KL_real/fake: 4.543/4.538 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[32/100][37/43] KL_real/fake: 4.542/4.535 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[32/100][38/43] KL_real/fake: 4.540/4.533 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[32/100][39/43] KL_real/fake: 4.539/4.535 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[32/100][40/43] KL_real/fake: 4.544/4.536 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[32/100][41/43] KL_real/fake: 4.544/4.537 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[32/100][42/43] KL_real/fake: 4.540/4.533 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[33/100][0/43] KL_real/fake: 4.535/4.537 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[33/100][1/43] KL_real/fake: 4.540/4.540 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[33/100][2/43] KL_real/fake: 4.539/4.533 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[33/100][3/43] KL_real/fake: 4.541/4.534 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[33/100][4/43] KL_real/fake: 4.538/4.532 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[33/100][5/43] KL_real/fake: 4.541/4.535 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[33/100][6/43] KL_real/fake: 4.545/4.538 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[33/100][7/43] KL_real/fake: 4.549/4.542 mean_real/fake: -0.003/-0.006 var_real/fake: 0.007/0.007 \n",
      "[33/100][8/43] KL_real/fake: 4.545/4.541 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[33/100][9/43] KL_real/fake: 4.550/4.541 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[33/100][10/43] KL_real/fake: 4.547/4.542 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[33/100][11/43] KL_real/fake: 4.545/4.542 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[33/100][12/43] KL_real/fake: 4.545/4.542 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[33/100][13/43] KL_real/fake: 4.546/4.541 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[33/100][14/43] KL_real/fake: 4.542/4.540 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[33/100][15/43] KL_real/fake: 4.547/4.536 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[33/100][16/43] KL_real/fake: 4.545/4.534 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[33/100][17/43] KL_real/fake: 4.541/4.534 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[33/100][18/43] KL_real/fake: 4.543/4.534 mean_real/fake: -0.005/-0.007 var_real/fake: 0.007/0.007 \n",
      "[33/100][19/43] KL_real/fake: 4.541/4.534 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[33/100][20/43] KL_real/fake: 4.548/4.534 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[33/100][21/43] KL_real/fake: 4.537/4.534 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[33/100][22/43] KL_real/fake: 4.537/4.532 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[33/100][23/43] KL_real/fake: 4.539/4.538 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[33/100][24/43] KL_real/fake: 4.540/4.539 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[33/100][25/43] KL_real/fake: 4.545/4.534 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[33/100][26/43] KL_real/fake: 4.539/4.535 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[33/100][27/43] KL_real/fake: 4.540/4.535 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[33/100][28/43] KL_real/fake: 4.549/4.534 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[33/100][29/43] KL_real/fake: 4.546/4.533 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[33/100][30/43] KL_real/fake: 4.545/4.537 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[33/100][31/43] KL_real/fake: 4.537/4.535 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[33/100][32/43] KL_real/fake: 4.540/4.533 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[33/100][33/43] KL_real/fake: 4.536/4.532 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[33/100][34/43] KL_real/fake: 4.541/4.531 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33/100][35/43] KL_real/fake: 4.537/4.533 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[33/100][36/43] KL_real/fake: 4.538/4.532 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[33/100][37/43] KL_real/fake: 4.536/4.532 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[33/100][38/43] KL_real/fake: 4.537/4.531 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[33/100][39/43] KL_real/fake: 4.537/4.535 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[33/100][40/43] KL_real/fake: 4.539/4.535 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[33/100][41/43] KL_real/fake: 4.537/4.534 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[33/100][42/43] KL_real/fake: 4.537/4.534 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[34/100][0/43] KL_real/fake: 4.539/4.531 mean_real/fake: -0.002/-0.006 var_real/fake: 0.007/0.007 \n",
      "[34/100][1/43] KL_real/fake: 4.536/4.528 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[34/100][2/43] KL_real/fake: 4.533/4.526 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[34/100][3/43] KL_real/fake: 4.529/4.524 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[34/100][4/43] KL_real/fake: 4.528/4.523 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[34/100][5/43] KL_real/fake: 4.528/4.524 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[34/100][6/43] KL_real/fake: 4.533/4.528 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[34/100][7/43] KL_real/fake: 4.535/4.533 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[34/100][8/43] KL_real/fake: 4.540/4.537 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[34/100][9/43] KL_real/fake: 4.543/4.541 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[34/100][10/43] KL_real/fake: 4.548/4.544 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[34/100][11/43] KL_real/fake: 4.550/4.543 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[34/100][12/43] KL_real/fake: 4.553/4.542 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[34/100][13/43] KL_real/fake: 4.547/4.540 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[34/100][14/43] KL_real/fake: 4.549/4.538 mean_real/fake: -0.003/-0.006 var_real/fake: 0.007/0.007 \n",
      "[34/100][15/43] KL_real/fake: 4.544/4.537 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[34/100][16/43] KL_real/fake: 4.552/4.540 mean_real/fake: -0.002/-0.005 var_real/fake: 0.007/0.007 \n",
      "[34/100][17/43] KL_real/fake: 4.553/4.542 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[34/100][18/43] KL_real/fake: 4.556/4.547 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[34/100][19/43] KL_real/fake: 4.553/4.542 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[34/100][20/43] KL_real/fake: 4.550/4.544 mean_real/fake: -0.005/-0.002 var_real/fake: 0.007/0.007 \n",
      "[34/100][21/43] KL_real/fake: 4.546/4.539 mean_real/fake: -0.003/-0.003 var_real/fake: 0.007/0.007 \n",
      "[34/100][22/43] KL_real/fake: 4.545/4.539 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[34/100][23/43] KL_real/fake: 4.545/4.537 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[34/100][24/43] KL_real/fake: 4.540/4.538 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[34/100][25/43] KL_real/fake: 4.543/4.538 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[34/100][26/43] KL_real/fake: 4.547/4.538 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[34/100][27/43] KL_real/fake: 4.553/4.538 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[34/100][28/43] KL_real/fake: 4.551/4.537 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[34/100][29/43] KL_real/fake: 4.542/4.530 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[34/100][30/43] KL_real/fake: 4.536/4.529 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[34/100][31/43] KL_real/fake: 4.532/4.529 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[34/100][32/43] KL_real/fake: 4.534/4.530 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[34/100][33/43] KL_real/fake: 4.538/4.533 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[34/100][34/43] KL_real/fake: 4.540/4.536 mean_real/fake: -0.006/-0.003 var_real/fake: 0.007/0.007 \n",
      "[34/100][35/43] KL_real/fake: 4.546/4.540 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[34/100][36/43] KL_real/fake: 4.548/4.545 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[34/100][37/43] KL_real/fake: 4.558/4.545 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[34/100][38/43] KL_real/fake: 4.553/4.545 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[34/100][39/43] KL_real/fake: 4.552/4.544 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[34/100][40/43] KL_real/fake: 4.552/4.543 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[34/100][41/43] KL_real/fake: 4.545/4.542 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[34/100][42/43] KL_real/fake: 4.544/4.539 mean_real/fake: -0.007/-0.007 var_real/fake: 0.007/0.007 \n",
      "[35/100][0/43] KL_real/fake: 4.544/4.539 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[35/100][1/43] KL_real/fake: 4.545/4.542 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[35/100][2/43] KL_real/fake: 4.547/4.535 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[35/100][3/43] KL_real/fake: 4.550/4.542 mean_real/fake: -0.007/-0.007 var_real/fake: 0.007/0.007 \n",
      "[35/100][4/43] KL_real/fake: 4.554/4.549 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[35/100][5/43] KL_real/fake: 4.547/4.541 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[35/100][6/43] KL_real/fake: 4.551/4.538 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[35/100][7/43] KL_real/fake: 4.545/4.539 mean_real/fake: -0.002/-0.005 var_real/fake: 0.007/0.007 \n",
      "[35/100][8/43] KL_real/fake: 4.541/4.537 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[35/100][9/43] KL_real/fake: 4.552/4.537 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[35/100][10/43] KL_real/fake: 4.546/4.540 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[35/100][11/43] KL_real/fake: 4.549/4.543 mean_real/fake: -0.007/-0.007 var_real/fake: 0.007/0.007 \n",
      "[35/100][12/43] KL_real/fake: 4.556/4.548 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[35/100][13/43] KL_real/fake: 4.572/4.553 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.007 \n",
      "[35/100][14/43] KL_real/fake: 4.559/4.556 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[35/100][15/43] KL_real/fake: 4.561/4.558 mean_real/fake: -0.008/-0.007 var_real/fake: 0.007/0.007 \n",
      "[35/100][16/43] KL_real/fake: 4.559/4.556 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[35/100][17/43] KL_real/fake: 4.563/4.556 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[35/100][18/43] KL_real/fake: 4.560/4.556 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[35/100][19/43] KL_real/fake: 4.561/4.550 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[35/100][20/43] KL_real/fake: 4.556/4.546 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[35/100][21/43] KL_real/fake: 4.552/4.540 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[35/100][22/43] KL_real/fake: 4.541/4.535 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[35/100][23/43] KL_real/fake: 4.544/4.536 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[35/100][24/43] KL_real/fake: 4.542/4.534 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[35/100][25/43] KL_real/fake: 4.543/4.535 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[35/100][26/43] KL_real/fake: 4.548/4.541 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[35/100][27/43] KL_real/fake: 4.553/4.547 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[35/100][28/43] KL_real/fake: 4.552/4.550 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[35/100][29/43] KL_real/fake: 4.558/4.553 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[35/100][30/43] KL_real/fake: 4.562/4.553 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[35/100][31/43] KL_real/fake: 4.560/4.556 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35/100][32/43] KL_real/fake: 4.560/4.553 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[35/100][33/43] KL_real/fake: 4.559/4.554 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[35/100][34/43] KL_real/fake: 4.559/4.558 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[35/100][35/43] KL_real/fake: 4.565/4.558 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[35/100][36/43] KL_real/fake: 4.559/4.557 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[35/100][37/43] KL_real/fake: 4.557/4.549 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[35/100][38/43] KL_real/fake: 4.550/4.543 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[35/100][39/43] KL_real/fake: 4.552/4.543 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[35/100][40/43] KL_real/fake: 4.544/4.536 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[35/100][41/43] KL_real/fake: 4.548/4.537 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[35/100][42/43] KL_real/fake: 4.543/4.536 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[36/100][0/43] KL_real/fake: 4.544/4.540 mean_real/fake: -0.005/-0.007 var_real/fake: 0.007/0.007 \n",
      "[36/100][1/43] KL_real/fake: 4.548/4.542 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[36/100][2/43] KL_real/fake: 4.554/4.546 mean_real/fake: -0.005/-0.008 var_real/fake: 0.007/0.007 \n",
      "[36/100][3/43] KL_real/fake: 4.547/4.542 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[36/100][4/43] KL_real/fake: 4.548/4.544 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[36/100][5/43] KL_real/fake: 4.551/4.542 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[36/100][6/43] KL_real/fake: 4.552/4.544 mean_real/fake: -0.008/-0.005 var_real/fake: 0.007/0.007 \n",
      "[36/100][7/43] KL_real/fake: 4.549/4.546 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[36/100][8/43] KL_real/fake: 4.547/4.543 mean_real/fake: -0.007/-0.004 var_real/fake: 0.007/0.007 \n",
      "[36/100][9/43] KL_real/fake: 4.544/4.537 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[36/100][10/43] KL_real/fake: 4.545/4.540 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[36/100][11/43] KL_real/fake: 4.542/4.537 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[36/100][12/43] KL_real/fake: 4.541/4.535 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[36/100][13/43] KL_real/fake: 4.547/4.537 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[36/100][14/43] KL_real/fake: 4.550/4.545 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[36/100][15/43] KL_real/fake: 4.561/4.550 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[36/100][16/43] KL_real/fake: 4.567/4.559 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.007 \n",
      "[36/100][17/43] KL_real/fake: 4.566/4.562 mean_real/fake: -0.004/-0.007 var_real/fake: 0.006/0.007 \n",
      "[36/100][18/43] KL_real/fake: 4.568/4.561 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.007 \n",
      "[36/100][19/43] KL_real/fake: 4.583/4.567 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.006 \n",
      "[36/100][20/43] KL_real/fake: 4.572/4.566 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[36/100][21/43] KL_real/fake: 4.570/4.564 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[36/100][22/43] KL_real/fake: 4.571/4.563 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[36/100][23/43] KL_real/fake: 4.576/4.561 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.007 \n",
      "[36/100][24/43] KL_real/fake: 4.563/4.561 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.007 \n",
      "[36/100][25/43] KL_real/fake: 4.574/4.560 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.007 \n",
      "[36/100][26/43] KL_real/fake: 4.570/4.562 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.006 \n",
      "[36/100][27/43] KL_real/fake: 4.567/4.560 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.007 \n",
      "[36/100][28/43] KL_real/fake: 4.566/4.557 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.007 \n",
      "[36/100][29/43] KL_real/fake: 4.568/4.554 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.007 \n",
      "[36/100][30/43] KL_real/fake: 4.556/4.548 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[36/100][31/43] KL_real/fake: 4.552/4.544 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[36/100][32/43] KL_real/fake: 4.558/4.543 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[36/100][33/43] KL_real/fake: 4.550/4.549 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[36/100][34/43] KL_real/fake: 4.552/4.543 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[36/100][35/43] KL_real/fake: 4.558/4.544 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[36/100][36/43] KL_real/fake: 4.548/4.545 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[36/100][37/43] KL_real/fake: 4.552/4.543 mean_real/fake: -0.007/-0.007 var_real/fake: 0.007/0.007 \n",
      "[36/100][38/43] KL_real/fake: 4.558/4.546 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[36/100][39/43] KL_real/fake: 4.555/4.546 mean_real/fake: -0.007/-0.007 var_real/fake: 0.007/0.007 \n",
      "[36/100][40/43] KL_real/fake: 4.554/4.548 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[36/100][41/43] KL_real/fake: 4.566/4.550 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.007 \n",
      "[36/100][42/43] KL_real/fake: 4.553/4.547 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[37/100][0/43] KL_real/fake: 4.559/4.554 mean_real/fake: -0.003/-0.006 var_real/fake: 0.007/0.007 \n",
      "[37/100][1/43] KL_real/fake: 4.551/4.547 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[37/100][2/43] KL_real/fake: 4.552/4.542 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[37/100][3/43] KL_real/fake: 4.547/4.535 mean_real/fake: -0.005/-0.007 var_real/fake: 0.007/0.007 \n",
      "[37/100][4/43] KL_real/fake: 4.550/4.535 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[37/100][5/43] KL_real/fake: 4.552/4.534 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[37/100][6/43] KL_real/fake: 4.550/4.540 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[37/100][7/43] KL_real/fake: 4.553/4.538 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[37/100][8/43] KL_real/fake: 4.550/4.545 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[37/100][9/43] KL_real/fake: 4.552/4.541 mean_real/fake: -0.004/-0.007 var_real/fake: 0.007/0.007 \n",
      "[37/100][10/43] KL_real/fake: 4.555/4.546 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[37/100][11/43] KL_real/fake: 4.556/4.550 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[37/100][12/43] KL_real/fake: 4.573/4.555 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.007 \n",
      "[37/100][13/43] KL_real/fake: 4.573/4.559 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.007 \n",
      "[37/100][14/43] KL_real/fake: 4.562/4.557 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[37/100][15/43] KL_real/fake: 4.561/4.557 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[37/100][16/43] KL_real/fake: 4.561/4.555 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[37/100][17/43] KL_real/fake: 4.563/4.560 mean_real/fake: -0.007/-0.004 var_real/fake: 0.007/0.007 \n",
      "[37/100][18/43] KL_real/fake: 4.562/4.554 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[37/100][19/43] KL_real/fake: 4.558/4.550 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[37/100][20/43] KL_real/fake: 4.557/4.549 mean_real/fake: -0.007/-0.007 var_real/fake: 0.007/0.007 \n",
      "[37/100][21/43] KL_real/fake: 4.555/4.547 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[37/100][22/43] KL_real/fake: 4.560/4.548 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[37/100][23/43] KL_real/fake: 4.564/4.556 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[37/100][24/43] KL_real/fake: 4.568/4.562 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[37/100][25/43] KL_real/fake: 4.569/4.565 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.007 \n",
      "[37/100][26/43] KL_real/fake: 4.571/4.565 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.007 \n",
      "[37/100][27/43] KL_real/fake: 4.571/4.564 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[37/100][28/43] KL_real/fake: 4.569/4.565 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.007 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37/100][29/43] KL_real/fake: 4.570/4.563 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.007 \n",
      "[37/100][30/43] KL_real/fake: 4.566/4.564 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[37/100][31/43] KL_real/fake: 4.561/4.557 mean_real/fake: -0.004/-0.007 var_real/fake: 0.007/0.007 \n",
      "[37/100][32/43] KL_real/fake: 4.558/4.554 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[37/100][33/43] KL_real/fake: 4.560/4.555 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[37/100][34/43] KL_real/fake: 4.563/4.553 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.007 \n",
      "[37/100][35/43] KL_real/fake: 4.555/4.550 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[37/100][36/43] KL_real/fake: 4.556/4.551 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[37/100][37/43] KL_real/fake: 4.553/4.549 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[37/100][38/43] KL_real/fake: 4.556/4.555 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[37/100][39/43] KL_real/fake: 4.553/4.549 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[37/100][40/43] KL_real/fake: 4.553/4.547 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[37/100][41/43] KL_real/fake: 4.554/4.548 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[37/100][42/43] KL_real/fake: 4.553/4.550 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[38/100][0/43] KL_real/fake: 4.554/4.553 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[38/100][1/43] KL_real/fake: 4.554/4.549 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[38/100][2/43] KL_real/fake: 4.562/4.549 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.007 \n",
      "[38/100][3/43] KL_real/fake: 4.555/4.547 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[38/100][4/43] KL_real/fake: 4.553/4.546 mean_real/fake: -0.004/-0.007 var_real/fake: 0.007/0.007 \n",
      "[38/100][5/43] KL_real/fake: 4.554/4.546 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[38/100][6/43] KL_real/fake: 4.551/4.543 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[38/100][7/43] KL_real/fake: 4.553/4.544 mean_real/fake: -0.005/-0.007 var_real/fake: 0.007/0.007 \n",
      "[38/100][8/43] KL_real/fake: 4.551/4.542 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[38/100][9/43] KL_real/fake: 4.549/4.542 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[38/100][10/43] KL_real/fake: 4.547/4.546 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[38/100][11/43] KL_real/fake: 4.548/4.541 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[38/100][12/43] KL_real/fake: 4.548/4.542 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[38/100][13/43] KL_real/fake: 4.548/4.542 mean_real/fake: -0.004/-0.002 var_real/fake: 0.007/0.007 \n",
      "[38/100][14/43] KL_real/fake: 4.546/4.544 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[38/100][15/43] KL_real/fake: 4.548/4.545 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[38/100][16/43] KL_real/fake: 4.553/4.546 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[38/100][17/43] KL_real/fake: 4.553/4.546 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[38/100][18/43] KL_real/fake: 4.553/4.550 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[38/100][19/43] KL_real/fake: 4.557/4.550 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[38/100][20/43] KL_real/fake: 4.561/4.554 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.007 \n",
      "[38/100][21/43] KL_real/fake: 4.557/4.548 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[38/100][22/43] KL_real/fake: 4.551/4.548 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[38/100][23/43] KL_real/fake: 4.549/4.541 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[38/100][24/43] KL_real/fake: 4.546/4.537 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[38/100][25/43] KL_real/fake: 4.544/4.541 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[38/100][26/43] KL_real/fake: 4.545/4.536 mean_real/fake: -0.007/-0.004 var_real/fake: 0.007/0.007 \n",
      "[38/100][27/43] KL_real/fake: 4.543/4.537 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[38/100][28/43] KL_real/fake: 4.541/4.539 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[38/100][29/43] KL_real/fake: 4.542/4.539 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[38/100][30/43] KL_real/fake: 4.543/4.536 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[38/100][31/43] KL_real/fake: 4.544/4.537 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[38/100][32/43] KL_real/fake: 4.550/4.540 mean_real/fake: -0.003/-0.003 var_real/fake: 0.007/0.007 \n",
      "[38/100][33/43] KL_real/fake: 4.553/4.543 mean_real/fake: -0.003/-0.006 var_real/fake: 0.007/0.007 \n",
      "[38/100][34/43] KL_real/fake: 4.550/4.545 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[38/100][35/43] KL_real/fake: 4.552/4.549 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[38/100][36/43] KL_real/fake: 4.547/4.542 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[38/100][37/43] KL_real/fake: 4.544/4.541 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[38/100][38/43] KL_real/fake: 4.543/4.539 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[38/100][39/43] KL_real/fake: 4.543/4.537 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[38/100][40/43] KL_real/fake: 4.545/4.540 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[38/100][41/43] KL_real/fake: 4.546/4.539 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[38/100][42/43] KL_real/fake: 4.542/4.537 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[39/100][0/43] KL_real/fake: 4.542/4.543 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[39/100][1/43] KL_real/fake: 4.545/4.538 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[39/100][2/43] KL_real/fake: 4.546/4.540 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[39/100][3/43] KL_real/fake: 4.545/4.540 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[39/100][4/43] KL_real/fake: 4.553/4.543 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[39/100][5/43] KL_real/fake: 4.547/4.542 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[39/100][6/43] KL_real/fake: 4.551/4.546 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[39/100][7/43] KL_real/fake: 4.558/4.548 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[39/100][8/43] KL_real/fake: 4.558/4.551 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[39/100][9/43] KL_real/fake: 4.561/4.561 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[39/100][10/43] KL_real/fake: 4.564/4.556 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.007 \n",
      "[39/100][11/43] KL_real/fake: 4.563/4.555 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.007 \n",
      "[39/100][12/43] KL_real/fake: 4.563/4.555 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.007 \n",
      "[39/100][13/43] KL_real/fake: 4.561/4.553 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[39/100][14/43] KL_real/fake: 4.563/4.557 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.007 \n",
      "[39/100][15/43] KL_real/fake: 4.561/4.553 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[39/100][16/43] KL_real/fake: 4.557/4.549 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[39/100][17/43] KL_real/fake: 4.557/4.549 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[39/100][18/43] KL_real/fake: 4.555/4.545 mean_real/fake: -0.002/-0.005 var_real/fake: 0.007/0.007 \n",
      "[39/100][19/43] KL_real/fake: 4.548/4.545 mean_real/fake: -0.003/-0.003 var_real/fake: 0.007/0.007 \n",
      "[39/100][20/43] KL_real/fake: 4.547/4.543 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[39/100][21/43] KL_real/fake: 4.552/4.544 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[39/100][22/43] KL_real/fake: 4.557/4.545 mean_real/fake: -0.007/-0.004 var_real/fake: 0.007/0.007 \n",
      "[39/100][23/43] KL_real/fake: 4.560/4.550 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[39/100][24/43] KL_real/fake: 4.561/4.553 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[39/100][25/43] KL_real/fake: 4.557/4.551 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39/100][26/43] KL_real/fake: 4.555/4.549 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[39/100][27/43] KL_real/fake: 4.552/4.550 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[39/100][28/43] KL_real/fake: 4.544/4.543 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[39/100][29/43] KL_real/fake: 4.556/4.539 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[39/100][30/43] KL_real/fake: 4.541/4.535 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[39/100][31/43] KL_real/fake: 4.549/4.535 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[39/100][32/43] KL_real/fake: 4.536/4.534 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[39/100][33/43] KL_real/fake: 4.540/4.532 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[39/100][34/43] KL_real/fake: 4.538/4.531 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[39/100][35/43] KL_real/fake: 4.538/4.533 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[39/100][36/43] KL_real/fake: 4.543/4.531 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[39/100][37/43] KL_real/fake: 4.540/4.533 mean_real/fake: -0.002/-0.006 var_real/fake: 0.007/0.007 \n",
      "[39/100][38/43] KL_real/fake: 4.543/4.535 mean_real/fake: -0.003/-0.006 var_real/fake: 0.007/0.007 \n",
      "[39/100][39/43] KL_real/fake: 4.545/4.535 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[39/100][40/43] KL_real/fake: 4.541/4.532 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[39/100][41/43] KL_real/fake: 4.539/4.532 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[39/100][42/43] KL_real/fake: 4.545/4.535 mean_real/fake: -0.008/-0.006 var_real/fake: 0.007/0.007 \n",
      "[40/100][0/43] KL_real/fake: 4.545/4.535 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[40/100][1/43] KL_real/fake: 4.548/4.538 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[40/100][2/43] KL_real/fake: 4.552/4.540 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[40/100][3/43] KL_real/fake: 4.554/4.542 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[40/100][4/43] KL_real/fake: 4.552/4.546 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[40/100][5/43] KL_real/fake: 4.551/4.549 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[40/100][6/43] KL_real/fake: 4.559/4.556 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[40/100][7/43] KL_real/fake: 4.561/4.555 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.007 \n",
      "[40/100][8/43] KL_real/fake: 4.555/4.548 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[40/100][9/43] KL_real/fake: 4.552/4.546 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[40/100][10/43] KL_real/fake: 4.547/4.543 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[40/100][11/43] KL_real/fake: 4.544/4.541 mean_real/fake: -0.004/-0.008 var_real/fake: 0.007/0.007 \n",
      "[40/100][12/43] KL_real/fake: 4.543/4.539 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[40/100][13/43] KL_real/fake: 4.541/4.531 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[40/100][14/43] KL_real/fake: 4.539/4.534 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[40/100][15/43] KL_real/fake: 4.540/4.533 mean_real/fake: -0.007/-0.007 var_real/fake: 0.007/0.007 \n",
      "[40/100][16/43] KL_real/fake: 4.543/4.535 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[40/100][17/43] KL_real/fake: 4.543/4.535 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[40/100][18/43] KL_real/fake: 4.542/4.536 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[40/100][19/43] KL_real/fake: 4.537/4.529 mean_real/fake: -0.007/-0.003 var_real/fake: 0.007/0.007 \n",
      "[40/100][20/43] KL_real/fake: 4.535/4.530 mean_real/fake: -0.006/-0.002 var_real/fake: 0.007/0.007 \n",
      "[40/100][21/43] KL_real/fake: 4.542/4.528 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[40/100][22/43] KL_real/fake: 4.541/4.530 mean_real/fake: -0.003/-0.003 var_real/fake: 0.007/0.007 \n",
      "[40/100][23/43] KL_real/fake: 4.544/4.537 mean_real/fake: -0.002/-0.002 var_real/fake: 0.007/0.007 \n",
      "[40/100][24/43] KL_real/fake: 4.545/4.539 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[40/100][25/43] KL_real/fake: 4.551/4.540 mean_real/fake: -0.002/-0.004 var_real/fake: 0.007/0.007 \n",
      "[40/100][26/43] KL_real/fake: 4.551/4.543 mean_real/fake: -0.002/-0.004 var_real/fake: 0.007/0.007 \n",
      "[40/100][27/43] KL_real/fake: 4.558/4.547 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[40/100][28/43] KL_real/fake: 4.554/4.541 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[40/100][29/43] KL_real/fake: 4.549/4.543 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[40/100][30/43] KL_real/fake: 4.554/4.543 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[40/100][31/43] KL_real/fake: 4.555/4.549 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[40/100][32/43] KL_real/fake: 4.560/4.559 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[40/100][33/43] KL_real/fake: 4.571/4.563 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.006 \n",
      "[40/100][34/43] KL_real/fake: 4.577/4.569 mean_real/fake: -0.006/-0.009 var_real/fake: 0.006/0.006 \n",
      "[40/100][35/43] KL_real/fake: 4.574/4.566 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.006 \n",
      "[40/100][36/43] KL_real/fake: 4.577/4.563 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.006 \n",
      "[40/100][37/43] KL_real/fake: 4.557/4.552 mean_real/fake: -0.007/-0.004 var_real/fake: 0.007/0.007 \n",
      "[40/100][38/43] KL_real/fake: 4.549/4.543 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[40/100][39/43] KL_real/fake: 4.548/4.542 mean_real/fake: -0.005/-0.007 var_real/fake: 0.007/0.007 \n",
      "[40/100][40/43] KL_real/fake: 4.551/4.541 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[40/100][41/43] KL_real/fake: 4.546/4.540 mean_real/fake: -0.005/-0.007 var_real/fake: 0.007/0.007 \n",
      "[40/100][42/43] KL_real/fake: 4.544/4.536 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[41/100][0/43] KL_real/fake: 4.541/4.533 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[41/100][1/43] KL_real/fake: 4.541/4.530 mean_real/fake: -0.008/-0.006 var_real/fake: 0.007/0.007 \n",
      "[41/100][2/43] KL_real/fake: 4.549/4.535 mean_real/fake: -0.007/-0.004 var_real/fake: 0.007/0.007 \n",
      "[41/100][3/43] KL_real/fake: 4.545/4.538 mean_real/fake: -0.008/-0.005 var_real/fake: 0.007/0.007 \n",
      "[41/100][4/43] KL_real/fake: 4.546/4.540 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[41/100][5/43] KL_real/fake: 4.556/4.546 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[41/100][6/43] KL_real/fake: 4.550/4.549 mean_real/fake: -0.003/-0.006 var_real/fake: 0.007/0.007 \n",
      "[41/100][7/43] KL_real/fake: 4.547/4.541 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[41/100][8/43] KL_real/fake: 4.555/4.545 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[41/100][9/43] KL_real/fake: 4.555/4.550 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[41/100][10/43] KL_real/fake: 4.559/4.551 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[41/100][11/43] KL_real/fake: 4.560/4.547 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.007 \n",
      "[41/100][12/43] KL_real/fake: 4.558/4.550 mean_real/fake: -0.007/-0.007 var_real/fake: 0.007/0.007 \n",
      "[41/100][13/43] KL_real/fake: 4.559/4.549 mean_real/fake: -0.009/-0.007 var_real/fake: 0.007/0.007 \n",
      "[41/100][14/43] KL_real/fake: 4.554/4.547 mean_real/fake: -0.007/-0.007 var_real/fake: 0.007/0.007 \n",
      "[41/100][15/43] KL_real/fake: 4.551/4.546 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[41/100][16/43] KL_real/fake: 4.555/4.550 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[41/100][17/43] KL_real/fake: 4.553/4.549 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[41/100][18/43] KL_real/fake: 4.543/4.536 mean_real/fake: -0.005/-0.007 var_real/fake: 0.007/0.007 \n",
      "[41/100][19/43] KL_real/fake: 4.545/4.529 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[41/100][20/43] KL_real/fake: 4.540/4.528 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[41/100][21/43] KL_real/fake: 4.536/4.527 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[41/100][22/43] KL_real/fake: 4.546/4.533 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41/100][23/43] KL_real/fake: 4.550/4.540 mean_real/fake: -0.007/-0.004 var_real/fake: 0.007/0.007 \n",
      "[41/100][24/43] KL_real/fake: 4.550/4.547 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[41/100][25/43] KL_real/fake: 4.556/4.551 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[41/100][26/43] KL_real/fake: 4.566/4.560 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[41/100][27/43] KL_real/fake: 4.578/4.569 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.007 \n",
      "[41/100][28/43] KL_real/fake: 4.583/4.574 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[41/100][29/43] KL_real/fake: 4.577/4.567 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.007 \n",
      "[41/100][30/43] KL_real/fake: 4.572/4.563 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.007 \n",
      "[41/100][31/43] KL_real/fake: 4.570/4.559 mean_real/fake: -0.005/-0.008 var_real/fake: 0.006/0.007 \n",
      "[41/100][32/43] KL_real/fake: 4.564/4.556 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[41/100][33/43] KL_real/fake: 4.564/4.557 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[41/100][34/43] KL_real/fake: 4.566/4.553 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[41/100][35/43] KL_real/fake: 4.563/4.553 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[41/100][36/43] KL_real/fake: 4.558/4.552 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[41/100][37/43] KL_real/fake: 4.557/4.554 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[41/100][38/43] KL_real/fake: 4.559/4.550 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[41/100][39/43] KL_real/fake: 4.554/4.547 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[41/100][40/43] KL_real/fake: 4.549/4.544 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[41/100][41/43] KL_real/fake: 4.552/4.545 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[41/100][42/43] KL_real/fake: 4.549/4.546 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[42/100][0/43] KL_real/fake: 4.553/4.544 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[42/100][1/43] KL_real/fake: 4.548/4.544 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[42/100][2/43] KL_real/fake: 4.543/4.538 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[42/100][3/43] KL_real/fake: 4.547/4.537 mean_real/fake: -0.007/-0.007 var_real/fake: 0.007/0.007 \n",
      "[42/100][4/43] KL_real/fake: 4.540/4.526 mean_real/fake: -0.008/-0.005 var_real/fake: 0.007/0.007 \n",
      "[42/100][5/43] KL_real/fake: 4.532/4.524 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[42/100][6/43] KL_real/fake: 4.535/4.530 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[42/100][7/43] KL_real/fake: 4.542/4.531 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[42/100][8/43] KL_real/fake: 4.554/4.547 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[42/100][9/43] KL_real/fake: 4.562/4.551 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.007 \n",
      "[42/100][10/43] KL_real/fake: 4.566/4.561 mean_real/fake: -0.004/-0.003 var_real/fake: 0.006/0.007 \n",
      "[42/100][11/43] KL_real/fake: 4.586/4.564 mean_real/fake: -0.002/-0.004 var_real/fake: 0.006/0.007 \n",
      "[42/100][12/43] KL_real/fake: 4.582/4.565 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.006 \n",
      "[42/100][13/43] KL_real/fake: 4.575/4.568 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[42/100][14/43] KL_real/fake: 4.574/4.566 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[42/100][15/43] KL_real/fake: 4.574/4.564 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.007 \n",
      "[42/100][16/43] KL_real/fake: 4.564/4.561 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.007 \n",
      "[42/100][17/43] KL_real/fake: 4.565/4.557 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[42/100][18/43] KL_real/fake: 4.561/4.555 mean_real/fake: -0.005/-0.007 var_real/fake: 0.007/0.007 \n",
      "[42/100][19/43] KL_real/fake: 4.554/4.540 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[42/100][20/43] KL_real/fake: 4.544/4.529 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[42/100][21/43] KL_real/fake: 4.546/4.526 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[42/100][22/43] KL_real/fake: 4.542/4.525 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[42/100][23/43] KL_real/fake: 4.547/4.530 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[42/100][24/43] KL_real/fake: 4.548/4.540 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[42/100][25/43] KL_real/fake: 4.561/4.551 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[42/100][26/43] KL_real/fake: 4.567/4.554 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[42/100][27/43] KL_real/fake: 4.564/4.557 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[42/100][28/43] KL_real/fake: 4.563/4.557 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[42/100][29/43] KL_real/fake: 4.561/4.559 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[42/100][30/43] KL_real/fake: 4.564/4.558 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[42/100][31/43] KL_real/fake: 4.564/4.558 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[42/100][32/43] KL_real/fake: 4.560/4.555 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[42/100][33/43] KL_real/fake: 4.569/4.555 mean_real/fake: -0.006/-0.007 var_real/fake: 0.006/0.007 \n",
      "[42/100][34/43] KL_real/fake: 4.570/4.559 mean_real/fake: -0.006/-0.007 var_real/fake: 0.006/0.007 \n",
      "[42/100][35/43] KL_real/fake: 4.570/4.559 mean_real/fake: -0.007/-0.007 var_real/fake: 0.006/0.007 \n",
      "[42/100][36/43] KL_real/fake: 4.561/4.558 mean_real/fake: -0.008/-0.006 var_real/fake: 0.007/0.007 \n",
      "[42/100][37/43] KL_real/fake: 4.555/4.549 mean_real/fake: -0.008/-0.005 var_real/fake: 0.007/0.007 \n",
      "[42/100][38/43] KL_real/fake: 4.551/4.545 mean_real/fake: -0.008/-0.006 var_real/fake: 0.007/0.007 \n",
      "[42/100][39/43] KL_real/fake: 4.551/4.548 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[42/100][40/43] KL_real/fake: 4.553/4.546 mean_real/fake: -0.005/-0.007 var_real/fake: 0.007/0.007 \n",
      "[42/100][41/43] KL_real/fake: 4.555/4.551 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[42/100][42/43] KL_real/fake: 4.558/4.555 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[43/100][0/43] KL_real/fake: 4.563/4.555 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[43/100][1/43] KL_real/fake: 4.559/4.553 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[43/100][2/43] KL_real/fake: 4.560/4.553 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[43/100][3/43] KL_real/fake: 4.562/4.553 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[43/100][4/43] KL_real/fake: 4.555/4.551 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[43/100][5/43] KL_real/fake: 4.559/4.549 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[43/100][6/43] KL_real/fake: 4.555/4.548 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[43/100][7/43] KL_real/fake: 4.557/4.549 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[43/100][8/43] KL_real/fake: 4.548/4.543 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[43/100][9/43] KL_real/fake: 4.547/4.538 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[43/100][10/43] KL_real/fake: 4.544/4.539 mean_real/fake: -0.007/-0.007 var_real/fake: 0.007/0.007 \n",
      "[43/100][11/43] KL_real/fake: 4.543/4.540 mean_real/fake: -0.006/-0.008 var_real/fake: 0.007/0.007 \n",
      "[43/100][12/43] KL_real/fake: 4.548/4.542 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[43/100][13/43] KL_real/fake: 4.547/4.542 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[43/100][14/43] KL_real/fake: 4.548/4.539 mean_real/fake: -0.008/-0.006 var_real/fake: 0.007/0.007 \n",
      "[43/100][15/43] KL_real/fake: 4.542/4.536 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[43/100][16/43] KL_real/fake: 4.539/4.532 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[43/100][17/43] KL_real/fake: 4.538/4.530 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[43/100][18/43] KL_real/fake: 4.547/4.529 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[43/100][19/43] KL_real/fake: 4.542/4.530 mean_real/fake: -0.007/-0.007 var_real/fake: 0.007/0.007 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43/100][20/43] KL_real/fake: 4.546/4.536 mean_real/fake: -0.008/-0.007 var_real/fake: 0.007/0.007 \n",
      "[43/100][21/43] KL_real/fake: 4.552/4.539 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[43/100][22/43] KL_real/fake: 4.551/4.545 mean_real/fake: -0.008/-0.004 var_real/fake: 0.007/0.007 \n",
      "[43/100][23/43] KL_real/fake: 4.555/4.545 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[43/100][24/43] KL_real/fake: 4.557/4.549 mean_real/fake: -0.005/-0.007 var_real/fake: 0.007/0.007 \n",
      "[43/100][25/43] KL_real/fake: 4.561/4.556 mean_real/fake: -0.006/-0.008 var_real/fake: 0.007/0.007 \n",
      "[43/100][26/43] KL_real/fake: 4.562/4.552 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[43/100][27/43] KL_real/fake: 4.556/4.550 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[43/100][28/43] KL_real/fake: 4.553/4.550 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[43/100][29/43] KL_real/fake: 4.553/4.548 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[43/100][30/43] KL_real/fake: 4.542/4.540 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[43/100][31/43] KL_real/fake: 4.546/4.536 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[43/100][32/43] KL_real/fake: 4.540/4.534 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[43/100][33/43] KL_real/fake: 4.547/4.541 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[43/100][34/43] KL_real/fake: 4.550/4.544 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[43/100][35/43] KL_real/fake: 4.551/4.544 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[43/100][36/43] KL_real/fake: 4.561/4.550 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[43/100][37/43] KL_real/fake: 4.557/4.554 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[43/100][38/43] KL_real/fake: 4.567/4.558 mean_real/fake: -0.005/-0.006 var_real/fake: 0.006/0.007 \n",
      "[43/100][39/43] KL_real/fake: 4.568/4.558 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[43/100][40/43] KL_real/fake: 4.567/4.562 mean_real/fake: -0.008/-0.005 var_real/fake: 0.007/0.007 \n",
      "[43/100][41/43] KL_real/fake: 4.564/4.557 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[43/100][42/43] KL_real/fake: 4.564/4.558 mean_real/fake: -0.007/-0.004 var_real/fake: 0.007/0.007 \n",
      "[44/100][0/43] KL_real/fake: 4.564/4.557 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.007 \n",
      "[44/100][1/43] KL_real/fake: 4.562/4.559 mean_real/fake: -0.007/-0.004 var_real/fake: 0.007/0.007 \n",
      "[44/100][2/43] KL_real/fake: 4.564/4.560 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[44/100][3/43] KL_real/fake: 4.560/4.556 mean_real/fake: -0.008/-0.004 var_real/fake: 0.007/0.007 \n",
      "[44/100][4/43] KL_real/fake: 4.557/4.551 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[44/100][5/43] KL_real/fake: 4.556/4.545 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[44/100][6/43] KL_real/fake: 4.554/4.541 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[44/100][7/43] KL_real/fake: 4.556/4.546 mean_real/fake: -0.004/-0.007 var_real/fake: 0.007/0.007 \n",
      "[44/100][8/43] KL_real/fake: 4.552/4.548 mean_real/fake: -0.005/-0.007 var_real/fake: 0.007/0.007 \n",
      "[44/100][9/43] KL_real/fake: 4.557/4.548 mean_real/fake: -0.005/-0.007 var_real/fake: 0.007/0.007 \n",
      "[44/100][10/43] KL_real/fake: 4.557/4.555 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[44/100][11/43] KL_real/fake: 4.556/4.551 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[44/100][12/43] KL_real/fake: 4.559/4.549 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[44/100][13/43] KL_real/fake: 4.555/4.546 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[44/100][14/43] KL_real/fake: 4.554/4.547 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[44/100][15/43] KL_real/fake: 4.554/4.548 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[44/100][16/43] KL_real/fake: 4.557/4.548 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[44/100][17/43] KL_real/fake: 4.553/4.549 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[44/100][18/43] KL_real/fake: 4.552/4.550 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[44/100][19/43] KL_real/fake: 4.551/4.549 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[44/100][20/43] KL_real/fake: 4.551/4.545 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[44/100][21/43] KL_real/fake: 4.552/4.550 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[44/100][22/43] KL_real/fake: 4.559/4.550 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[44/100][23/43] KL_real/fake: 4.556/4.553 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[44/100][24/43] KL_real/fake: 4.557/4.549 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[44/100][25/43] KL_real/fake: 4.560/4.553 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[44/100][26/43] KL_real/fake: 4.568/4.558 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[44/100][27/43] KL_real/fake: 4.567/4.560 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.007 \n",
      "[44/100][28/43] KL_real/fake: 4.569/4.562 mean_real/fake: -0.007/-0.008 var_real/fake: 0.006/0.007 \n",
      "[44/100][29/43] KL_real/fake: 4.573/4.566 mean_real/fake: -0.005/-0.007 var_real/fake: 0.006/0.006 \n",
      "[44/100][30/43] KL_real/fake: 4.566/4.558 mean_real/fake: -0.008/-0.006 var_real/fake: 0.006/0.007 \n",
      "[44/100][31/43] KL_real/fake: 4.564/4.560 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.007 \n",
      "[44/100][32/43] KL_real/fake: 4.570/4.565 mean_real/fake: -0.007/-0.004 var_real/fake: 0.006/0.006 \n",
      "[44/100][33/43] KL_real/fake: 4.565/4.562 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[44/100][34/43] KL_real/fake: 4.557/4.550 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[44/100][35/43] KL_real/fake: 4.554/4.547 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[44/100][36/43] KL_real/fake: 4.550/4.545 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[44/100][37/43] KL_real/fake: 4.555/4.545 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[44/100][38/43] KL_real/fake: 4.552/4.540 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[44/100][39/43] KL_real/fake: 4.546/4.539 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[44/100][40/43] KL_real/fake: 4.548/4.541 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[44/100][41/43] KL_real/fake: 4.551/4.545 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[44/100][42/43] KL_real/fake: 4.554/4.549 mean_real/fake: -0.008/-0.005 var_real/fake: 0.007/0.007 \n",
      "[45/100][0/43] KL_real/fake: 4.565/4.553 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[45/100][1/43] KL_real/fake: 4.568/4.559 mean_real/fake: -0.007/-0.006 var_real/fake: 0.006/0.007 \n",
      "[45/100][2/43] KL_real/fake: 4.579/4.566 mean_real/fake: -0.007/-0.005 var_real/fake: 0.006/0.006 \n",
      "[45/100][3/43] KL_real/fake: 4.575/4.568 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[45/100][4/43] KL_real/fake: 4.569/4.564 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.007 \n",
      "[45/100][5/43] KL_real/fake: 4.571/4.564 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.007 \n",
      "[45/100][6/43] KL_real/fake: 4.556/4.553 mean_real/fake: -0.002/-0.005 var_real/fake: 0.007/0.007 \n",
      "[45/100][7/43] KL_real/fake: 4.556/4.544 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[45/100][8/43] KL_real/fake: 4.558/4.544 mean_real/fake: -0.001/-0.005 var_real/fake: 0.007/0.007 \n",
      "[45/100][9/43] KL_real/fake: 4.556/4.549 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[45/100][10/43] KL_real/fake: 4.562/4.552 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[45/100][11/43] KL_real/fake: 4.560/4.554 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[45/100][12/43] KL_real/fake: 4.560/4.551 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[45/100][13/43] KL_real/fake: 4.565/4.549 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[45/100][14/43] KL_real/fake: 4.561/4.553 mean_real/fake: -0.008/-0.006 var_real/fake: 0.007/0.007 \n",
      "[45/100][15/43] KL_real/fake: 4.566/4.557 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[45/100][16/43] KL_real/fake: 4.562/4.557 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45/100][17/43] KL_real/fake: 4.559/4.555 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[45/100][18/43] KL_real/fake: 4.566/4.558 mean_real/fake: -0.006/-0.005 var_real/fake: 0.006/0.007 \n",
      "[45/100][19/43] KL_real/fake: 4.568/4.552 mean_real/fake: -0.005/-0.003 var_real/fake: 0.006/0.007 \n",
      "[45/100][20/43] KL_real/fake: 4.557/4.550 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[45/100][21/43] KL_real/fake: 4.561/4.556 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[45/100][22/43] KL_real/fake: 4.559/4.553 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[45/100][23/43] KL_real/fake: 4.555/4.550 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[45/100][24/43] KL_real/fake: 4.558/4.548 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[45/100][25/43] KL_real/fake: 4.546/4.545 mean_real/fake: -0.004/-0.007 var_real/fake: 0.007/0.007 \n",
      "[45/100][26/43] KL_real/fake: 4.549/4.541 mean_real/fake: -0.005/-0.008 var_real/fake: 0.007/0.007 \n",
      "[45/100][27/43] KL_real/fake: 4.550/4.545 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[45/100][28/43] KL_real/fake: 4.554/4.548 mean_real/fake: -0.005/-0.007 var_real/fake: 0.007/0.007 \n",
      "[45/100][29/43] KL_real/fake: 4.559/4.548 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[45/100][30/43] KL_real/fake: 4.552/4.548 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[45/100][31/43] KL_real/fake: 4.553/4.551 mean_real/fake: -0.007/-0.004 var_real/fake: 0.007/0.007 \n",
      "[45/100][32/43] KL_real/fake: 4.550/4.546 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[45/100][33/43] KL_real/fake: 4.558/4.552 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[45/100][34/43] KL_real/fake: 4.560/4.552 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[45/100][35/43] KL_real/fake: 4.560/4.555 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[45/100][36/43] KL_real/fake: 4.554/4.555 mean_real/fake: -0.003/-0.006 var_real/fake: 0.007/0.007 \n",
      "[45/100][37/43] KL_real/fake: 4.554/4.547 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[45/100][38/43] KL_real/fake: 4.554/4.543 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[45/100][39/43] KL_real/fake: 4.555/4.547 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[45/100][40/43] KL_real/fake: 4.558/4.553 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[45/100][41/43] KL_real/fake: 4.554/4.551 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[45/100][42/43] KL_real/fake: 4.552/4.550 mean_real/fake: -0.007/-0.004 var_real/fake: 0.007/0.007 \n",
      "[46/100][0/43] KL_real/fake: 4.553/4.547 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[46/100][1/43] KL_real/fake: 4.556/4.548 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[46/100][2/43] KL_real/fake: 4.562/4.552 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[46/100][3/43] KL_real/fake: 4.562/4.558 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[46/100][4/43] KL_real/fake: 4.564/4.561 mean_real/fake: -0.006/-0.006 var_real/fake: 0.006/0.007 \n",
      "[46/100][5/43] KL_real/fake: 4.564/4.560 mean_real/fake: -0.005/-0.003 var_real/fake: 0.006/0.007 \n",
      "[46/100][6/43] KL_real/fake: 4.557/4.555 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[46/100][7/43] KL_real/fake: 4.555/4.553 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[46/100][8/43] KL_real/fake: 4.554/4.550 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[46/100][9/43] KL_real/fake: 4.554/4.548 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[46/100][10/43] KL_real/fake: 4.551/4.544 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[46/100][11/43] KL_real/fake: 4.549/4.544 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[46/100][12/43] KL_real/fake: 4.552/4.549 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[46/100][13/43] KL_real/fake: 4.554/4.551 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[46/100][14/43] KL_real/fake: 4.554/4.546 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[46/100][15/43] KL_real/fake: 4.551/4.545 mean_real/fake: -0.005/-0.002 var_real/fake: 0.007/0.007 \n",
      "[46/100][16/43] KL_real/fake: 4.556/4.544 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[46/100][17/43] KL_real/fake: 4.545/4.539 mean_real/fake: -0.003/-0.003 var_real/fake: 0.007/0.007 \n",
      "[46/100][18/43] KL_real/fake: 4.543/4.542 mean_real/fake: -0.002/-0.003 var_real/fake: 0.007/0.007 \n",
      "[46/100][19/43] KL_real/fake: 4.552/4.539 mean_real/fake: -0.002/-0.004 var_real/fake: 0.007/0.007 \n",
      "[46/100][20/43] KL_real/fake: 4.541/4.538 mean_real/fake: -0.001/-0.004 var_real/fake: 0.007/0.007 \n",
      "[46/100][21/43] KL_real/fake: 4.543/4.533 mean_real/fake: -0.002/-0.005 var_real/fake: 0.007/0.007 \n",
      "[46/100][22/43] KL_real/fake: 4.535/4.534 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[46/100][23/43] KL_real/fake: 4.535/4.537 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[46/100][24/43] KL_real/fake: 4.541/4.532 mean_real/fake: -0.007/-0.004 var_real/fake: 0.007/0.007 \n",
      "[46/100][25/43] KL_real/fake: 4.537/4.530 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[46/100][26/43] KL_real/fake: 4.539/4.533 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[46/100][27/43] KL_real/fake: 4.547/4.538 mean_real/fake: -0.002/-0.002 var_real/fake: 0.007/0.007 \n",
      "[46/100][28/43] KL_real/fake: 4.553/4.546 mean_real/fake: -0.002/-0.004 var_real/fake: 0.007/0.007 \n",
      "[46/100][29/43] KL_real/fake: 4.557/4.549 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[46/100][30/43] KL_real/fake: 4.563/4.554 mean_real/fake: -0.003/-0.003 var_real/fake: 0.006/0.007 \n",
      "[46/100][31/43] KL_real/fake: 4.570/4.559 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.007 \n",
      "[46/100][32/43] KL_real/fake: 4.568/4.562 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[46/100][33/43] KL_real/fake: 4.578/4.560 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.007 \n",
      "[46/100][34/43] KL_real/fake: 4.568/4.557 mean_real/fake: -0.006/-0.003 var_real/fake: 0.006/0.007 \n",
      "[46/100][35/43] KL_real/fake: 4.563/4.553 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.007 \n",
      "[46/100][36/43] KL_real/fake: 4.558/4.550 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[46/100][37/43] KL_real/fake: 4.562/4.548 mean_real/fake: -0.003/-0.003 var_real/fake: 0.007/0.007 \n",
      "[46/100][38/43] KL_real/fake: 4.556/4.548 mean_real/fake: -0.001/-0.002 var_real/fake: 0.007/0.007 \n",
      "[46/100][39/43] KL_real/fake: 4.557/4.547 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[46/100][40/43] KL_real/fake: 4.549/4.547 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[46/100][41/43] KL_real/fake: 4.555/4.545 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[46/100][42/43] KL_real/fake: 4.553/4.547 mean_real/fake: -0.002/-0.004 var_real/fake: 0.007/0.007 \n",
      "[47/100][0/43] KL_real/fake: 4.552/4.548 mean_real/fake: -0.002/-0.003 var_real/fake: 0.007/0.007 \n",
      "[47/100][1/43] KL_real/fake: 4.554/4.549 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[47/100][2/43] KL_real/fake: 4.557/4.547 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[47/100][3/43] KL_real/fake: 4.554/4.549 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[47/100][4/43] KL_real/fake: 4.558/4.550 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[47/100][5/43] KL_real/fake: 4.559/4.547 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[47/100][6/43] KL_real/fake: 4.551/4.544 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[47/100][7/43] KL_real/fake: 4.550/4.544 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[47/100][8/43] KL_real/fake: 4.549/4.546 mean_real/fake: -0.002/-0.003 var_real/fake: 0.007/0.007 \n",
      "[47/100][9/43] KL_real/fake: 4.547/4.542 mean_real/fake: -0.003/-0.003 var_real/fake: 0.007/0.007 \n",
      "[47/100][10/43] KL_real/fake: 4.552/4.541 mean_real/fake: -0.002/-0.004 var_real/fake: 0.007/0.007 \n",
      "[47/100][11/43] KL_real/fake: 4.546/4.539 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[47/100][12/43] KL_real/fake: 4.547/4.536 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[47/100][13/43] KL_real/fake: 4.547/4.535 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47/100][14/43] KL_real/fake: 4.556/4.536 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[47/100][15/43] KL_real/fake: 4.554/4.543 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[47/100][16/43] KL_real/fake: 4.552/4.540 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[47/100][17/43] KL_real/fake: 4.550/4.543 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[47/100][18/43] KL_real/fake: 4.549/4.538 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[47/100][19/43] KL_real/fake: 4.548/4.540 mean_real/fake: -0.007/-0.004 var_real/fake: 0.007/0.007 \n",
      "[47/100][20/43] KL_real/fake: 4.544/4.542 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[47/100][21/43] KL_real/fake: 4.544/4.541 mean_real/fake: -0.004/-0.007 var_real/fake: 0.007/0.007 \n",
      "[47/100][22/43] KL_real/fake: 4.548/4.543 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[47/100][23/43] KL_real/fake: 4.555/4.546 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[47/100][24/43] KL_real/fake: 4.553/4.545 mean_real/fake: -0.004/-0.007 var_real/fake: 0.007/0.007 \n",
      "[47/100][25/43] KL_real/fake: 4.554/4.545 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[47/100][26/43] KL_real/fake: 4.555/4.543 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[47/100][27/43] KL_real/fake: 4.547/4.542 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[47/100][28/43] KL_real/fake: 4.548/4.544 mean_real/fake: -0.005/-0.002 var_real/fake: 0.007/0.007 \n",
      "[47/100][29/43] KL_real/fake: 4.552/4.545 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[47/100][30/43] KL_real/fake: 4.550/4.545 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[47/100][31/43] KL_real/fake: 4.548/4.543 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[47/100][32/43] KL_real/fake: 4.552/4.542 mean_real/fake: -0.003/-0.006 var_real/fake: 0.007/0.007 \n",
      "[47/100][33/43] KL_real/fake: 4.552/4.547 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[47/100][34/43] KL_real/fake: 4.561/4.554 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[47/100][35/43] KL_real/fake: 4.560/4.558 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[47/100][36/43] KL_real/fake: 4.559/4.555 mean_real/fake: -0.003/-0.003 var_real/fake: 0.007/0.007 \n",
      "[47/100][37/43] KL_real/fake: 4.556/4.549 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[47/100][38/43] KL_real/fake: 4.557/4.553 mean_real/fake: -0.003/-0.001 var_real/fake: 0.007/0.007 \n",
      "[47/100][39/43] KL_real/fake: 4.553/4.551 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[47/100][40/43] KL_real/fake: 4.554/4.551 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[47/100][41/43] KL_real/fake: 4.553/4.549 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[47/100][42/43] KL_real/fake: 4.551/4.547 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[48/100][0/43] KL_real/fake: 4.549/4.544 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[48/100][1/43] KL_real/fake: 4.549/4.542 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[48/100][2/43] KL_real/fake: 4.552/4.535 mean_real/fake: -0.009/-0.006 var_real/fake: 0.007/0.007 \n",
      "[48/100][3/43] KL_real/fake: 4.544/4.534 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[48/100][4/43] KL_real/fake: 4.541/4.531 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[48/100][5/43] KL_real/fake: 4.543/4.538 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[48/100][6/43] KL_real/fake: 4.546/4.541 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[48/100][7/43] KL_real/fake: 4.556/4.545 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[48/100][8/43] KL_real/fake: 4.561/4.552 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[48/100][9/43] KL_real/fake: 4.563/4.554 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[48/100][10/43] KL_real/fake: 4.558/4.555 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[48/100][11/43] KL_real/fake: 4.558/4.553 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[48/100][12/43] KL_real/fake: 4.553/4.545 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[48/100][13/43] KL_real/fake: 4.553/4.550 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[48/100][14/43] KL_real/fake: 4.557/4.551 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[48/100][15/43] KL_real/fake: 4.550/4.545 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[48/100][16/43] KL_real/fake: 4.548/4.541 mean_real/fake: -0.002/-0.004 var_real/fake: 0.007/0.007 \n",
      "[48/100][17/43] KL_real/fake: 4.547/4.542 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[48/100][18/43] KL_real/fake: 4.552/4.545 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[48/100][19/43] KL_real/fake: 4.554/4.548 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[48/100][20/43] KL_real/fake: 4.548/4.543 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[48/100][21/43] KL_real/fake: 4.548/4.539 mean_real/fake: -0.008/-0.004 var_real/fake: 0.007/0.007 \n",
      "[48/100][22/43] KL_real/fake: 4.544/4.534 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[48/100][23/43] KL_real/fake: 4.540/4.535 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[48/100][24/43] KL_real/fake: 4.540/4.537 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[48/100][25/43] KL_real/fake: 4.546/4.534 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[48/100][26/43] KL_real/fake: 4.541/4.538 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[48/100][27/43] KL_real/fake: 4.547/4.542 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[48/100][28/43] KL_real/fake: 4.558/4.549 mean_real/fake: -0.004/-0.007 var_real/fake: 0.007/0.007 \n",
      "[48/100][29/43] KL_real/fake: 4.553/4.551 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[48/100][30/43] KL_real/fake: 4.555/4.545 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[48/100][31/43] KL_real/fake: 4.553/4.544 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[48/100][32/43] KL_real/fake: 4.548/4.540 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[48/100][33/43] KL_real/fake: 4.558/4.549 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[48/100][34/43] KL_real/fake: 4.563/4.558 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.007 \n",
      "[48/100][35/43] KL_real/fake: 4.579/4.566 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[48/100][36/43] KL_real/fake: 4.578/4.569 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.006 \n",
      "[48/100][37/43] KL_real/fake: 4.578/4.564 mean_real/fake: -0.004/-0.003 var_real/fake: 0.006/0.007 \n",
      "[48/100][38/43] KL_real/fake: 4.579/4.566 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.006 \n",
      "[48/100][39/43] KL_real/fake: 4.572/4.566 mean_real/fake: -0.004/-0.004 var_real/fake: 0.006/0.006 \n",
      "[48/100][40/43] KL_real/fake: 4.565/4.560 mean_real/fake: -0.003/-0.004 var_real/fake: 0.006/0.007 \n",
      "[48/100][41/43] KL_real/fake: 4.559/4.553 mean_real/fake: -0.003/-0.003 var_real/fake: 0.007/0.007 \n",
      "[48/100][42/43] KL_real/fake: 4.554/4.546 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[49/100][0/43] KL_real/fake: 4.550/4.543 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[49/100][1/43] KL_real/fake: 4.550/4.546 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[49/100][2/43] KL_real/fake: 4.552/4.548 mean_real/fake: -0.005/-0.007 var_real/fake: 0.007/0.007 \n",
      "[49/100][3/43] KL_real/fake: 4.552/4.545 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[49/100][4/43] KL_real/fake: 4.550/4.542 mean_real/fake: -0.007/-0.004 var_real/fake: 0.007/0.007 \n",
      "[49/100][5/43] KL_real/fake: 4.548/4.544 mean_real/fake: -0.003/-0.006 var_real/fake: 0.007/0.007 \n",
      "[49/100][6/43] KL_real/fake: 4.558/4.544 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[49/100][7/43] KL_real/fake: 4.552/4.545 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[49/100][8/43] KL_real/fake: 4.553/4.547 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[49/100][9/43] KL_real/fake: 4.559/4.551 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[49/100][10/43] KL_real/fake: 4.557/4.551 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49/100][11/43] KL_real/fake: 4.555/4.551 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[49/100][12/43] KL_real/fake: 4.562/4.548 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[49/100][13/43] KL_real/fake: 4.558/4.553 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[49/100][14/43] KL_real/fake: 4.558/4.548 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[49/100][15/43] KL_real/fake: 4.554/4.546 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[49/100][16/43] KL_real/fake: 4.552/4.546 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[49/100][17/43] KL_real/fake: 4.551/4.542 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[49/100][18/43] KL_real/fake: 4.544/4.540 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[49/100][19/43] KL_real/fake: 4.548/4.539 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[49/100][20/43] KL_real/fake: 4.547/4.541 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[49/100][21/43] KL_real/fake: 4.545/4.542 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[49/100][22/43] KL_real/fake: 4.550/4.543 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[49/100][23/43] KL_real/fake: 4.544/4.536 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[49/100][24/43] KL_real/fake: 4.545/4.531 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[49/100][25/43] KL_real/fake: 4.543/4.530 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[49/100][26/43] KL_real/fake: 4.552/4.533 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[49/100][27/43] KL_real/fake: 4.545/4.535 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[49/100][28/43] KL_real/fake: 4.548/4.537 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[49/100][29/43] KL_real/fake: 4.547/4.539 mean_real/fake: -0.008/-0.007 var_real/fake: 0.007/0.007 \n",
      "[49/100][30/43] KL_real/fake: 4.547/4.541 mean_real/fake: -0.007/-0.007 var_real/fake: 0.007/0.007 \n",
      "[49/100][31/43] KL_real/fake: 4.558/4.551 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[49/100][32/43] KL_real/fake: 4.558/4.549 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[49/100][33/43] KL_real/fake: 4.559/4.550 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[49/100][34/43] KL_real/fake: 4.558/4.550 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[49/100][35/43] KL_real/fake: 4.559/4.551 mean_real/fake: -0.007/-0.007 var_real/fake: 0.007/0.007 \n",
      "[49/100][36/43] KL_real/fake: 4.561/4.555 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[49/100][37/43] KL_real/fake: 4.562/4.553 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[49/100][38/43] KL_real/fake: 4.557/4.552 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[49/100][39/43] KL_real/fake: 4.554/4.551 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[49/100][40/43] KL_real/fake: 4.550/4.548 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[49/100][41/43] KL_real/fake: 4.547/4.545 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[49/100][42/43] KL_real/fake: 4.553/4.549 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "Adjusting learning rate from 0.000100 to 0.000050 on E and G\n",
      "[50/100][0/43] KL_real/fake: 4.558/4.555 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[50/100][1/43] KL_real/fake: 4.559/4.553 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[50/100][2/43] KL_real/fake: 4.556/4.551 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[50/100][3/43] KL_real/fake: 4.559/4.553 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[50/100][4/43] KL_real/fake: 4.560/4.557 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[50/100][5/43] KL_real/fake: 4.563/4.557 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[50/100][6/43] KL_real/fake: 4.559/4.560 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[50/100][7/43] KL_real/fake: 4.563/4.559 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[50/100][8/43] KL_real/fake: 4.561/4.559 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[50/100][9/43] KL_real/fake: 4.568/4.559 mean_real/fake: -0.006/-0.004 var_real/fake: 0.006/0.006 \n",
      "[50/100][10/43] KL_real/fake: 4.560/4.557 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[50/100][11/43] KL_real/fake: 4.561/4.556 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[50/100][12/43] KL_real/fake: 4.565/4.558 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.007 \n",
      "[50/100][13/43] KL_real/fake: 4.559/4.554 mean_real/fake: -0.005/-0.004 var_real/fake: 0.006/0.007 \n",
      "[50/100][14/43] KL_real/fake: 4.554/4.554 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[50/100][15/43] KL_real/fake: 4.554/4.552 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[50/100][16/43] KL_real/fake: 4.552/4.550 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[50/100][17/43] KL_real/fake: 4.552/4.549 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[50/100][18/43] KL_real/fake: 4.552/4.547 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[50/100][19/43] KL_real/fake: 4.555/4.550 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[50/100][20/43] KL_real/fake: 4.553/4.549 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[50/100][21/43] KL_real/fake: 4.551/4.549 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[50/100][22/43] KL_real/fake: 4.552/4.549 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[50/100][23/43] KL_real/fake: 4.553/4.548 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[50/100][24/43] KL_real/fake: 4.549/4.545 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[50/100][25/43] KL_real/fake: 4.548/4.546 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[50/100][26/43] KL_real/fake: 4.545/4.544 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[50/100][27/43] KL_real/fake: 4.550/4.547 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[50/100][28/43] KL_real/fake: 4.551/4.545 mean_real/fake: -0.003/-0.003 var_real/fake: 0.007/0.007 \n",
      "[50/100][29/43] KL_real/fake: 4.549/4.546 mean_real/fake: -0.003/-0.006 var_real/fake: 0.007/0.007 \n",
      "[50/100][30/43] KL_real/fake: 4.552/4.547 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[50/100][31/43] KL_real/fake: 4.548/4.548 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[50/100][32/43] KL_real/fake: 4.548/4.548 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[50/100][33/43] KL_real/fake: 4.550/4.547 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[50/100][34/43] KL_real/fake: 4.551/4.546 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[50/100][35/43] KL_real/fake: 4.548/4.548 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[50/100][36/43] KL_real/fake: 4.544/4.543 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[50/100][37/43] KL_real/fake: 4.552/4.545 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[50/100][38/43] KL_real/fake: 4.549/4.545 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[50/100][39/43] KL_real/fake: 4.549/4.546 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[50/100][40/43] KL_real/fake: 4.550/4.546 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[50/100][41/43] KL_real/fake: 4.551/4.547 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[50/100][42/43] KL_real/fake: 4.548/4.545 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[51/100][0/43] KL_real/fake: 4.548/4.547 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[51/100][1/43] KL_real/fake: 4.551/4.550 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[51/100][2/43] KL_real/fake: 4.554/4.554 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[51/100][3/43] KL_real/fake: 4.556/4.554 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[51/100][4/43] KL_real/fake: 4.559/4.553 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[51/100][5/43] KL_real/fake: 4.557/4.553 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[51/100][6/43] KL_real/fake: 4.555/4.554 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51/100][7/43] KL_real/fake: 4.554/4.553 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[51/100][8/43] KL_real/fake: 4.555/4.551 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[51/100][9/43] KL_real/fake: 4.554/4.553 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[51/100][10/43] KL_real/fake: 4.552/4.547 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[51/100][11/43] KL_real/fake: 4.556/4.546 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[51/100][12/43] KL_real/fake: 4.548/4.546 mean_real/fake: -0.003/-0.006 var_real/fake: 0.007/0.007 \n",
      "[51/100][13/43] KL_real/fake: 4.547/4.547 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[51/100][14/43] KL_real/fake: 4.548/4.549 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[51/100][15/43] KL_real/fake: 4.549/4.547 mean_real/fake: -0.004/-0.007 var_real/fake: 0.007/0.007 \n",
      "[51/100][16/43] KL_real/fake: 4.546/4.545 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[51/100][17/43] KL_real/fake: 4.547/4.546 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[51/100][18/43] KL_real/fake: 4.550/4.544 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[51/100][19/43] KL_real/fake: 4.547/4.546 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[51/100][20/43] KL_real/fake: 4.548/4.544 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[51/100][21/43] KL_real/fake: 4.546/4.543 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[51/100][22/43] KL_real/fake: 4.548/4.543 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[51/100][23/43] KL_real/fake: 4.544/4.542 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[51/100][24/43] KL_real/fake: 4.547/4.547 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[51/100][25/43] KL_real/fake: 4.548/4.544 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[51/100][26/43] KL_real/fake: 4.547/4.543 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[51/100][27/43] KL_real/fake: 4.548/4.549 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[51/100][28/43] KL_real/fake: 4.555/4.550 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[51/100][29/43] KL_real/fake: 4.552/4.551 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[51/100][30/43] KL_real/fake: 4.554/4.550 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[51/100][31/43] KL_real/fake: 4.550/4.549 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[51/100][32/43] KL_real/fake: 4.550/4.549 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[51/100][33/43] KL_real/fake: 4.553/4.547 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[51/100][34/43] KL_real/fake: 4.546/4.547 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[51/100][35/43] KL_real/fake: 4.549/4.546 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[51/100][36/43] KL_real/fake: 4.549/4.545 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[51/100][37/43] KL_real/fake: 4.551/4.547 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[51/100][38/43] KL_real/fake: 4.555/4.551 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[51/100][39/43] KL_real/fake: 4.556/4.552 mean_real/fake: -0.003/-0.006 var_real/fake: 0.007/0.007 \n",
      "[51/100][40/43] KL_real/fake: 4.559/4.553 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[51/100][41/43] KL_real/fake: 4.560/4.557 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[51/100][42/43] KL_real/fake: 4.562/4.556 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[52/100][0/43] KL_real/fake: 4.564/4.558 mean_real/fake: -0.003/-0.005 var_real/fake: 0.006/0.007 \n",
      "[52/100][1/43] KL_real/fake: 4.560/4.557 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[52/100][2/43] KL_real/fake: 4.558/4.556 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[52/100][3/43] KL_real/fake: 4.555/4.556 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[52/100][4/43] KL_real/fake: 4.553/4.553 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[52/100][5/43] KL_real/fake: 4.556/4.554 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[52/100][6/43] KL_real/fake: 4.556/4.553 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[52/100][7/43] KL_real/fake: 4.551/4.552 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[52/100][8/43] KL_real/fake: 4.552/4.548 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[52/100][9/43] KL_real/fake: 4.547/4.545 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[52/100][10/43] KL_real/fake: 4.545/4.541 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[52/100][11/43] KL_real/fake: 4.545/4.544 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[52/100][12/43] KL_real/fake: 4.551/4.546 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[52/100][13/43] KL_real/fake: 4.546/4.543 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[52/100][14/43] KL_real/fake: 4.546/4.544 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[52/100][15/43] KL_real/fake: 4.550/4.547 mean_real/fake: -0.006/-0.003 var_real/fake: 0.007/0.007 \n",
      "[52/100][16/43] KL_real/fake: 4.549/4.546 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[52/100][17/43] KL_real/fake: 4.549/4.547 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[52/100][18/43] KL_real/fake: 4.551/4.548 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[52/100][19/43] KL_real/fake: 4.550/4.547 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[52/100][20/43] KL_real/fake: 4.545/4.546 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[52/100][21/43] KL_real/fake: 4.546/4.545 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[52/100][22/43] KL_real/fake: 4.547/4.545 mean_real/fake: -0.002/-0.007 var_real/fake: 0.007/0.007 \n",
      "[52/100][23/43] KL_real/fake: 4.551/4.544 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[52/100][24/43] KL_real/fake: 4.544/4.544 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[52/100][25/43] KL_real/fake: 4.544/4.545 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[52/100][26/43] KL_real/fake: 4.545/4.542 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[52/100][27/43] KL_real/fake: 4.547/4.544 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[52/100][28/43] KL_real/fake: 4.551/4.546 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[52/100][29/43] KL_real/fake: 4.547/4.546 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[52/100][30/43] KL_real/fake: 4.546/4.545 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[52/100][31/43] KL_real/fake: 4.549/4.547 mean_real/fake: -0.004/-0.007 var_real/fake: 0.007/0.007 \n",
      "[52/100][32/43] KL_real/fake: 4.548/4.546 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[52/100][33/43] KL_real/fake: 4.548/4.546 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[52/100][34/43] KL_real/fake: 4.552/4.549 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[52/100][35/43] KL_real/fake: 4.551/4.549 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[52/100][36/43] KL_real/fake: 4.551/4.546 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[52/100][37/43] KL_real/fake: 4.548/4.549 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[52/100][38/43] KL_real/fake: 4.550/4.548 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[52/100][39/43] KL_real/fake: 4.552/4.546 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[52/100][40/43] KL_real/fake: 4.552/4.548 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[52/100][41/43] KL_real/fake: 4.552/4.550 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[52/100][42/43] KL_real/fake: 4.553/4.549 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[53/100][0/43] KL_real/fake: 4.551/4.553 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[53/100][1/43] KL_real/fake: 4.553/4.551 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[53/100][2/43] KL_real/fake: 4.554/4.549 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[53/100][3/43] KL_real/fake: 4.551/4.548 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53/100][4/43] KL_real/fake: 4.556/4.551 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[53/100][5/43] KL_real/fake: 4.553/4.549 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[53/100][6/43] KL_real/fake: 4.560/4.553 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[53/100][7/43] KL_real/fake: 4.559/4.552 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[53/100][8/43] KL_real/fake: 4.558/4.555 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[53/100][9/43] KL_real/fake: 4.562/4.558 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[53/100][10/43] KL_real/fake: 4.563/4.558 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[53/100][11/43] KL_real/fake: 4.563/4.557 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[53/100][12/43] KL_real/fake: 4.562/4.559 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.007 \n",
      "[53/100][13/43] KL_real/fake: 4.566/4.558 mean_real/fake: -0.005/-0.003 var_real/fake: 0.006/0.007 \n",
      "[53/100][14/43] KL_real/fake: 4.560/4.558 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[53/100][15/43] KL_real/fake: 4.559/4.555 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[53/100][16/43] KL_real/fake: 4.554/4.554 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[53/100][17/43] KL_real/fake: 4.554/4.551 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[53/100][18/43] KL_real/fake: 4.553/4.554 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[53/100][19/43] KL_real/fake: 4.558/4.553 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[53/100][20/43] KL_real/fake: 4.555/4.554 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[53/100][21/43] KL_real/fake: 4.558/4.556 mean_real/fake: -0.005/-0.005 var_real/fake: 0.006/0.007 \n",
      "[53/100][22/43] KL_real/fake: 4.564/4.555 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.007 \n",
      "[53/100][23/43] KL_real/fake: 4.557/4.553 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[53/100][24/43] KL_real/fake: 4.558/4.553 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[53/100][25/43] KL_real/fake: 4.557/4.554 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[53/100][26/43] KL_real/fake: 4.553/4.549 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[53/100][27/43] KL_real/fake: 4.548/4.545 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[53/100][28/43] KL_real/fake: 4.552/4.543 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[53/100][29/43] KL_real/fake: 4.543/4.541 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[53/100][30/43] KL_real/fake: 4.540/4.538 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[53/100][31/43] KL_real/fake: 4.539/4.537 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[53/100][32/43] KL_real/fake: 4.539/4.538 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[53/100][33/43] KL_real/fake: 4.544/4.541 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[53/100][34/43] KL_real/fake: 4.542/4.540 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[53/100][35/43] KL_real/fake: 4.545/4.542 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[53/100][36/43] KL_real/fake: 4.544/4.545 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[53/100][37/43] KL_real/fake: 4.549/4.545 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[53/100][38/43] KL_real/fake: 4.551/4.546 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[53/100][39/43] KL_real/fake: 4.551/4.547 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[53/100][40/43] KL_real/fake: 4.551/4.545 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[53/100][41/43] KL_real/fake: 4.554/4.544 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[53/100][42/43] KL_real/fake: 4.556/4.547 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[54/100][0/43] KL_real/fake: 4.549/4.544 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[54/100][1/43] KL_real/fake: 4.550/4.548 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[54/100][2/43] KL_real/fake: 4.551/4.548 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[54/100][3/43] KL_real/fake: 4.556/4.549 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[54/100][4/43] KL_real/fake: 4.551/4.546 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[54/100][5/43] KL_real/fake: 4.547/4.541 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[54/100][6/43] KL_real/fake: 4.550/4.541 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[54/100][7/43] KL_real/fake: 4.543/4.536 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[54/100][8/43] KL_real/fake: 4.538/4.538 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[54/100][9/43] KL_real/fake: 4.542/4.539 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[54/100][10/43] KL_real/fake: 4.545/4.540 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[54/100][11/43] KL_real/fake: 4.540/4.537 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[54/100][12/43] KL_real/fake: 4.539/4.535 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[54/100][13/43] KL_real/fake: 4.534/4.533 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[54/100][14/43] KL_real/fake: 4.542/4.532 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[54/100][15/43] KL_real/fake: 4.536/4.530 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[54/100][16/43] KL_real/fake: 4.537/4.533 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[54/100][17/43] KL_real/fake: 4.535/4.530 mean_real/fake: -0.003/-0.006 var_real/fake: 0.007/0.007 \n",
      "[54/100][18/43] KL_real/fake: 4.538/4.536 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[54/100][19/43] KL_real/fake: 4.544/4.544 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[54/100][20/43] KL_real/fake: 4.545/4.542 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[54/100][21/43] KL_real/fake: 4.544/4.543 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[54/100][22/43] KL_real/fake: 4.552/4.545 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[54/100][23/43] KL_real/fake: 4.549/4.545 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[54/100][24/43] KL_real/fake: 4.553/4.547 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[54/100][25/43] KL_real/fake: 4.555/4.550 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[54/100][26/43] KL_real/fake: 4.553/4.552 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[54/100][27/43] KL_real/fake: 4.557/4.555 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[54/100][28/43] KL_real/fake: 4.559/4.553 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[54/100][29/43] KL_real/fake: 4.564/4.555 mean_real/fake: -0.004/-0.005 var_real/fake: 0.006/0.007 \n",
      "[54/100][30/43] KL_real/fake: 4.558/4.553 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[54/100][31/43] KL_real/fake: 4.556/4.553 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[54/100][32/43] KL_real/fake: 4.555/4.549 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[54/100][33/43] KL_real/fake: 4.551/4.548 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[54/100][34/43] KL_real/fake: 4.551/4.547 mean_real/fake: -0.005/-0.007 var_real/fake: 0.007/0.007 \n",
      "[54/100][35/43] KL_real/fake: 4.548/4.547 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[54/100][36/43] KL_real/fake: 4.551/4.550 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[54/100][37/43] KL_real/fake: 4.548/4.542 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[54/100][38/43] KL_real/fake: 4.546/4.542 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[54/100][39/43] KL_real/fake: 4.545/4.544 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[54/100][40/43] KL_real/fake: 4.547/4.544 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[54/100][41/43] KL_real/fake: 4.547/4.547 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[54/100][42/43] KL_real/fake: 4.549/4.544 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[55/100][0/43] KL_real/fake: 4.549/4.546 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55/100][1/43] KL_real/fake: 4.551/4.547 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[55/100][2/43] KL_real/fake: 4.552/4.546 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[55/100][3/43] KL_real/fake: 4.553/4.544 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[55/100][4/43] KL_real/fake: 4.548/4.545 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[55/100][5/43] KL_real/fake: 4.548/4.545 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[55/100][6/43] KL_real/fake: 4.548/4.546 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[55/100][7/43] KL_real/fake: 4.550/4.543 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[55/100][8/43] KL_real/fake: 4.546/4.543 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[55/100][9/43] KL_real/fake: 4.547/4.543 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[55/100][10/43] KL_real/fake: 4.550/4.548 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[55/100][11/43] KL_real/fake: 4.545/4.541 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[55/100][12/43] KL_real/fake: 4.544/4.542 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[55/100][13/43] KL_real/fake: 4.542/4.543 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[55/100][14/43] KL_real/fake: 4.542/4.540 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[55/100][15/43] KL_real/fake: 4.540/4.536 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[55/100][16/43] KL_real/fake: 4.538/4.539 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[55/100][17/43] KL_real/fake: 4.539/4.538 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[55/100][18/43] KL_real/fake: 4.539/4.539 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[55/100][19/43] KL_real/fake: 4.541/4.537 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[55/100][20/43] KL_real/fake: 4.541/4.540 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[55/100][21/43] KL_real/fake: 4.542/4.543 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[55/100][22/43] KL_real/fake: 4.544/4.543 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[55/100][23/43] KL_real/fake: 4.548/4.543 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[55/100][24/43] KL_real/fake: 4.542/4.542 mean_real/fake: -0.004/-0.007 var_real/fake: 0.007/0.007 \n",
      "[55/100][25/43] KL_real/fake: 4.540/4.540 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[55/100][26/43] KL_real/fake: 4.541/4.539 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[55/100][27/43] KL_real/fake: 4.539/4.538 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[55/100][28/43] KL_real/fake: 4.537/4.537 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[55/100][29/43] KL_real/fake: 4.538/4.538 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[55/100][30/43] KL_real/fake: 4.542/4.538 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[55/100][31/43] KL_real/fake: 4.545/4.539 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[55/100][32/43] KL_real/fake: 4.543/4.540 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[55/100][33/43] KL_real/fake: 4.544/4.541 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[55/100][34/43] KL_real/fake: 4.542/4.541 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[55/100][35/43] KL_real/fake: 4.548/4.543 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[55/100][36/43] KL_real/fake: 4.545/4.544 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[55/100][37/43] KL_real/fake: 4.540/4.538 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[55/100][38/43] KL_real/fake: 4.540/4.536 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[55/100][39/43] KL_real/fake: 4.541/4.537 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[55/100][40/43] KL_real/fake: 4.542/4.540 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[55/100][41/43] KL_real/fake: 4.544/4.542 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[55/100][42/43] KL_real/fake: 4.547/4.544 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[56/100][0/43] KL_real/fake: 4.552/4.546 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[56/100][1/43] KL_real/fake: 4.553/4.549 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[56/100][2/43] KL_real/fake: 4.550/4.548 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[56/100][3/43] KL_real/fake: 4.549/4.550 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[56/100][4/43] KL_real/fake: 4.549/4.546 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[56/100][5/43] KL_real/fake: 4.547/4.546 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[56/100][6/43] KL_real/fake: 4.546/4.543 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[56/100][7/43] KL_real/fake: 4.546/4.543 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[56/100][8/43] KL_real/fake: 4.542/4.539 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[56/100][9/43] KL_real/fake: 4.540/4.535 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[56/100][10/43] KL_real/fake: 4.538/4.534 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[56/100][11/43] KL_real/fake: 4.539/4.535 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[56/100][12/43] KL_real/fake: 4.540/4.538 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[56/100][13/43] KL_real/fake: 4.540/4.541 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[56/100][14/43] KL_real/fake: 4.542/4.538 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[56/100][15/43] KL_real/fake: 4.537/4.537 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[56/100][16/43] KL_real/fake: 4.545/4.539 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[56/100][17/43] KL_real/fake: 4.555/4.542 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[56/100][18/43] KL_real/fake: 4.538/4.536 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[56/100][19/43] KL_real/fake: 4.538/4.539 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[56/100][20/43] KL_real/fake: 4.540/4.535 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[56/100][21/43] KL_real/fake: 4.537/4.536 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[56/100][22/43] KL_real/fake: 4.538/4.533 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[56/100][23/43] KL_real/fake: 4.533/4.531 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[56/100][24/43] KL_real/fake: 4.534/4.531 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[56/100][25/43] KL_real/fake: 4.535/4.535 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[56/100][26/43] KL_real/fake: 4.544/4.538 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[56/100][27/43] KL_real/fake: 4.541/4.538 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[56/100][28/43] KL_real/fake: 4.542/4.539 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[56/100][29/43] KL_real/fake: 4.547/4.542 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[56/100][30/43] KL_real/fake: 4.545/4.543 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[56/100][31/43] KL_real/fake: 4.551/4.547 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[56/100][32/43] KL_real/fake: 4.550/4.551 mean_real/fake: -0.003/-0.003 var_real/fake: 0.007/0.007 \n",
      "[56/100][33/43] KL_real/fake: 4.549/4.546 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[56/100][34/43] KL_real/fake: 4.547/4.546 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[56/100][35/43] KL_real/fake: 4.548/4.542 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[56/100][36/43] KL_real/fake: 4.547/4.544 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[56/100][37/43] KL_real/fake: 4.547/4.546 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[56/100][38/43] KL_real/fake: 4.548/4.546 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[56/100][39/43] KL_real/fake: 4.548/4.547 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[56/100][40/43] KL_real/fake: 4.551/4.548 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56/100][41/43] KL_real/fake: 4.550/4.548 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[56/100][42/43] KL_real/fake: 4.553/4.546 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[57/100][0/43] KL_real/fake: 4.545/4.546 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[57/100][1/43] KL_real/fake: 4.548/4.542 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[57/100][2/43] KL_real/fake: 4.543/4.542 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[57/100][3/43] KL_real/fake: 4.550/4.547 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[57/100][4/43] KL_real/fake: 4.551/4.546 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[57/100][5/43] KL_real/fake: 4.549/4.545 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[57/100][6/43] KL_real/fake: 4.546/4.544 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[57/100][7/43] KL_real/fake: 4.548/4.541 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[57/100][8/43] KL_real/fake: 4.545/4.542 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[57/100][9/43] KL_real/fake: 4.540/4.540 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[57/100][10/43] KL_real/fake: 4.542/4.540 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[57/100][11/43] KL_real/fake: 4.548/4.540 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[57/100][12/43] KL_real/fake: 4.546/4.544 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[57/100][13/43] KL_real/fake: 4.552/4.549 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[57/100][14/43] KL_real/fake: 4.545/4.545 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[57/100][15/43] KL_real/fake: 4.549/4.547 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[57/100][16/43] KL_real/fake: 4.552/4.547 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[57/100][17/43] KL_real/fake: 4.549/4.548 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[57/100][18/43] KL_real/fake: 4.548/4.546 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[57/100][19/43] KL_real/fake: 4.550/4.547 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[57/100][20/43] KL_real/fake: 4.552/4.543 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[57/100][21/43] KL_real/fake: 4.544/4.541 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[57/100][22/43] KL_real/fake: 4.537/4.534 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[57/100][23/43] KL_real/fake: 4.538/4.534 mean_real/fake: -0.006/-0.003 var_real/fake: 0.007/0.007 \n",
      "[57/100][24/43] KL_real/fake: 4.533/4.530 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[57/100][25/43] KL_real/fake: 4.535/4.529 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[57/100][26/43] KL_real/fake: 4.539/4.526 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[57/100][27/43] KL_real/fake: 4.533/4.524 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[57/100][28/43] KL_real/fake: 4.533/4.525 mean_real/fake: -0.007/-0.004 var_real/fake: 0.007/0.007 \n",
      "[57/100][29/43] KL_real/fake: 4.532/4.529 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[57/100][30/43] KL_real/fake: 4.533/4.531 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[57/100][31/43] KL_real/fake: 4.539/4.536 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[57/100][32/43] KL_real/fake: 4.541/4.539 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[57/100][33/43] KL_real/fake: 4.541/4.540 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[57/100][34/43] KL_real/fake: 4.539/4.534 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[57/100][35/43] KL_real/fake: 4.542/4.538 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[57/100][36/43] KL_real/fake: 4.541/4.536 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[57/100][37/43] KL_real/fake: 4.544/4.535 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[57/100][38/43] KL_real/fake: 4.544/4.537 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[57/100][39/43] KL_real/fake: 4.542/4.539 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[57/100][40/43] KL_real/fake: 4.543/4.539 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[57/100][41/43] KL_real/fake: 4.547/4.539 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[57/100][42/43] KL_real/fake: 4.551/4.543 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[58/100][0/43] KL_real/fake: 4.549/4.549 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[58/100][1/43] KL_real/fake: 4.551/4.548 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[58/100][2/43] KL_real/fake: 4.549/4.549 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[58/100][3/43] KL_real/fake: 4.547/4.544 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[58/100][4/43] KL_real/fake: 4.543/4.542 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[58/100][5/43] KL_real/fake: 4.543/4.543 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[58/100][6/43] KL_real/fake: 4.540/4.534 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[58/100][7/43] KL_real/fake: 4.538/4.533 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[58/100][8/43] KL_real/fake: 4.533/4.532 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[58/100][9/43] KL_real/fake: 4.531/4.528 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[58/100][10/43] KL_real/fake: 4.538/4.533 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[58/100][11/43] KL_real/fake: 4.537/4.535 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[58/100][12/43] KL_real/fake: 4.542/4.537 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[58/100][13/43] KL_real/fake: 4.539/4.538 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[58/100][14/43] KL_real/fake: 4.543/4.539 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[58/100][15/43] KL_real/fake: 4.538/4.533 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[58/100][16/43] KL_real/fake: 4.533/4.532 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[58/100][17/43] KL_real/fake: 4.531/4.531 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[58/100][18/43] KL_real/fake: 4.535/4.532 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[58/100][19/43] KL_real/fake: 4.534/4.533 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[58/100][20/43] KL_real/fake: 4.536/4.531 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[58/100][21/43] KL_real/fake: 4.533/4.533 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[58/100][22/43] KL_real/fake: 4.534/4.531 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[58/100][23/43] KL_real/fake: 4.534/4.529 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[58/100][24/43] KL_real/fake: 4.534/4.530 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[58/100][25/43] KL_real/fake: 4.535/4.532 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[58/100][26/43] KL_real/fake: 4.531/4.531 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[58/100][27/43] KL_real/fake: 4.533/4.534 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[58/100][28/43] KL_real/fake: 4.534/4.535 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[58/100][29/43] KL_real/fake: 4.538/4.532 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[58/100][30/43] KL_real/fake: 4.534/4.530 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[58/100][31/43] KL_real/fake: 4.536/4.534 mean_real/fake: -0.003/-0.003 var_real/fake: 0.007/0.007 \n",
      "[58/100][32/43] KL_real/fake: 4.538/4.536 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[58/100][33/43] KL_real/fake: 4.538/4.540 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[58/100][34/43] KL_real/fake: 4.542/4.543 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[58/100][35/43] KL_real/fake: 4.556/4.549 mean_real/fake: -0.003/-0.004 var_real/fake: 0.007/0.007 \n",
      "[58/100][36/43] KL_real/fake: 4.552/4.552 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[58/100][37/43] KL_real/fake: 4.551/4.549 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58/100][38/43] KL_real/fake: 4.549/4.547 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[58/100][39/43] KL_real/fake: 4.553/4.547 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[58/100][40/43] KL_real/fake: 4.548/4.545 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[58/100][41/43] KL_real/fake: 4.546/4.547 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[58/100][42/43] KL_real/fake: 4.555/4.548 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[59/100][0/43] KL_real/fake: 4.548/4.548 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[59/100][1/43] KL_real/fake: 4.552/4.545 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[59/100][2/43] KL_real/fake: 4.544/4.543 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[59/100][3/43] KL_real/fake: 4.543/4.542 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[59/100][4/43] KL_real/fake: 4.541/4.539 mean_real/fake: -0.003/-0.006 var_real/fake: 0.007/0.007 \n",
      "[59/100][5/43] KL_real/fake: 4.540/4.540 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[59/100][6/43] KL_real/fake: 4.543/4.541 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[59/100][7/43] KL_real/fake: 4.546/4.543 mean_real/fake: -0.003/-0.006 var_real/fake: 0.007/0.007 \n",
      "[59/100][8/43] KL_real/fake: 4.550/4.546 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[59/100][9/43] KL_real/fake: 4.548/4.543 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[59/100][10/43] KL_real/fake: 4.550/4.546 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[59/100][11/43] KL_real/fake: 4.551/4.544 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[59/100][12/43] KL_real/fake: 4.548/4.544 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[59/100][13/43] KL_real/fake: 4.550/4.544 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[59/100][14/43] KL_real/fake: 4.553/4.548 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[59/100][15/43] KL_real/fake: 4.556/4.550 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[59/100][16/43] KL_real/fake: 4.554/4.551 mean_real/fake: -0.003/-0.006 var_real/fake: 0.007/0.007 \n",
      "[59/100][17/43] KL_real/fake: 4.552/4.551 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[59/100][18/43] KL_real/fake: 4.552/4.552 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[59/100][19/43] KL_real/fake: 4.552/4.548 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[59/100][20/43] KL_real/fake: 4.549/4.547 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[59/100][21/43] KL_real/fake: 4.552/4.548 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[59/100][22/43] KL_real/fake: 4.550/4.546 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[59/100][23/43] KL_real/fake: 4.550/4.544 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[59/100][24/43] KL_real/fake: 4.547/4.544 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[59/100][25/43] KL_real/fake: 4.548/4.545 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[59/100][26/43] KL_real/fake: 4.544/4.544 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[59/100][27/43] KL_real/fake: 4.547/4.539 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[59/100][28/43] KL_real/fake: 4.535/4.535 mean_real/fake: -0.006/-0.003 var_real/fake: 0.007/0.007 \n",
      "[59/100][29/43] KL_real/fake: 4.537/4.534 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[59/100][30/43] KL_real/fake: 4.534/4.531 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[59/100][31/43] KL_real/fake: 4.532/4.528 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[59/100][32/43] KL_real/fake: 4.528/4.526 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[59/100][33/43] KL_real/fake: 4.531/4.526 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[59/100][34/43] KL_real/fake: 4.528/4.526 mean_real/fake: -0.003/-0.003 var_real/fake: 0.007/0.007 \n",
      "[59/100][35/43] KL_real/fake: 4.531/4.528 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[59/100][36/43] KL_real/fake: 4.528/4.527 mean_real/fake: -0.005/-0.002 var_real/fake: 0.007/0.007 \n",
      "[59/100][37/43] KL_real/fake: 4.533/4.531 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[59/100][38/43] KL_real/fake: 4.539/4.534 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[59/100][39/43] KL_real/fake: 4.541/4.539 mean_real/fake: -0.003/-0.003 var_real/fake: 0.007/0.007 \n",
      "[59/100][40/43] KL_real/fake: 4.544/4.538 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[59/100][41/43] KL_real/fake: 4.551/4.542 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[59/100][42/43] KL_real/fake: 4.547/4.544 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[60/100][0/43] KL_real/fake: 4.553/4.543 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[60/100][1/43] KL_real/fake: 4.549/4.546 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[60/100][2/43] KL_real/fake: 4.553/4.547 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[60/100][3/43] KL_real/fake: 4.551/4.551 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[60/100][4/43] KL_real/fake: 4.553/4.550 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[60/100][5/43] KL_real/fake: 4.553/4.551 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[60/100][6/43] KL_real/fake: 4.555/4.552 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[60/100][7/43] KL_real/fake: 4.551/4.550 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[60/100][8/43] KL_real/fake: 4.553/4.550 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[60/100][9/43] KL_real/fake: 4.551/4.550 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[60/100][10/43] KL_real/fake: 4.557/4.550 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[60/100][11/43] KL_real/fake: 4.562/4.553 mean_real/fake: -0.004/-0.006 var_real/fake: 0.006/0.007 \n",
      "[60/100][12/43] KL_real/fake: 4.559/4.554 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[60/100][13/43] KL_real/fake: 4.556/4.554 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[60/100][14/43] KL_real/fake: 4.556/4.551 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[60/100][15/43] KL_real/fake: 4.554/4.547 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[60/100][16/43] KL_real/fake: 4.553/4.544 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[60/100][17/43] KL_real/fake: 4.551/4.547 mean_real/fake: -0.005/-0.003 var_real/fake: 0.007/0.007 \n",
      "[60/100][18/43] KL_real/fake: 4.549/4.546 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[60/100][19/43] KL_real/fake: 4.547/4.544 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[60/100][20/43] KL_real/fake: 4.551/4.544 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[60/100][21/43] KL_real/fake: 4.549/4.547 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[60/100][22/43] KL_real/fake: 4.552/4.555 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[60/100][23/43] KL_real/fake: 4.548/4.545 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[60/100][24/43] KL_real/fake: 4.549/4.545 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[60/100][25/43] KL_real/fake: 4.548/4.543 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[60/100][26/43] KL_real/fake: 4.544/4.541 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[60/100][27/43] KL_real/fake: 4.540/4.540 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[60/100][28/43] KL_real/fake: 4.544/4.539 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[60/100][29/43] KL_real/fake: 4.541/4.541 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[60/100][30/43] KL_real/fake: 4.546/4.544 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[60/100][31/43] KL_real/fake: 4.548/4.546 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[60/100][32/43] KL_real/fake: 4.544/4.543 mean_real/fake: -0.007/-0.003 var_real/fake: 0.007/0.007 \n",
      "[60/100][33/43] KL_real/fake: 4.540/4.542 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[60/100][34/43] KL_real/fake: 4.542/4.538 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60/100][35/43] KL_real/fake: 4.539/4.538 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[60/100][36/43] KL_real/fake: 4.544/4.538 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[60/100][37/43] KL_real/fake: 4.543/4.542 mean_real/fake: -0.004/-0.007 var_real/fake: 0.007/0.007 \n",
      "[60/100][38/43] KL_real/fake: 4.544/4.543 mean_real/fake: -0.006/-0.007 var_real/fake: 0.007/0.007 \n",
      "[60/100][39/43] KL_real/fake: 4.543/4.541 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[60/100][40/43] KL_real/fake: 4.541/4.544 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[60/100][41/43] KL_real/fake: 4.543/4.538 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[60/100][42/43] KL_real/fake: 4.544/4.537 mean_real/fake: -0.007/-0.005 var_real/fake: 0.007/0.007 \n",
      "[61/100][0/43] KL_real/fake: 4.539/4.533 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[61/100][1/43] KL_real/fake: 4.536/4.530 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[61/100][2/43] KL_real/fake: 4.538/4.529 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[61/100][3/43] KL_real/fake: 4.534/4.533 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[61/100][4/43] KL_real/fake: 4.536/4.533 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[61/100][5/43] KL_real/fake: 4.541/4.534 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[61/100][6/43] KL_real/fake: 4.543/4.538 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[61/100][7/43] KL_real/fake: 4.536/4.538 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[61/100][8/43] KL_real/fake: 4.541/4.536 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[61/100][9/43] KL_real/fake: 4.537/4.537 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[61/100][10/43] KL_real/fake: 4.538/4.538 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[61/100][11/43] KL_real/fake: 4.543/4.538 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[61/100][12/43] KL_real/fake: 4.540/4.537 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[61/100][13/43] KL_real/fake: 4.540/4.538 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[61/100][14/43] KL_real/fake: 4.541/4.535 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[61/100][15/43] KL_real/fake: 4.538/4.539 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[61/100][16/43] KL_real/fake: 4.541/4.537 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[61/100][17/43] KL_real/fake: 4.542/4.539 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[61/100][18/43] KL_real/fake: 4.546/4.542 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[61/100][19/43] KL_real/fake: 4.550/4.544 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[61/100][20/43] KL_real/fake: 4.546/4.544 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[61/100][21/43] KL_real/fake: 4.549/4.545 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[61/100][22/43] KL_real/fake: 4.549/4.549 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[61/100][23/43] KL_real/fake: 4.548/4.546 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[61/100][24/43] KL_real/fake: 4.543/4.544 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[61/100][25/43] KL_real/fake: 4.546/4.541 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[61/100][26/43] KL_real/fake: 4.545/4.545 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[61/100][27/43] KL_real/fake: 4.539/4.540 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[61/100][28/43] KL_real/fake: 4.539/4.537 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[61/100][29/43] KL_real/fake: 4.537/4.534 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[61/100][30/43] KL_real/fake: 4.537/4.536 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[61/100][31/43] KL_real/fake: 4.538/4.532 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[61/100][32/43] KL_real/fake: 4.538/4.535 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[61/100][33/43] KL_real/fake: 4.536/4.537 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[61/100][34/43] KL_real/fake: 4.535/4.535 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[61/100][35/43] KL_real/fake: 4.537/4.536 mean_real/fake: -0.007/-0.006 var_real/fake: 0.007/0.007 \n",
      "[61/100][36/43] KL_real/fake: 4.537/4.534 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[61/100][37/43] KL_real/fake: 4.541/4.535 mean_real/fake: -0.003/-0.007 var_real/fake: 0.007/0.007 \n",
      "[61/100][38/43] KL_real/fake: 4.542/4.544 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[61/100][39/43] KL_real/fake: 4.553/4.550 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[61/100][40/43] KL_real/fake: 4.556/4.553 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[61/100][41/43] KL_real/fake: 4.556/4.552 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[61/100][42/43] KL_real/fake: 4.559/4.554 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[62/100][0/43] KL_real/fake: 4.557/4.554 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[62/100][1/43] KL_real/fake: 4.554/4.552 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[62/100][2/43] KL_real/fake: 4.548/4.546 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[62/100][3/43] KL_real/fake: 4.544/4.542 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[62/100][4/43] KL_real/fake: 4.544/4.541 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[62/100][5/43] KL_real/fake: 4.543/4.542 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[62/100][6/43] KL_real/fake: 4.545/4.545 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[62/100][7/43] KL_real/fake: 4.546/4.544 mean_real/fake: -0.005/-0.006 var_real/fake: 0.007/0.007 \n",
      "[62/100][8/43] KL_real/fake: 4.547/4.542 mean_real/fake: -0.003/-0.005 var_real/fake: 0.007/0.007 \n",
      "[62/100][9/43] KL_real/fake: 4.543/4.542 mean_real/fake: -0.004/-0.004 var_real/fake: 0.007/0.007 \n",
      "[62/100][10/43] KL_real/fake: 4.547/4.543 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[62/100][11/43] KL_real/fake: 4.545/4.543 mean_real/fake: -0.005/-0.004 var_real/fake: 0.007/0.007 \n",
      "[62/100][12/43] KL_real/fake: 4.549/4.543 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[62/100][13/43] KL_real/fake: 4.545/4.541 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[62/100][14/43] KL_real/fake: 4.540/4.539 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[62/100][15/43] KL_real/fake: 4.541/4.541 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[62/100][16/43] KL_real/fake: 4.541/4.540 mean_real/fake: -0.004/-0.003 var_real/fake: 0.007/0.007 \n",
      "[62/100][17/43] KL_real/fake: 4.544/4.542 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[62/100][18/43] KL_real/fake: 4.545/4.543 mean_real/fake: -0.003/-0.003 var_real/fake: 0.007/0.007 \n",
      "[62/100][19/43] KL_real/fake: 4.547/4.548 mean_real/fake: -0.003/-0.006 var_real/fake: 0.007/0.007 \n",
      "[62/100][20/43] KL_real/fake: 4.545/4.544 mean_real/fake: -0.004/-0.005 var_real/fake: 0.007/0.007 \n",
      "[62/100][21/43] KL_real/fake: 4.550/4.546 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[62/100][22/43] KL_real/fake: 4.550/4.547 mean_real/fake: -0.004/-0.006 var_real/fake: 0.007/0.007 \n",
      "[62/100][23/43] KL_real/fake: 4.549/4.547 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[62/100][24/43] KL_real/fake: 4.543/4.542 mean_real/fake: -0.006/-0.006 var_real/fake: 0.007/0.007 \n",
      "[62/100][25/43] KL_real/fake: 4.545/4.540 mean_real/fake: -0.006/-0.005 var_real/fake: 0.007/0.007 \n",
      "[62/100][26/43] KL_real/fake: 4.541/4.537 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[62/100][27/43] KL_real/fake: 4.540/4.537 mean_real/fake: -0.005/-0.007 var_real/fake: 0.007/0.007 \n",
      "[62/100][28/43] KL_real/fake: 4.543/4.539 mean_real/fake: -0.006/-0.003 var_real/fake: 0.007/0.007 \n",
      "[62/100][29/43] KL_real/fake: 4.544/4.537 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n",
      "[62/100][30/43] KL_real/fake: 4.546/4.542 mean_real/fake: -0.005/-0.005 var_real/fake: 0.007/0.007 \n",
      "[62/100][31/43] KL_real/fake: 4.544/4.543 mean_real/fake: -0.006/-0.004 var_real/fake: 0.007/0.007 \n"
     ]
    }
   ],
   "source": [
    "stats = {}\n",
    "losses = {'KL_real': [],\n",
    "         'Ex_e': [],\n",
    "         'KL_fake': [], \n",
    "         'Ez_e': [],\n",
    "         'KL_fake_g': [],\n",
    "         'Ex_g': [],\n",
    "         'Ez_g_10e3': [],\n",
    "        }\n",
    "\n",
    "for epoch in range(start_epoch, nepoch):\n",
    "\n",
    "    for i in range(len(dataloader['train'])):\n",
    "\n",
    "        # ---------------------------\n",
    "        #        Optimize over e\n",
    "        # ---------------------------\n",
    "        \n",
    "        # e_updates = '1; KL_fake:1, KL_real:1, match_z:0, match_x:10' \n",
    "        \n",
    "        KL_real_ = []\n",
    "        KL_fake_ = []\n",
    "        Ex_e_ = []\n",
    "        Ez_e_ = []\n",
    "\n",
    "        for e_iter in range(updates['e']['num_updates']):\n",
    "            e_losses = []\n",
    "            netE.zero_grad()\n",
    "\n",
    "            # X - e(X)\n",
    "            populate_x(x, dataloader['train'])\n",
    "            ex = netE(x)\n",
    "\n",
    "            # KL_real: - \\Delta( e(X) , Z ) -> max_e\n",
    "            KL_real = KL_minimizer(ex)\n",
    "            e_losses.append(KL_real * updates['e']['KL_real'])\n",
    "            # === stats ===    \n",
    "            KL_real_.append(KL_real.data[0])\n",
    "            \n",
    "            if updates['e']['match_x'] != 0:\n",
    "                # g(e(X))\n",
    "                gex = netG(ex)\n",
    "\n",
    "                # match_x: E_x||g(e(x)) - x|| -> min_e\n",
    "                err = match(gex, x, match_x)\n",
    "                e_losses.append(err * updates['e']['match_x'])\n",
    "                # === stats === \n",
    "                Ex_e_.append(err.data[0])\n",
    "\n",
    "            # Save some stats\n",
    "            stats['real_mean'] = KL_minimizer.samples_mean.data.mean()\n",
    "            stats['real_var'] = KL_minimizer.samples_var.data.mean()\n",
    "            stats['KL_real'] = KL_real.data[0]\n",
    "\n",
    "            # ================================================\n",
    "\n",
    "            # Z - g(Z) - e(g(Z))\n",
    "            populate_z(z)\n",
    "            fake = netG(z).detach()\n",
    "            egz = netE(fake)\n",
    "\n",
    "            # KL_fake: \\Delta( e(g(Z)) , Z ) -> max_e\n",
    "            KL_fake = KL_maximizer(egz)\n",
    "            e_losses.append(KL_fake * updates['e']['KL_fake'])\n",
    "            # === stats === \n",
    "            KL_fake_.append(-KL_fake.data[0])\n",
    "            \n",
    "            if updates['e']['match_z'] != 0:\n",
    "                # match_z: E_z||e(g(z)) - z|| -> min_e\n",
    "                err = match(egz, z, match_z)\n",
    "                e_losses.append(err * updates['e']['match_z'])\n",
    "                # === stats === \n",
    "                Ez_e_.append(err.data[0])\n",
    "            \n",
    "            # Update e\n",
    "            sum(e_losses).backward()\n",
    "            optimizerD.step()\n",
    "\n",
    "            # === stats === \n",
    "            stats['fake_mean'] = KL_maximizer.samples_mean.data.mean()\n",
    "            stats['fake_var'] = KL_maximizer.samples_var.data.mean()\n",
    "            stats['KL_fake'] = -KL_fake.data[0]\n",
    "            \n",
    "            if KL_real_: losses['KL_real'].append(np.mean(KL_real_))\n",
    "            if KL_fake_: losses['KL_fake'].append(np.mean(KL_fake_))\n",
    "            if Ex_e_: losses['Ex_e'].append(np.mean(Ex_e_))\n",
    "            if Ez_e_: losses['Ez_e'].append(np.mean(Ez_e_))\n",
    "            \n",
    "        # ---------------------------\n",
    "        #        Minimize over g\n",
    "        # ---------------------------\n",
    "        \n",
    "        # g_updates = '3; KL_fake:1, match_z:1000, match_x:0'\n",
    "\n",
    "        KL_fake_g_ = []\n",
    "        Ex_g_ = []\n",
    "        Ez_g_ = []\n",
    "        \n",
    "        for g_iter in range(updates['g']['num_updates']):\n",
    "            g_losses = []\n",
    "            netG.zero_grad()\n",
    "\n",
    "            # Z - g(Z) - e(g(Z))\n",
    "            populate_z(z)\n",
    "            fake = netG(z)\n",
    "            egz = netE(fake)\n",
    "\n",
    "            # KL_fake: \\Delta( e(g(Z)) , Z ) -> min_g\n",
    "            KL_fake_g = KL_minimizer(egz)\n",
    "            g_losses.append(KL_fake_g * updates['g']['KL_fake'])\n",
    "            # === stats === \n",
    "            KL_fake_g_.append(KL_fake_g.data[0])\n",
    "            \n",
    "            if updates['g']['match_z'] != 0:\n",
    "                # match_z: E_z||e(g(z)) - z|| -> min_g\n",
    "                err = match(egz, z, match_z)\n",
    "                err = err * updates['g']['match_z']\n",
    "                g_losses.append(err)\n",
    "                # === stats === \n",
    "#                 Ez_g_.append(err.data[0])\n",
    "                Ez_g_.append(err.data[0] / 1000)\n",
    "                \n",
    "            # ==================================\n",
    "\n",
    "            if updates['g']['match_x'] != 0:\n",
    "                # X - e(X) - g(e(X))\n",
    "                populate_x(x, dataloader['train'])\n",
    "                ex = netE(x)\n",
    "                gex = netG(ex)\n",
    "\n",
    "                # match_x: E_x||g(e(x)) - x|| -> min_g\n",
    "                err = match(gex, x, match_x)\n",
    "                err = err * updates['g']['match_x']\n",
    "                g_losses.append(err)\n",
    "                # === stats === \n",
    "                Ex_g_.append(err.data[0])\n",
    "\n",
    "            # Step g\n",
    "            sum(g_losses).backward()\n",
    "            optimizerG.step()\n",
    "        \n",
    "        # === stats === \n",
    "        if KL_fake_g_: losses['KL_fake_g'].append(np.mean(KL_fake_g_))\n",
    "        if Ez_g_: losses['Ez_g_10e3'].append(np.mean(Ez_g_))\n",
    "        if Ex_g_: losses['Ex_g'].append(np.mean(Ex_g_))\n",
    "        \n",
    "        # === stdout === \n",
    "        print('[{epoch}/{nepoch}][{iter}/{niter}] '\n",
    "              'KL_real/fake: {KL_real:.3f}/{KL_fake:.3f} '\n",
    "              'mean_real/fake: {real_mean:.3f}/{fake_mean:.3f} '\n",
    "              'var_real/fake: {real_var:.3f}/{fake_var:.3f} '\n",
    "              ''.format(epoch=epoch,\n",
    "                        nepoch=nepoch,\n",
    "                        iter=i,\n",
    "                        niter=len(dataloader['train']),\n",
    "                        **stats))\n",
    "        \n",
    "        \n",
    "# #         if save_every_b:\n",
    "# #             if i % save_every_b == 0: save_images(epoch)\n",
    "            \n",
    "#         # If an epoch takes long time, dump intermediate\n",
    "#         if dataset in ['lsun', 'imagenet'] and (i % 5000 == 0):\n",
    "#             torch.save(netG, '%s/netG_epoch_%d_it_%d.pth' %\n",
    "#                        (save_dir, epoch, i))\n",
    "#             torch.save(netE, '%s/netE_epoch_%d_it_%d.pth' %\n",
    "#                        (save_dir, epoch, i))\n",
    "\n",
    "    # === adjusting learning rate ===\n",
    "    adjust_lr(epoch)\n",
    "    \n",
    "    # === saving === \n",
    "    if epoch % save_every_e == 0: \n",
    "        save_images(epoch)\n",
    "        # do checkpointing\n",
    "        torch.save(netG, '%s/netG_epoch_%d.pth' % (save_dir, epoch))\n",
    "        torch.save(netE, '%s/netE_epoch_%d.pth' % (save_dir, epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to init](#init)\n",
    "<a id='train'.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/pytorch/issues/1355"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o_f = 'output/helen/train_hist_ims_64_64_25.gif'\n",
    "# from IPython.display import HTML\n",
    "# # HTML('<img src=\"%s\">' %o_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_train_hist(hist, run, show=True, save=True, o_p='output/helen'):\n",
    "    \n",
    "    nepoch = int(run.split('_')[2])\n",
    "    batch_size = int(run.split('_')[1])\n",
    "    \n",
    "    plt.figure(figsize = (12, 6))\n",
    "    x = range(len(hist['KL_real']))\n",
    "    for i, j in hist.items():\n",
    "        if j: plt.plot(x, j, label=i)\n",
    "            \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Losses')\n",
    "    plt.legend(loc=4)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save: plt.savefig(os.path.join(o_p, 'train_hist_%s.png' %run))\n",
    "    if show: plt.show()\n",
    "    else: plt.close()\n",
    "        \n",
    "def log_last_epoch(netG, netE, run, o_p='output/helen'):\n",
    "    le = round((nepoch / save_every_e)) * save_every_e\n",
    "    if le < 10: le_str = 'epoch_00%d' %le\n",
    "    elif le < 100: le_str = 'epoch_0%d' %le\n",
    "    else: le_str = 'epoch_%d' %le\n",
    "    \n",
    "    fr_name = os.path.join(o_p, 'reconstructions_' + le_str + '.png'); print(fr_name)\n",
    "    fn_name = os.path.join(o_p, 'fake_samples_' + le_str + '.png'); print(fn_name)\n",
    "    \n",
    "    imr = cv2.imread(fr_name, cv2.IMREAD_UNCHANGED); cv2.imwrite(os.path.join(o_p, 'ims_rec_last_epoch_%s.png' %run), imr)\n",
    "    imn = cv2.imread(fn_name, cv2.IMREAD_UNCHANGED); cv2.imwrite(os.path.join(o_p, 'ims_noi_last_epoch_%s.png' %run), imn)\n",
    "        \n",
    "    torch.save(netG, '%s/models_netG_last_epoch_%s.pth' % (o_p, run))\n",
    "    torch.save(netE, '%s/models_netE_last_epoch_%s.pth' % (o_p, run))\n",
    "    \n",
    "    plot_ims(np.array([imr, imn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_train_hist(losses, run)\n",
    "log_last_epoch(netG, netE, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type _netG_Base. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/ubuntu/anaconda/envs/p3/lib/python3.6/site-packages/torch/serialization.py:158: UserWarning: Couldn't retrieve source code for container of type _netE_Base. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "o_p='output/helen'\n",
    "torch.save(netG, '%s/models_netG_last_epoch_%s.pth' % (o_p, run))\n",
    "torch.save(netE, '%s/models_netE_last_epoch_%s.pth' % (o_p, run))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def train_hist_ims_gif(run, save=True, show=True, o_p='output/helen'):\n",
    "    \n",
    "#     ims_rec = []\n",
    "#     for i in range(nepoch):\n",
    "#         if i < 10:\n",
    "#             f_name = os.path.join(o_p, 'reconstructions_epoch_00' + str(i) + '.png')\n",
    "#             ims_rec.append(imageio.imread(f_name))\n",
    "#         elif i < 100:\n",
    "#             f_name = os.path.join(o_p, 'reconstructions_epoch_0' + str(i) + '.png')\n",
    "#             ims_rec.append(imageio.imread(f_name))                     \n",
    "#         else:\n",
    "#             f_name = os.path.join(o_p, 'reconstructions_epoch_' + str(i) + '.png')\n",
    "#             ims_rec.append(imageio.imread(f_name))  \n",
    "#         print(len(ims_rec))\n",
    "#     o_f = os.path.join(o_p, 'train_hist_ims_%s.gif' %run); print(o_f)\n",
    "    \n",
    "#     if save: \n",
    "#         imageio.mimsave(o_f, ims_rec, fps=5)\n",
    "    \n",
    "#     if show:\n",
    "#         from IPython.display import HTML\n",
    "#         HTML('<img src=\"%s\">' %o_f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
